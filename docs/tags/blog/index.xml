<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog | SERDAR KORUR</title>
    <link>/tags/blog/</link>
      <atom:link href="/tags/blog/index.xml" rel="self" type="application/rss+xml" />
    <description>Blog</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 10 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>Blog</title>
      <link>/tags/blog/</link>
    </image>
    
    <item>
      <title>Data Preparation: Web Scraping html tables with rvest</title>
      <link>/r/scrape-tables-rvest/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/scrape-tables-rvest/</guid>
      <description>


&lt;div id=&#34;accessing-different-data-sources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accessing different data sources&lt;/h2&gt;
&lt;p&gt;Sometimes, the data you need is available on the web. Accessing those will ease your life as a data scientist.&lt;/p&gt;
&lt;p&gt;I want to perform an exploratory data analysis on &lt;strong&gt;2018/19 Season of England Premier league&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are there changes in team performances during the season timeline?&lt;/li&gt;
&lt;li&gt;Does some teams cluster?&lt;/li&gt;
&lt;li&gt;Which is the earliest week we can predict team’s final positions?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I need the &lt;strong&gt;standings table&lt;/strong&gt; for each week of the season and integrate them in a way that will allow me to plot the graphs that I want.
We will scrap those tables from &lt;a href=&#34;https://www.weltfussball.de/&#34; class=&#34;uri&#34;&gt;https://www.weltfussball.de/&lt;/a&gt;.&lt;img src=&#34;/img/welt.png&#34; alt=&#34;welt&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For example standings table for the Week 1 is at the url:&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&#34; class=&#34;uri&#34;&gt;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the consequent weeks only the number at the end changes e.g.&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/2&#34;&gt;../spielplan/eng-premier-league-2018-2019-spieltag/&lt;strong&gt;2&lt;/strong&gt;&lt;/a&gt; ←&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/3&#34;&gt;../spielplan/eng-premier-league-2018-2019-spieltag/&lt;strong&gt;3&lt;/strong&gt;&lt;/a&gt; ←&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Pull the necessary packages  

library(rvest)     # xml2
library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
library(gganimate)
library(RColorBrewer)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the remote url
baseUrl &amp;lt;- &amp;quot;https://www.weltfussball.de/&amp;quot;
path &amp;lt;- &amp;quot;spielplan/eng-premier-league-2018-2019-spieltag/&amp;quot;
fileName &amp;lt;- 1
url &amp;lt;- paste0(baseUrl, path, fileName)
url&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We start by downloading and parsing the file with &lt;strong&gt;read_html()&lt;/strong&gt; function from the rvest package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tables &amp;lt;- read_html(url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To extract the html table individually you can use &lt;strong&gt;XPath&lt;/strong&gt; syntax which defines parts on XML documents.&lt;/p&gt;
&lt;p&gt;To get the XPath for standings table open the url on google chrome,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hover the mouse over the table &amp;gt; right click &amp;gt; inspect&lt;/strong&gt;&lt;br /&gt;
# This will open inspector&lt;/li&gt;
&lt;li&gt;Move your mouse a few lines up or down to find the line where whole table is highlighted&lt;/li&gt;
&lt;li&gt;Right click &amp;gt; Copy &amp;gt; Copy full XPath&lt;img src=&#34;/img/weltxpath.png&#34; alt=&#34;weltxpath&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can feed that XPath we copied to html_nodes() function and extract the node which contains the table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xpath = &amp;quot;/html/body/div[3]/div[2]/div[4]/div[2]/div[1]/div/div[7]/div/table[1]&amp;quot;
nodes &amp;lt;- html_nodes(tables, xpath = xpath)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end, html_table() function will extract us the individual table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;html_table(nodes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##     # Mannschaft              Mannschaft Sp. S. U. N. Tore Dif. Pk.
## 1   1         NA            Liverpool FC   1  1  0  0  4:0    4   3
## 2   2         NA              Chelsea FC   1  1  0  0  3:0    3   3
## 3   3         NA         AFC Bournemouth   1  1  0  0  2:0    2   3
## 4  NA         NA          Crystal Palace   1  1  0  0  2:0    2   3
## 5  NA         NA         Manchester City   1  1  0  0  2:0    2   3
## 6  NA         NA              Watford FC   1  1  0  0  2:0    2   3
## 7   7         NA       Manchester United   1  1  0  0  2:1    1   3
## 8  NA         NA       Tottenham Hotspur   1  1  0  0  2:1    1   3
## 9   9         NA              Everton FC   1  0  1  0  2:2    0   1
## 10 NA         NA Wolverhampton Wanderers   1  0  1  0  2:2    0   1
## 11 11         NA              Burnley FC   1  0  1  0  0:0    0   1
## 12 NA         NA          Southampton FC   1  0  1  0  0:0    0   1
## 13 13         NA          Leicester City   1  0  0  1  1:2   -1   0
## 14 NA         NA        Newcastle United   1  0  0  1  1:2   -1   0
## 15 15         NA              Arsenal FC   1  0  0  1  0:2   -2   0
## 16 NA         NA  Brighton &amp;amp; Hove Albion   1  0  0  1  0:2   -2   0
## 17 NA         NA            Cardiff City   1  0  0  1  0:2   -2   0
## 18 NA         NA               Fulham FC   1  0  0  1  0:2   -2   0
## 19 19         NA       Huddersfield Town   1  0  0  1  0:3   -3   0
## 20 20         NA         West Ham United   1  0  0  1  0:4   -4   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wonderful, we scraped the standings table for the first week, but we want tables for each 38 week of the season.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You can make this easily by packing what we have done so far in a for loop.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As only the last number in our url link changes, we can code different url addresses as in &lt;code&gt;url[[i]] &amp;lt;- paste0(baseUrl, path, i)&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create emtpy lists
url &amp;lt;- list()
pages &amp;lt;- list()
nodes &amp;lt;- list()
final &amp;lt;- list()
start &amp;lt;- Sys.time()
# For loop.
# It will connect one by one to 38 different url links predefined 
# by the line starting with url[[i]]
# Collect the information with read_html(), html_nodes() and html_table()
# Finally each table will be converted to a data frame
for(i in 1:38){
url[[i]] &amp;lt;- paste0(baseUrl, path, i)
pages[[i]] &amp;lt;- read_html(url[[i]])
nodes[[i]] &amp;lt;- html_nodes(pages[[i]], xpath = xpath)
final[[i]] &amp;lt;- data.frame(html_table(nodes[[i]]))
}

# By coding start and end times of the whole process 
# I can keep an eye on how fast my code is.
end &amp;lt;- Sys.time()
end-start&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 22.62705 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, &lt;code&gt;final[[19]]&lt;/code&gt; will give me standings of mid season:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final[[19]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    X. Mannschaft            Mannschaft.1 Sp. S. U. N.  Tore Dif. Pk.
## 1   1         NA            Liverpool FC  19 16  3  0  43:7   36  51
## 2   2         NA       Tottenham Hotspur  19 15  0  4 42:18   24  45
## 3   3         NA         Manchester City  19 14  2  3 51:15   36  44
## 4   4         NA              Chelsea FC  19 12  4  3 37:16   21  40
## 5   5         NA              Arsenal FC  19 11  5  3 41:25   16  38
## 6   6         NA       Manchester United  19  9  5  5 37:31    6  32
## 7   7         NA          Leicester City  19  8  4  7 24:22    2  28
## 8   8         NA              Everton FC  19  7  6  6 31:29    2  27
## 9   9         NA         West Ham United  19  8  3  8 27:28   -1  27
## 10 10         NA              Watford FC  19  8  3  8 26:27   -1  27
## 11 11         NA Wolverhampton Wanderers  19  7  5  7 20:22   -2  26
## 12 12         NA         AFC Bournemouth  19  8  2  9 27:33   -6  26
## 13 13         NA  Brighton &amp;amp; Hove Albion  19  6  4  9 21:27   -6  22
## 14 14         NA          Crystal Palace  19  5  4 10 17:25   -8  19
## 15 15         NA        Newcastle United  19  4  5 10 14:26  -12  17
## 16 16         NA          Southampton FC  19  3  6 10 20:35  -15  15
## 17 17         NA            Cardiff City  19  4  3 12 18:38  -20  15
## 18 18         NA              Burnley FC  19  3  3 13 17:41  -24  12
## 19 19         NA               Fulham FC  19  2  5 12 17:43  -26  11
## 20 20         NA       Huddersfield Town  19  2  4 13 12:34  -22  10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don’t mind the NAs in the second column, we will remove them soon.
Now, we have all 38 table in our list &lt;strong&gt;final&lt;/strong&gt;, we can combine them to a new data frame which will contain standings of the whole season.&lt;/p&gt;
&lt;p&gt;To be able to plot e.g. timeline, let’s keep the tidy data principles:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Each observation has its own row.&lt;/li&gt;
&lt;li&gt;Each variable has its own column.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since we have same column names in each table, we can use &lt;strong&gt;rbind&lt;/strong&gt; function to add rows of each table to the bottom of the first one. How to do that? We can’t use lapply() function here. It will not combine elements in a list. We can use &lt;strong&gt;do.call() function to perform the rbind() operation and combine all data frames we have&lt;/strong&gt;*.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk18 &amp;lt;-  do.call(&amp;quot;rbind&amp;quot;, final)
dim(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 760  10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X. Mannschaft    Mannschaft.1 Sp. S. U. N. Tore Dif. Pk.
## 1  1         NA    Liverpool FC   1  1  0  0  4:0    4   3
## 2  2         NA      Chelsea FC   1  1  0  0  3:0    3   3
## 3  3         NA AFC Bournemouth   1  1  0  0  2:0    2   3
## 4 NA         NA  Crystal Palace   1  1  0  0  2:0    2   3
## 5 NA         NA Manchester City   1  1  0  0  2:0    2   3
## 6 NA         NA      Watford FC   1  1  0  0  2:0    2   3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Column names/shorcuts were in German, let’s replace them with the English words.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Correct final table
uk18 &amp;lt;- uk18  %&amp;gt;% select(3:10)
new_names &amp;lt;- c(&amp;quot;team&amp;quot;, &amp;quot;week&amp;quot;, &amp;quot;won&amp;quot;, &amp;quot;drawn&amp;quot;, &amp;quot;lost&amp;quot;, &amp;quot;goals&amp;quot;, 
               &amp;quot;difference&amp;quot;, &amp;quot;points&amp;quot;)
colnames(uk18) &amp;lt;- new_names&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Goals variable is contains two different data separated with “:”. &lt;code&gt;E.g. (4:0)&lt;/code&gt;. Those represent goals scored:goals scored against. Let’s split goals column into two by &lt;strong&gt;separate() function from tidyr&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk18 &amp;lt;- uk18 %&amp;gt;% separate(goals, c(&amp;quot;scored&amp;quot;, &amp;quot;against&amp;quot;), sep=&amp;quot;\\:&amp;quot;)
head(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              team week won drawn lost scored against difference points
## 1    Liverpool FC    1   1     0    0      4       0          4      3
## 2      Chelsea FC    1   1     0    0      3       0          3      3
## 3 AFC Bournemouth    1   1     0    0      2       0          2      3
## 4  Crystal Palace    1   1     0    0      2       0          2      3
## 5 Manchester City    1   1     0    0      2       0          2      3
## 6      Watford FC    1   1     0    0      2       0          2      3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;I want to order my legend with the same order of teams final positions&lt;/strong&gt;. Let’s filter for the last week of the season and arrange them in descending order. I will assign this list to the factor levels of the team variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract team names in the order as the season end
uk18_filt &amp;lt;- uk18 %&amp;gt;% 
  filter(week == 38) %&amp;gt;%
  arrange(desc(points))
knitr::kable(uk18_filt)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
team
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
week
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
won
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
drawn
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lost
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
scored
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
against
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
difference
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
points
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Manchester City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
98
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Liverpool FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
89
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
97
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chelsea FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tottenham Hotspur
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Arsenal FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Manchester United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wolverhampton Wanderers
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Everton FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Leicester City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
West Ham United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Watford FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Crystal Palace
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Newcastle United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AFC Bournemouth
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burnley FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Southampton FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brighton &amp;amp; Hove Albion
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cardiff City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Fulham FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Huddersfield Town
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;finallevels &amp;lt;- as.character(uk18_filt$team)
uk18$team &amp;lt;- factor(uk18$team, levels = finallevels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also create a color palette which fits to your needs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We need a color palette with 20 colors
colorCount &amp;lt;- length(unique(uk18$team))
# colorRampPalette creatas a getPalette() function
# This can modify an existing palette to include as many colors we want
getPalette &amp;lt;- colorRampPalette(brewer.pal(9, &amp;quot;Set1&amp;quot;))
getPalette(colorCount)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;#E41A1C&amp;quot; &amp;quot;#9B445D&amp;quot; &amp;quot;#526E9F&amp;quot; &amp;quot;#3C8A9B&amp;quot; &amp;quot;#469F6C&amp;quot; &amp;quot;#54A453&amp;quot; &amp;quot;#747B78&amp;quot;
##  [8] &amp;quot;#94539E&amp;quot; &amp;quot;#BD6066&amp;quot; &amp;quot;#E97422&amp;quot; &amp;quot;#FF990A&amp;quot; &amp;quot;#FFCF20&amp;quot; &amp;quot;#FAF632&amp;quot; &amp;quot;#D4AE2D&amp;quot;
## [15] &amp;quot;#AF6729&amp;quot; &amp;quot;#BF6357&amp;quot; &amp;quot;#E17597&amp;quot; &amp;quot;#E884B9&amp;quot; &amp;quot;#C08EA9&amp;quot; &amp;quot;#999999&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot season timeline using the palette we just created
uk &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) +   
  geom_point(size=3) + 
  theme(text = element_text(size=15)) + 
  scale_color_manual(values = getPalette(colorCount))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the regression lines&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot season timeline
uk &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) + 
  geom_smooth(se=TRUE) + 
  theme(text = element_text(size=15)) + 
  scale_color_manual(values = getPalette(colorCount))

uk&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/Season%20timeline%20linear%20model-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk_facet &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) + 
  geom_smooth(se=FALSE) + 
  theme(text = element_text(size=10)) + 
  scale_color_manual(values = getPalette(colorCount)) + 
  facet_wrap(ncol = 4, team~.)

uk_facet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/Season%20timeline%20linear%20model-2.png&#34; width=&#34;672&#34; /&gt;
Some insights from the plots:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I see three clusters here. Two teams (Man. City and Liverpool) competed head to head for the championship and next three teams (Chelsea, Tottenham and Arsenal) for the 3rd position.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;We can predict 4 out of 5 teams which will take first 5 place at the end of the season early as week 10.&lt;/li&gt;
&lt;li&gt;Manchester United showed peak performance mid season, Everton have improved performances while Tottenham slowed down (which costed them 3rd position) in the second part of the season.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I can plot points against goal differences in the same plot. Same clusters pop up here as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk &amp;lt;- ggplot(uk18, aes(x=difference, y=points, col=team)) + 
  geom_point(size=2) + 
  scale_color_manual(values = getPalette(colorCount)) + 
  theme(text = element_text(size=15))
uk&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/points%20vs%20goal%20differences-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s visualize this in a small animation. You can create an animated plot of the teams progress during the season. Gganimate does good job.`&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Add a shadow tail
# anim + shadow_wake(wake_length = 0.3, alpha = FALSE)
 
anim &amp;lt;- uk + 
             transition_time(week) + 
             labs(title = &amp;quot;week: {round(frame_time,0)}&amp;quot;) + 
             shadow_wake(wake_length = 0.1, alpha = 0.5)

fullanimation &amp;lt;- animate(anim, fps= 7, nframes=100, 
                         height=500, width=800, res=0.8)

fullanimation&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/gganimate-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-future-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions / Future Thoughts&lt;/h1&gt;
&lt;p&gt;One of the most important steps to answer a research question is gathering and pre-processing data that fits best for the planned analysis.&lt;/p&gt;
&lt;p&gt;Some of the questions we tackled were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to find the &lt;strong&gt;XPath&lt;/strong&gt; for an &lt;strong&gt;html table&lt;/strong&gt; in a website?&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;combine data frames&lt;/strong&gt; from &lt;strong&gt;a list&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;split columns&lt;/strong&gt; containing more than one variable?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The earliest time, we can predict top teams final positions was around 10th. We can collect data from previous years or compare other countries leagues to check if we can generalize this finding.&lt;/p&gt;
&lt;p&gt;What else we can ask? For example, we can connect performance changes to new transfers. Or whether changing coaches benefited any team.&lt;/p&gt;
&lt;p&gt;Please share if you have other ideas in the comments below!&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;p&gt;PS: If you liked my blog you can find here some other blogs on R at &lt;a href=&#34;https://www.r-bloggers.com&#34;&gt;https://www.r-bloggers.com&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Can machine learning change your lifestyle? Predicting Diabetes</title>
      <link>/r/predict-diseases/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/predict-diseases/</guid>
      <description>


&lt;p&gt;Would you be taking care of yourself better if your doctor told today that you have &lt;strong&gt;high risk of diabetes?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Advances in fields, such as omics and internet of things (sensors that collect data), and centralization of healthcare information (e.g. &lt;a href=&#34;https://www.ohdsi.org/data-standardization/the-common-data-model/&#34;&gt;OMOP common data model&lt;/a&gt;) enable us to access much wider data sources.&lt;/p&gt;
&lt;p&gt;Gaining insights from those we can improve our well being with better healthcare. Some applications of machine learning tools are;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diagnosing diseases earlier&lt;/li&gt;
&lt;li&gt;Identifying drugs with reduced side effects&lt;/li&gt;
&lt;li&gt;Select patient groups responding to an experimental therapy&lt;/li&gt;
&lt;li&gt;Utilize existing therapies better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Let’s look at an example and try to help some doctors in diagnosing their patients.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;problem-formulation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Problem formulation&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we build a Machine learning algorithm to predict which patients will develop Diabetes?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The goal is to predict a Binary &lt;strong&gt;Outcome&lt;/strong&gt;: &lt;code&gt;Diabetes&lt;/code&gt; vs &lt;code&gt;Healthy&lt;/code&gt;
by using 8 medical indicators.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overview-of-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview of the data&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The Pima Indians of Arizona and Mexico&lt;/strong&gt; have contributed to numerous scientific gains. Their involvement has led to significant findings on genetics of both &lt;strong&gt;type 2 diabetes&lt;/strong&gt; and &lt;strong&gt;obesity.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The medical indicators recorded are;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pregnancies:&lt;/strong&gt; Number of times pregnant&lt;br /&gt;
&lt;strong&gt;Glucose:&lt;/strong&gt; Plasma glucose concentration a 2 hours in an oral glucose tolerance test&lt;br /&gt;
&lt;strong&gt;BloodPressure:&lt;/strong&gt; Diastolic blood pressure (mm Hg)&lt;br /&gt;
&lt;strong&gt;SkinThickness:&lt;/strong&gt; Triceps skin fold thickness (mm)&lt;br /&gt;
&lt;strong&gt;Insulin:&lt;/strong&gt; 2-Hour serum insulin (mu U/ml)&lt;br /&gt;
&lt;strong&gt;BMI:&lt;/strong&gt; Body mass index (weight in kg/(height in m)^2)&lt;br /&gt;
&lt;strong&gt;DiabetesPedigreeFunction:&lt;/strong&gt; Diabetes pedigree function&lt;br /&gt;
&lt;strong&gt;Age:&lt;/strong&gt; Age (years)&lt;br /&gt;
&lt;strong&gt;Outcome:&lt;/strong&gt; Class variable (0 or 1)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-acquisition&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data acquisition&lt;/h1&gt;
&lt;p&gt;I downloaded the &lt;a href=&#34;https://www.kaggle.com/uciml/pima-indians-diabetes-database&#34;&gt;Pima Indians Diabetes Dataset&lt;/a&gt; from Kaggle and imported it from my local directory.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diabetes &amp;lt;- read.csv(&amp;quot;posts_data/diabetes.csv&amp;quot;)
library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
library(reshape2)
library(ggcorrplot)
library(pROC)
library(lattice)
library(caret)
library(waffle)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-quality-control&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Quality control&lt;/h1&gt;
&lt;p&gt;Before counting on any algorithm a good starting point is to &lt;strong&gt;check obvious mistakes and abnormalities in your data.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here, I would look at &lt;strong&gt;Missing values&lt;/strong&gt;, variable ranges (&lt;strong&gt;min, max values&lt;/strong&gt;). A very extreme value might be basically a sign of typing error.&lt;/p&gt;
&lt;div id=&#34;understand-your-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Understand your Data&lt;/h2&gt;
&lt;p&gt;How big is the data? Classes of variables?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 768   9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(sapply(diabetes, class))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pregnancies&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Glucose&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;BloodPressure&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;SkinThickness&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Insulin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;BMI&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;DiabetesPedigreeFunction&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Outcome&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Next, what catches my attention is &lt;strong&gt;unexpected zero values in Insulin&lt;/strong&gt;. Look below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(head(diabetes))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Pregnancies&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Glucose&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BloodPressure&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SkinThickness&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Insulin&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BMI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;DiabetesPedigreeFunction&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;148&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.351&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;183&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.672&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.167&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;168&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;116&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.201&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;missing-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Missing Values&lt;/h2&gt;
&lt;p&gt;Summary gives a good overview of the variables. Any missing data will show up here listed as &lt;strong&gt;“NA’s”&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Pregnancies        Glucose      BloodPressure    SkinThickness  
##  Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  
##  1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  
##  Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  
##  Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  
##  3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  
##  Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  
##     Insulin           BMI        DiabetesPedigreeFunction      Age       
##  Min.   :  0.0   Min.   : 0.00   Min.   :0.0780           Min.   :21.00  
##  1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00  
##  Median : 30.5   Median :32.00   Median :0.3725           Median :29.00  
##  Mean   : 79.8   Mean   :31.99   Mean   :0.4719           Mean   :33.24  
##  3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  
##  Max.   :846.0   Max.   :67.10   Max.   :2.4200           Max.   :81.00  
##     Outcome     
##  Min.   :0.000  
##  1st Qu.:0.000  
##  Median :0.000  
##  Mean   :0.349  
##  3rd Qu.:1.000  
##  Max.   :1.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will make visualizations of the variables to see how they are distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- melt(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No id variables; using all as measure variables&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(gg, aes(x=value, fill=variable)) +
  geom_histogram(binwidth=5)+ 
  facet_wrap(~variable) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/Check%20out%20how%20variables%20are%20distributed-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Peaks at zero of Skin Thickness and Insulin is obvious here.&lt;/p&gt;
&lt;p&gt;In cases where the numbers are small we might remove them. &lt;strong&gt;Let’s figure it out with a for loop.&lt;/strong&gt; and then visualize on a waffle plot.&lt;/p&gt;
&lt;p&gt;This will bring me the number of zero containing rows in variables from 2 to 6.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zero_rows &amp;lt;- list()
for(i in 2:6){
zero_rows[[i]] &amp;lt;- length(which(diabetes[,i] == 0))  
}
rows_with_zero &amp;lt;- unlist(zero_rows)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Feed those numbers to a waffle plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zeros &amp;lt;- c(&amp;quot;Glucose&amp;quot; =rows_with_zero[1], &amp;quot;Blood Pressure&amp;quot; = rows_with_zero[2], 
           &amp;quot;Skin Thickness&amp;quot;= rows_with_zero[3], &amp;quot;Insulin&amp;quot; =rows_with_zero[4], 
           &amp;quot;BMI&amp;quot; = rows_with_zero[5])
waffle(zeros, rows=20) + 
  theme(text = element_text(size=15)) + 
  ggtitle(&amp;quot;Number of rows with zero&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/waffle%20plot%20of%20zero%20values-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(rows_with_zero, row.names = names(diabetes[2:6]))
df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               rows_with_zero
## Glucose                    5
## BloodPressure             35
## SkinThickness            227
## Insulin                  374
## BMI                       11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, &lt;strong&gt;374&lt;/strong&gt; Insulin values are zero. Other variables also contain zeros. It is impossible to have Blood Pressure or Glucose levels at 0. It is unlikely that those are simply entry mistakes. It seems missing values are filled with &lt;strong&gt;zeros&lt;/strong&gt; in the data collection phase.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to circumvent this?&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;convert-all-zeroes-to-nas-and-then-perform-median-imputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Convert all &lt;strong&gt;zeroes&lt;/strong&gt; to &lt;strong&gt;NAs&lt;/strong&gt; and then perform &lt;strong&gt;Median Imputation&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Most models require numbers, and can’t handle missing data. Throwing out rows is not a good idea since it can lead to biases in your dataset and generate overconfident models.&lt;/p&gt;
&lt;p&gt;Median imputation lets you model data with missing values. By replacing them with their medians.&lt;/p&gt;
&lt;p&gt;To do this, I need to change zeros to missing values. I will do this for all the predictors which zero is not plausible(columns 2 to 6).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 2:6){
# Convert zeros to NAs
diabetes[, i][diabetes[, i] == 0] &amp;lt;- NA
# Calculate median
median &amp;lt;- median(diabetes[, i], na.rm = TRUE)
diabetes[, i][is.na(diabetes[, i])] &amp;lt;- median
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check if it really happened.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(head(diabetes))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Pregnancies&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Glucose&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BloodPressure&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SkinThickness&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Insulin&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BMI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;DiabetesPedigreeFunction&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;148&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.351&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;183&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.672&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.167&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;168&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;116&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.201&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For instance, I see that zero values in the insulin variable is replaced with median of insulin which is 125.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now, the data is clean and ready for the modeling phase.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-the-data-build-fit-and-validate-a-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Modeling the data (build, fit and validate a model)&lt;/h1&gt;
&lt;p&gt;Before going into any complicated model starting with a simple model is a good idea. It might do surprisingly well and will give us more insights.&lt;/p&gt;
&lt;div id=&#34;logistic-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic Regression Model&lt;/h2&gt;
&lt;p&gt;We will create two random subsets of our data in 80/20 proportion as &lt;strong&gt;training and test data.&lt;/strong&gt; Training data will be used to build our model and test data will be reserved to validate it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(22)
# Create train test split
sample_rows &amp;lt;- sample(nrow(diabetes), nrow(diabetes) * 0.8)
# Create the training dataset
dia_train &amp;lt;- diabetes[sample_rows, ]
# Create the test dataset
dia_test &amp;lt;- diabetes[-sample_rows, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Build a logistic regression model with the train data
glm_dia &amp;lt;- glm(Outcome ~ .,data = dia_train)
summary(glm_dia)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Outcome ~ ., data = dia_train)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.01862  -0.28264  -0.07603   0.29983   0.86403  
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)              -1.0441425  0.1180483  -8.845  &amp;lt; 2e-16 ***
## Pregnancies               0.0173561  0.0056433   3.076 0.002196 ** 
## Glucose                   0.0063034  0.0006150  10.250  &amp;lt; 2e-16 ***
## BloodPressure            -0.0013212  0.0014700  -0.899 0.369137    
## SkinThickness             0.0008966  0.0023291   0.385 0.700395    
## Insulin                  -0.0003233  0.0002088  -1.548 0.122077    
## BMI                       0.0150019  0.0030523   4.915 1.15e-06 ***
## DiabetesPedigreeFunction  0.1661357  0.0489591   3.393 0.000736 ***
## Age                       0.0036157  0.0017283   2.092 0.036845 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 0.1572889)
## 
##     Null deviance: 139.41  on 613  degrees of freedom
## Residual deviance:  95.16  on 605  degrees of freedom
## AIC: 617.69
## 
## Number of Fisher Scoring iterations: 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The summary shows us not all the variables play a role in predicting outcome. The signicant correlations was found for Pregnancies, Glucose, BMI and Pedigree function.&lt;/p&gt;
&lt;p&gt;The predict function will give us probabilities. To compute our model accuracy we need to &lt;strong&gt;convert them to class predictions by setting a threshold level.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We will predict the Outcome for the test data
p&amp;lt;-predict(glm_dia, dia_test)
# Choose a threshold 0.5 to calculate the accuracy of our model
p_05 &amp;lt;- ifelse(p &amp;gt; 0.5, 1, 0)
table(p_05, dia_test$Outcome)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     
## p_05  0  1
##    0 85 17
##    1 15 37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will build a confusion matrix to calculate how accurate our model is in this particular random train/test split and at 0.5 threshold level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat &amp;lt;- table(p_05, dia_test$Outcome)
accuracy &amp;lt;- sum(diag(conf_mat))/sum(conf_mat)
accuracy&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7922078&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;roc&lt;/strong&gt; function pROC package, can plot us a ROC curve which tests accuracy of our model at multiple threshold levels and is a good estimate on how well our model is performing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate AUC(Area under the curve)
roc(dia_test$Outcome, p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting levels: control = 0, case = 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting direction: controls &amp;lt; cases&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## roc.default(response = dia_test$Outcome, predictor = p)
## 
## Data: p in 100 controls (dia_test$Outcome 0) &amp;lt; 54 cases (dia_test$Outcome 1).
## Area under the curve: 0.8498&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this process is little fragile, presence or absence of a single outlier might vastly change the results you might get from a given random train/test split.&lt;/p&gt;
&lt;p&gt;A better approach than a simple train/test split is using multiple test sets and averaging their accuracies.&lt;/p&gt;
&lt;p&gt;Let’s test that. I will create 1, 30 or 1000 random test sets, build models and compare their accuracies.&lt;/p&gt;
&lt;div id=&#34;how-to-apply-multiple-traintest-split&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How to apply multiple train/test split&lt;/h4&gt;
&lt;p&gt;To do this, I will &lt;strong&gt;write a function&lt;/strong&gt; where I can choose number of independent train/test splits.&lt;/p&gt;
&lt;p&gt;It will return me an average value of the accuracy(auc) of the model after chosen number of iteration. The higher the number of random splits the more stable your estimated AUC will be.&lt;/p&gt;
&lt;p&gt;Let’s see how it will work out for our diabetes patients.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I will define my function as follows
multi_split &amp;lt;- function(x){
sample_rows &amp;lt;- list()
dia_train &amp;lt;- list()
dia_test &amp;lt;- list()
glm &amp;lt;- list()
p &amp;lt;-  list()
roc_auc &amp;lt;- list()
for(i in 1:x){
  sample_rows[[i]] &amp;lt;- sample(nrow(diabetes), nrow(diabetes) * 0.8)
  # Create the training dataset
  dia_train[[i]] &amp;lt;- diabetes[sample_rows[[i]], ]
  # Create the test dataset
  dia_test[[i]] &amp;lt;- diabetes[-sample_rows[[i]], ]
  glm[[i]] &amp;lt;- glm(Outcome ~ .,data = dia_train[[i]])
  p[[i]] &amp;lt;- predict(glm[[i]], dia_test[[i]])
  
  # Calculate AUC for all &amp;quot;x&amp;quot; number of random splits
  roc_auc[[i]] &amp;lt;- roc(dia_test[[i]]$Outcome, p[[i]])$auc[1]
  glm_mean &amp;lt;- mean(unlist(roc_auc))
}
print(mean(unlist(roc_auc)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s calculate the average AUC of our model after different number of random splits.&lt;/p&gt;
&lt;p&gt;I will run my &lt;strong&gt;multi_split() function&lt;/strong&gt; 3x for 1, 30 and 1000 random train/test splits. I can then compare variances at each level of sampling.&lt;/p&gt;
&lt;p&gt;Here are the results from my multi_site function at each randomization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_1 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8769133&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_2 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8283688&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_3 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8216108&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_1 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.840713&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_2 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8501071&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_3 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8294741&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_1 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8362065&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_2 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8364364&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_3 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compare Variance levels at &lt;strong&gt;1, 30 and 1000&lt;/strong&gt; random splits&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_1_1, auc_1_2, auc_1_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0009101001&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_30_1, auc_30_2, auc_30_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0001067148&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_1000_1, auc_1000_2, auc_1000_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.672518e-07&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What we see here as we increase the number of iterations to 30 and 1000 the variability
gradually stabilizes around a trustable AUC of &lt;code&gt;0.836&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Seeing is believing. Let’s plot it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a data.frame containing accuracies
random_1X &amp;lt;- c(auc_1_1, auc_1_2, auc_1_3)
random_30X &amp;lt;- c(auc_30_1, auc_30_2, auc_30_3)
random_1000X &amp;lt;- c(auc_1000_1, auc_1000_2, auc_1000_3)

df_r &amp;lt;- data.frame(random_1X, random_30X, random_1000X)
df_r&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   random_1X random_30X random_1000X
## 1 0.8769133  0.8407130    0.8362065
## 2 0.8283688  0.8501071    0.8364364
## 3 0.8216108  0.8294741    0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Here, I will reformat my data for easy plotting by using gather() function from tidyr
# It takes multiple columns, and gathers them into key-value pairs: it makes “wide” data longer.
df_long &amp;lt;- gather(df_r, sampling, auc)
df_long&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       sampling       auc
## 1    random_1X 0.8769133
## 2    random_1X 0.8283688
## 3    random_1X 0.8216108
## 4   random_30X 0.8407130
## 5   random_30X 0.8501071
## 6   random_30X 0.8294741
## 7 random_1000X 0.8362065
## 8 random_1000X 0.8364364
## 9 random_1000X 0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_long$sampling &amp;lt;- factor(df_long$sampling, levels = c(&amp;quot;random_1X&amp;quot;, &amp;quot;random_30X&amp;quot;, &amp;quot;random_1000X&amp;quot;))

# 
model_variation &amp;lt;- ggplot(df_long, aes(y=auc, x=sampling, fill=sampling)) + geom_boxplot() + theme(text = element_text(size=15), axis.title.x=element_blank(), legend.position = &amp;quot;none&amp;quot;) + ggtitle(&amp;quot;Variation in model performance&amp;quot;)
model_variation&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/change%20in%20variance%20plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Great. We have an estimate of our model performance after 1000 random train/test splits. This process is also called &lt;strong&gt;Monte-Carlo Cross validation.&lt;/strong&gt; This approach might give you a less variable, but more biased estimate.&lt;/p&gt;
&lt;p&gt;A more common approach to estimate model performance is &lt;strong&gt;k-Fold cross Validation.&lt;/strong&gt; Where the samples divided into k-folds and one fold is used as a test set, and the remaining k-1 as the training set. This process is run k times until all folds appear once in the test sample.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;logistic-regression-model-with-k-fold-cross-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression model with k-fold Cross Validation&lt;/h2&gt;
&lt;p&gt;I will switch here to caret package. With the &lt;strong&gt;Train()&lt;/strong&gt; function we can test different types of machine learning algorithms and set the cross validation parameters.&lt;/p&gt;
&lt;p&gt;To make the models below comparable I will create &lt;strong&gt;a custom cross validation fold object (d_folds)&lt;/strong&gt; that I can apply to multiple models.&lt;/p&gt;
&lt;p&gt;I will repeat the logistic regression model with 5 fold cross validation and then we can compare it to monte carlo cross validation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Convert Outcome to a factor with two levels
diabetes$Outcome &amp;lt;- ifelse(diabetes$Outcome == 1, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;)
outcome &amp;lt;- diabetes$Outcome
d_folds &amp;lt;- createFolds(outcome, k=5)

# Create a dataframe without the outcome column
diab &amp;lt;- diabetes[,-9]

# MyControl
myControl &amp;lt;- trainControl(
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    verboseIter = TRUE,
    savePredictions = TRUE,
    index = d_folds
)
# Model_glm
model_glm &amp;lt;- train(x = diab, y = outcome,
                   metric = &amp;quot;ROC&amp;quot;,
                   method = &amp;quot;glm&amp;quot;,
                   trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## + Fold1: parameter=none 
## - Fold1: parameter=none 
## + Fold2: parameter=none 
## - Fold2: parameter=none 
## + Fold3: parameter=none 
## - Fold3: parameter=none 
## + Fold4: parameter=none 
## - Fold4: parameter=none 
## + Fold5: parameter=none 
## - Fold5: parameter=none 
## Aggregating results
## Fitting final model on full training set&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_glm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Generalized Linear Model 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;No&amp;#39;, &amp;#39;Yes&amp;#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (5 reps) 
## Summary of sample sizes: 154, 153, 153, 154, 154 
## Resampling results:
## 
##   ROC        Sens   Spec    
##   0.8136093  0.844  0.577431&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, My model performance is &lt;code&gt;0.8136093&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;glmnet-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Glmnet model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Model
model_glmnet &amp;lt;- train(x = diab, y = outcome,
                   metric = &amp;quot;ROC&amp;quot;,
                   method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(
                          alpha = 0:1,
                          lambda = seq(0.0001, 1, length = 20)
                      ),
                   trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_glmnet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## glmnet 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;No&amp;#39;, &amp;#39;Yes&amp;#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (5 reps) 
## Summary of sample sizes: 154, 153, 153, 154, 154 
## Resampling results across tuning parameters:
## 
##   alpha  lambda      ROC        Sens    Spec       
##   0      0.00010000  0.8201210  0.8615  0.554096935
##   0      0.05272632  0.8227469  0.8725  0.541977831
##   0      0.10535263  0.8239613  0.8880  0.506537709
##   0      0.15797895  0.8242214  0.9005  0.482290806
##   0      0.21060526  0.8240544  0.9115  0.444025212
##   0      0.26323158  0.8238034  0.9210  0.420725929
##   0      0.31585789  0.8233937  0.9290  0.395548794
##   0      0.36848421  0.8230260  0.9365  0.357313627
##   0      0.42111053  0.8228119  0.9430  0.331201913
##   0      0.47373684  0.8224972  0.9505  0.306955010
##   0      0.52636316  0.8222639  0.9575  0.276166051
##   0      0.57898947  0.8220894  0.9615  0.254705499
##   0      0.63161579  0.8219008  0.9670  0.238852423
##   0      0.68424211  0.8217353  0.9690  0.217396218
##   0      0.73686842  0.8215489  0.9705  0.200604216
##   0      0.78949474  0.8214394  0.9725  0.178235166
##   0      0.84212105  0.8212995  0.9755  0.157704847
##   0      0.89474737  0.8210990  0.9785  0.138109107
##   0      0.94737368  0.8209896  0.9800  0.125976962
##   0      1.00000000  0.8208614  0.9805  0.111980004
##   1      0.00010000  0.8141708  0.8450  0.575553141
##   1      0.05272632  0.8232373  0.9040  0.505646599
##   1      0.10535263  0.8064789  0.9490  0.348028689
##   1      0.15797895  0.7982626  0.9865  0.118687242
##   1      0.21060526  0.7913587  0.9995  0.002803738
##   1      0.26323158  0.5552114  1.0000  0.000000000
##   1      0.31585789  0.5000000  1.0000  0.000000000
##   1      0.36848421  0.5000000  1.0000  0.000000000
##   1      0.42111053  0.5000000  1.0000  0.000000000
##   1      0.47373684  0.5000000  1.0000  0.000000000
##   1      0.52636316  0.5000000  1.0000  0.000000000
##   1      0.57898947  0.5000000  1.0000  0.000000000
##   1      0.63161579  0.5000000  1.0000  0.000000000
##   1      0.68424211  0.5000000  1.0000  0.000000000
##   1      0.73686842  0.5000000  1.0000  0.000000000
##   1      0.78949474  0.5000000  1.0000  0.000000000
##   1      0.84212105  0.5000000  1.0000  0.000000000
##   1      0.89474737  0.5000000  1.0000  0.000000000
##   1      0.94737368  0.5000000  1.0000  0.000000000
##   1      1.00000000  0.5000000  1.0000  0.000000000
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were alpha = 0 and lambda = 0.1579789.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model_glmnet)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/print%20Glmnet%20model-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we see in the plot, ridge regression (alpha = 0) performed better than the lasso at all lambda values.&lt;/p&gt;
&lt;p&gt;Glmnet model performance is &lt;code&gt;0.8242214&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random-forest-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random forest model&lt;/h2&gt;
&lt;p&gt;One of the big diferences between random forest and linear models is that they require “tuning.”&lt;/p&gt;
&lt;p&gt;Hyperparameters –&amp;gt; How the model is fit. Selected by hand.&lt;/p&gt;
&lt;p&gt;advantages: no need to log transform or normalize,
but they are less interpretable and slower than glmnet.&lt;/p&gt;
&lt;p&gt;Random forests &lt;strong&gt;capture threshold effects and variable interactions. both of which occur often in real world data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mtry&lt;/strong&gt; is the number of variables used at each split point in individual decision tree that make up the rf. Default is 3, I will use here 8.&lt;/p&gt;
&lt;p&gt;tuneLength = how many different mtry values to be tested.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Random forest model
model_rf &amp;lt;- train(x = diab, y = outcome,
                   tuneLength = 8,
                   metric = &amp;quot;ROC&amp;quot;,
                   method = &amp;quot;ranger&amp;quot;,
                   trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_rf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Random Forest 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;No&amp;#39;, &amp;#39;Yes&amp;#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (5 reps) 
## Summary of sample sizes: 154, 153, 153, 154, 154 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   ROC        Sens    Spec     
##   2     gini        0.8155919  0.8565  0.5410389
##   2     extratrees  0.8247223  0.8730  0.5419474
##   3     gini        0.8142703  0.8490  0.5596827
##   3     extratrees  0.8241664  0.8650  0.5550185
##   4     gini        0.8098886  0.8440  0.5559617
##   4     extratrees  0.8244122  0.8595  0.5671376
##   5     gini        0.8096393  0.8475  0.5596914
##   5     extratrees  0.8244900  0.8550  0.5708498
##   6     gini        0.8075402  0.8460  0.5578309
##   6     extratrees  0.8231397  0.8530  0.5755401
##   7     gini        0.8063892  0.8415  0.5662117
##   7     extratrees  0.8213101  0.8515  0.5652728
##   8     gini        0.8058247  0.8335  0.5717931
##   8     extratrees  0.8209827  0.8485  0.5773788
## 
## Tuning parameter &amp;#39;min.node.size&amp;#39; was held constant at a value of 1
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 2, splitrule =
##  extratrees and min.node.size = 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Random forest performance is &lt;code&gt;0.8247223&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gradient-boost-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gradient boost model&lt;/h2&gt;
&lt;p&gt;I will define manualy a grid to test hyperparameter values wider than set in default.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid &amp;lt;- expand.grid(interaction.depth = c(1, 2, 3, 4, 5),
                 n.trees = (1:20)*50,  shrinkage = 0.01,
             n.minobsinnode = 10)
model_gbm &amp;lt;- train(x = diab, y = outcome,
                   metric = &amp;quot;ROC&amp;quot;,
                   method = &amp;quot;gbm&amp;quot;,
                   tuneGrid = grid,
                   trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_gbm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Stochastic Gradient Boosting 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;No&amp;#39;, &amp;#39;Yes&amp;#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (5 reps) 
## Summary of sample sizes: 154, 153, 153, 154, 154 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  ROC        Sens    Spec      
##   1                    50     0.7996312  0.9850  0.09252336
##   1                   100     0.8103617  0.9505  0.32756357
##   1                   150     0.8153748  0.9275  0.42350793
##   1                   200     0.8180549  0.9100  0.48598131
##   1                   250     0.8213254  0.8965  0.51863943
##   1                   300     0.8221740  0.8860  0.52983699
##   1                   350     0.8210830  0.8815  0.53729189
##   1                   400     0.8218884  0.8740  0.55409694
##   1                   450     0.8222721  0.8680  0.55874375
##   1                   500     0.8212831  0.8625  0.55593567
##   1                   550     0.8222189  0.8595  0.56525973
##   1                   600     0.8210507  0.8540  0.56620300
##   1                   650     0.8206810  0.8510  0.56806781
##   1                   700     0.8197731  0.8495  0.56806781
##   1                   750     0.8194073  0.8495  0.57180178
##   1                   800     0.8179990  0.8460  0.57459683
##   1                   850     0.8173591  0.8435  0.57459683
##   1                   900     0.8167653  0.8400  0.57272332
##   1                   950     0.8159870  0.8395  0.57366225
##   1                  1000     0.8155800  0.8375  0.57738752
##   2                    50     0.8097645  0.9705  0.19896110
##   2                   100     0.8153114  0.9225  0.42633341
##   2                   150     0.8182821  0.9040  0.47947837
##   2                   200     0.8214800  0.8910  0.51491415
##   2                   250     0.8209545  0.8780  0.53262769
##   2                   300     0.8209278  0.8655  0.54569007
##   2                   350     0.8203395  0.8595  0.55967398
##   2                   400     0.8193341  0.8560  0.56620735
##   2                   450     0.8187081  0.8520  0.57274071
##   2                   500     0.8177495  0.8475  0.58300369
##   2                   550     0.8172341  0.8470  0.58206912
##   2                   600     0.8160518  0.8430  0.58579005
##   2                   650     0.8150557  0.8335  0.58580309
##   2                   700     0.8142389  0.8285  0.58765486
##   2                   750     0.8129551  0.8265  0.59045860
##   2                   800     0.8114235  0.8235  0.58859378
##   2                   850     0.8106544  0.8230  0.58951967
##   2                   900     0.8098655  0.8225  0.58952402
##   2                   950     0.8089927  0.8195  0.59231471
##   2                  1000     0.8085903  0.8185  0.59044990
##   3                    50     0.8124471  0.9675  0.23434471
##   3                   100     0.8166505  0.9160  0.43008042
##   3                   150     0.8183159  0.8875  0.50374701
##   3                   200     0.8170682  0.8700  0.52424690
##   3                   250     0.8167332  0.8610  0.54665942
##   3                   300     0.8170788  0.8535  0.55690067
##   3                   350     0.8155400  0.8470  0.57181917
##   3                   400     0.8140688  0.8410  0.57181482
##   3                   450     0.8124477  0.8355  0.57367529
##   3                   500     0.8114718  0.8325  0.57367963
##   3                   550     0.8100906  0.8275  0.57740926
##   3                   600     0.8092354  0.8230  0.58113888
##   3                   650     0.8082420  0.8220  0.58859813
##   3                   700     0.8065477  0.8190  0.58766355
##   3                   750     0.8062263  0.8160  0.58858944
##   3                   800     0.8044913  0.8130  0.58765486
##   3                   850     0.8029262  0.8125  0.58765486
##   3                   900     0.8020108  0.8110  0.58858944
##   3                   950     0.8016405  0.8105  0.59045860
##   3                  1000     0.8011373  0.8090  0.59232775
##   4                    50     0.8139509  0.9640  0.24734188
##   4                   100     0.8150242  0.9120  0.43657900
##   4                   150     0.8179537  0.8850  0.49533145
##   4                   200     0.8176002  0.8710  0.53356227
##   4                   250     0.8162216  0.8615  0.55220170
##   4                   300     0.8159643  0.8490  0.56901543
##   4                   350     0.8141087  0.8445  0.57553141
##   4                   400     0.8131285  0.8430  0.57832645
##   4                   450     0.8114524  0.8385  0.58020430
##   4                   500     0.8104583  0.8335  0.58671158
##   4                   550     0.8089872  0.8265  0.58764182
##   4                   600     0.8078067  0.8240  0.59137144
##   4                   650     0.8064856  0.8230  0.59418387
##   4                   700     0.8051274  0.8200  0.59044121
##   4                   750     0.8038530  0.8205  0.59324495
##   4                   800     0.8030680  0.8205  0.59699196
##   4                   850     0.8023061  0.8190  0.59793088
##   4                   900     0.8011695  0.8185  0.59606607
##   4                   950     0.8000060  0.8160  0.59326668
##   4                  1000     0.7988982  0.8140  0.59045860
##   5                    50     0.8124004  0.9640  0.23430124
##   5                   100     0.8128960  0.9085  0.43658770
##   5                   150     0.8164498  0.8875  0.50560313
##   5                   200     0.8159795  0.8755  0.53263638
##   5                   250     0.8154252  0.8595  0.55782221
##   5                   300     0.8146149  0.8500  0.56622473
##   5                   350     0.8132774  0.8420  0.57460987
##   5                   400     0.8123588  0.8405  0.58207781
##   5                   450     0.8111443  0.8355  0.58207781
##   5                   500     0.8090119  0.8295  0.58767225
##   5                   550     0.8078390  0.8255  0.58488589
##   5                   600     0.8068005  0.8255  0.58954575
##   5                   650     0.8047019  0.8230  0.59045425
##   5                   700     0.8033723  0.8215  0.59231906
##   5                   750     0.8024794  0.8210  0.58951967
##   5                   800     0.8019000  0.8190  0.59232341
##   5                   850     0.8006418  0.8185  0.59512715
##   5                   900     0.7998935  0.8170  0.59605303
##   5                   950     0.7984835  0.8170  0.59698326
##   5                  1000     0.7970453  0.8165  0.59418822
## 
## Tuning parameter &amp;#39;shrinkage&amp;#39; was held constant at a value of 0.01
## 
## Tuning parameter &amp;#39;n.minobsinnode&amp;#39; was held constant at a value of 10
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 450,
##  interaction.depth = 1, shrinkage = 0.01 and n.minobsinnode = 10.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gradient boost model performance is &lt;code&gt;0.8222721&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-bayes-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Naive Bayes model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_nb &amp;lt;- train(x = diab, y = outcome,
                   metric = &amp;quot;ROC&amp;quot;,
                   method = &amp;quot;nb&amp;quot;,
                   trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_nb&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Naive Bayes 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;No&amp;#39;, &amp;#39;Yes&amp;#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (5 reps) 
## Summary of sample sizes: 154, 153, 153, 154, 154 
## Resampling results across tuning parameters:
## 
##   usekernel  ROC        Sens    Spec     
##   FALSE      0.8029047  0.8280  0.5801608
##    TRUE      0.7895701  0.8145  0.5745447
## 
## Tuning parameter &amp;#39;fL&amp;#39; was held constant at a value of 0
## Tuning
##  parameter &amp;#39;adjust&amp;#39; was held constant at a value of 1
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were fL = 0, usekernel = FALSE
##  and adjust = 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Naive Bayes model performance is &lt;code&gt;0.8029047&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- c(&amp;quot;glm&amp;quot;, &amp;quot;glmnet&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;gbm&amp;quot;, &amp;quot;naive&amp;quot;)
glm &amp;lt;- max(model_glm$results$ROC)
glmnet &amp;lt;- max(model_glmnet$results$ROC)
rf &amp;lt;- max(model_rf$results$ROC)
gbm &amp;lt;- max(model_gbm$results$ROC)
naive &amp;lt;- max(model_nb$results$ROC)
AUC &amp;lt;- c(glm, glmnet, rf, gbm, naive)
df &amp;lt;- data.frame(models, AUC)
df&amp;lt;- df[order(df[,2], decreasing=TRUE), ]
knitr::kable(df)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;models&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AUC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;rf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8247223&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glmnet&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8242214&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;gbm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8222721&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8136093&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;naive&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8029047&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here, we found &lt;code&gt;rf&lt;/code&gt; model performed the best, and also there are not big differences between the models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Future thoughts&lt;/h2&gt;
&lt;p&gt;I used different machine learning algorithms to predict Diabetes. Models showed similar performances except the naives bayes which performed worst. &lt;strong&gt;As we saw, our simple glm model performance was very close to other more advanced algorithms.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can help doctors to predict &lt;strong&gt;Diabetes with accuracy around 83%&lt;/strong&gt; by using 8 simple medical parameters.&lt;/p&gt;
&lt;p&gt;Given current speed in generation and collection of types data by including additional predictors we can build even better models.&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Start blogging in 5 minutes on Netlify with Hugo and blogdown (September 2019 Update)</title>
      <link>/r/deploy-your-blog-in-5-minutes/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/r/deploy-your-blog-in-5-minutes/</guid>
      <description>


&lt;p&gt;This guide will help you to get your website online in a few minutes. Then, customize and add your own material in RStudio environment, push it to your Github repository and benefit from the continuous deployment feature of Netlify.
It took me many days of work, reading tens of blog posts, YouTube videos and a lot of testing to figure out all of this.&lt;/p&gt;
&lt;p&gt;Here is an up to date workflow of &lt;strong&gt;how I created my Blog on Github and deployed at Netlify.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;tools-we-need&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tools we need;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RStudio&lt;/li&gt;
&lt;li&gt;Hugo&lt;/li&gt;
&lt;li&gt;Blogdown&lt;/li&gt;
&lt;li&gt;Git&lt;/li&gt;
&lt;li&gt;Github&lt;/li&gt;
&lt;li&gt;Netlify&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hugo is the actual website builder and &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; is an R package that allows us to use Hugo in R environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;on-rstudio-build-your-website-locally.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On RStudio: Build your website locally.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Select &lt;strong&gt;File&lt;/strong&gt; menu&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Select &lt;strong&gt;New Project -&amp;gt; New Directory -&amp;gt; Website using blogdown&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, to create a new site with the academic theme replace default lithium &lt;code&gt;Hugo theme&lt;/code&gt; with &lt;strong&gt;gcushen/hugo-academic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For other themes go to &lt;a href=&#34;http://themes.gohugo.io&#34; class=&#34;uri&#34;&gt;http://themes.gohugo.io&lt;/a&gt;, choose a theme you like, click homepage and you will be redirected to its github repository.&lt;br /&gt;
Replace its &lt;strong&gt;repository name&lt;/strong&gt; with “&lt;strong&gt;gcushen/hugo-academic&lt;/strong&gt;” above)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;command will create the website and it should be visible on the viewer pane.&lt;/p&gt;
&lt;p&gt;Use &lt;strong&gt;list.files()&lt;/strong&gt; to see the files/folders generated.&lt;/p&gt;
&lt;div id=&#34;prepare-for-github-compatibility&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prepare for GitHub compatibility&lt;/h4&gt;
&lt;p&gt;To be able to publish the website on github we need to specify a &lt;strong&gt;docs&lt;/strong&gt; folder instead of the default public folder where the website is created.&lt;/p&gt;
&lt;p&gt;Open your &lt;strong&gt;config.toml&lt;/strong&gt; file under the Website folder, and add the lines; &lt;a id=&#34;editconfig&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;baseurl: &#34;https://yourusername.github.io/page/&#34;&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;publishDir = &#34;docs&#34;&lt;/code&gt;
&lt;img src=&#34;/img/configtoml.jpg&#34; alt=&#34;configtoml&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Save the config file. This will rebuild the site and create the docs folder.
Now you can go back to your folder and delete the public directory.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;on-github-account&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On Github account&lt;/h3&gt;
&lt;div id=&#34;create-a-new-repository&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create a new repository&lt;/h4&gt;
&lt;p&gt;Log in to your Github account and create a new repository.
Here I called it &lt;code&gt;page.&lt;/code&gt;
Then your remote repository will be at&lt;br /&gt;
&lt;a href=&#34;https://github.com/yourusername/page.git&#34; class=&#34;uri&#34;&gt;https://github.com/yourusername/page.git&lt;/a&gt;
Copy that link.
&lt;img src=&#34;/img/git.png&#34; alt=&#34;git&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;on-git&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On Git&lt;/h3&gt;
&lt;div id=&#34;create-your-local-.git-repository&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create your local .git repository&lt;/h4&gt;
&lt;p&gt;By using pwd and cd commands navigate your directory to the Website folder&lt;/p&gt;
&lt;p&gt;Initialize your local repository&lt;br /&gt;
&lt;code&gt;git init&lt;/code&gt;&lt;br /&gt;
Use the copied link from above&lt;br /&gt;
&lt;code&gt;git remote add origin https://github.com/yourusername/page.git&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git add .&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git commit -m createmywebsite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Following command will synchronize all your files to your Github repository&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;publishing-your-website-on-github-pages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Publishing your website on Github pages&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In your Github repository. Go to settings&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Scroll down to Github pages, choose source &amp;gt; &lt;strong&gt;master branch/docs&lt;/strong&gt; folder&lt;/li&gt;
&lt;li&gt;This will update the page. Scroll down to Github pages again click the link:&lt;br /&gt;
e.g. &lt;a href=&#34;https://yourusername.github.io/page/&#34; class=&#34;uri&#34;&gt;https://yourusername.github.io/page/&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Hoorray! In this step your website should be up and running on Github!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deploying-your-website-to-netlify&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Deploying your Website to Netlify&lt;/h3&gt;
&lt;p&gt;If you want to benefit from the advantages like continous deployment you can
use &lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Go to your &lt;strong&gt;Netlify&lt;/strong&gt;, Click &lt;code&gt;Get started for free&lt;/code&gt; and sign up with Github.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose &lt;strong&gt;New site from Git&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Choose &lt;strong&gt;GitHub&lt;/strong&gt; at the bottom&lt;/li&gt;
&lt;li&gt;Click on &lt;strong&gt;Configure the Netlify app on GitHub.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;On github select your target repository. Save.&lt;/li&gt;
&lt;li&gt;On Netlify pick up that repository.&lt;/li&gt;
&lt;li&gt;Modify Basic build settings: &lt;strong&gt;Publish directory&lt;/strong&gt; should be &lt;strong&gt;docs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Click on &lt;strong&gt;Show advanced&lt;/strong&gt; &amp;gt; New Variable&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Add a New Variable&lt;br /&gt;
Modify as Key = HUGO_VERSION and Value = 0.58.1&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;This step is important otherwise your site will not be built.&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you dont know your hugo version; on Rstudio &amp;gt; type&lt;/p&gt;
&lt;p&gt;&lt;code&gt;blogdown::hugo_version()&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;strong&gt;Deploy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It will allocate you a random link. You have to go back to your config.toml and modify baseurl as we did for Github &lt;a href=&#34;#editconfig&#34;&gt;above&lt;/a&gt; but with this netlify link.&lt;/p&gt;
&lt;p&gt;After this step you have to push changes to github from your local git. Similarly to the steps above without &lt;code&gt;git init&lt;/code&gt; this time.&lt;/p&gt;
&lt;p&gt;Netlify will detect those changes you pushed to your github repository and your site will be published in a few seconds.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hoorray! In this step your website should be up and running on Netlify!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-use-your-own-domain-name&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to use your own domain name&lt;/h3&gt;
&lt;div id=&#34;go-to-your-domain-provider-e.g-i-did-on-go-daddy&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Go to your domain provider e.g I did on Go Daddy&lt;/h4&gt;
&lt;p&gt;My Products &amp;gt; Scroll down to your domain &amp;gt; Click DNS&lt;/p&gt;
&lt;p&gt;Create new or modify if existing an A record pointing your root domain to Netlify load balancer’s IP address 104.198.14.52 as in below;
&lt;img src=&#34;/img/A_record.jpg&#34; alt=&#34;A_record&#34; /&gt;Add a CNAME file as here;
&lt;img src=&#34;/img/netlify_CNAME.jpg&#34; alt=&#34;netlify_CNAME&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;go-to-domain-settings-on-your-deploy-at-netlify&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Go to domain settings on your deploy at Netlify&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Add custom domain&lt;/li&gt;
&lt;li&gt;Fill in your domain name&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Click Verify &amp;gt; Yes, add domain &amp;gt; Verify DNS configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Voila, in this step your website should be online at www.yourdomain.com!!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
