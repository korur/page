<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ggplot2 | SERDAR KORUR</title>
    <link>/tags/ggplot2/</link>
      <atom:link href="/tags/ggplot2/index.xml" rel="self" type="application/rss+xml" />
    <description>ggplot2</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 28 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>ggplot2</title>
      <link>/tags/ggplot2/</link>
    </image>
    
    <item>
      <title>An intuitive real life example of a binomial distribution and how to simulate it in R: Learn it once, use it everyday</title>
      <link>/r/probability-distributions/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/probability-distributions/</guid>
      <description>


&lt;p&gt;Last week, I came across a data that I thought it is a great opportunity to write about Binomial probability distributions.&lt;/p&gt;
&lt;div id=&#34;what-is-a-binomial-distribution-and-why-we-need-to-know-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is a binomial distribution and why we need to know it?&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Binomial distributions&lt;/strong&gt; are formed when we repeat a set of events and each single event in a set has two possible outcomes. Bi- in binomial distributions refers to those outcomes. Two possibilities are usually described as &lt;strong&gt;Success&lt;/strong&gt; or &lt;strong&gt;no Success&lt;/strong&gt;. A “yes” or “no”.&lt;/p&gt;
&lt;p&gt;For example, in flipping coins, the two possibilities are getting a head (success) or tails (no success) or vice versa. And one set can be, e.g. 10 or 50 times coin flipping. We can repeat this set as many times as we like and record how many times we got heads (success) in each repetition.&lt;/p&gt;
&lt;div id=&#34;why-is-this-interesting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why is this interesting?&lt;/h2&gt;
&lt;p&gt;What is the probability of getting 25 heads out of 50 coin flips? This is not very unusual. &lt;strong&gt;But how about getting 49 heads out of 50 flips? Is this really possible?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s figure it out. We can repeat this set of 50 times coin flipping 100.000 times and record the results of each set.&lt;/p&gt;
&lt;p&gt;Luckily, we can simulate this in R.&lt;/p&gt;
&lt;p&gt;We can simulate a given number of repeated (here 100.000) sets (50 times of coin flipping) of experiments with &lt;strong&gt;rbinom()&lt;/strong&gt; function. It takes 3 arguments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;rbinom(&lt;/strong&gt;&lt;br /&gt;
n = number of repetitions = 100.000,&lt;br /&gt;
size = sample size = 50,&lt;br /&gt;
p = the probability of success (chance of throwing heads is 0.5)&lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s compare the probabilities of getting more than 25, 35 or even 49 heads. You can combine rbinom with mean function to find the percentage of the events with a chosen outcome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Probability of getting 25 or more heads
mean(rbinom(100000, 50, .5) &amp;gt;= 25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5555&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Probability of getting 35 or more heads
mean(rbinom(100000, 50, .5) &amp;gt;= 35)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0033&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Probability of getting 49 or more heads
mean(rbinom(100000, 50, .5) &amp;gt;= 49)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We found the probability of throwing 49 or more heads to be 0. But to be technically precise it is one in 375 trillion times
(= &lt;span class=&#34;math inline&#34;&gt;\(1/((1/(2^{49}) + (1/2^{50})))\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Let’s visualize our simulation. The bars in red represents the sets which had 35 or more heads.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
library(viridis)

heads &amp;lt;- rbinom(100000, 50, 0.5)
heads &amp;lt;- data.frame(heads)
heads &amp;lt;- heads %&amp;gt;% mutate(events = ifelse(heads &amp;gt; 35, &amp;quot;&amp;gt; 35&amp;quot;, &amp;quot;&amp;lt; 35&amp;quot;))
heads %&amp;gt;%  ggplot(aes(x=heads, fill = events)) + 
  geom_histogram(binwidth = 0.5) + 
  scale_fill_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;)) +
  theme_classic() +
  theme(text = element_text(size = 18),
        legend.position = c(0.85, 0.85)) +
  labs(x = &amp;quot;Number of heads in 50 coin flips&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/install%20packages-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even to get 35 or more heads has very low probability. Most of the events will be an integer between 15 and 35.&lt;/p&gt;
&lt;p&gt;Binomial probability distributions help us to understand the likelihood of such rare events.&lt;/p&gt;
&lt;p&gt;You can also see here a key difference of a binomial distribution with normal distribution is that they can take only discrete values. It is not possible to have 35.5 heads. Although, there are differences, &lt;strong&gt;when the sample size is large enough their shape will be similar and normal distributions can be used to estimate binomial probabilities&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So what are all those will be useful for?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Coin flipping expertise may have limited real life applications but let’s give some other examples.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Binomial distributions in machine learning&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You built a machine learning model with a binary outcome. Let’s say pathological image recognition algorithm for liver cancer that works with 90% accuracy. You tested 100 patients and you want to know your 95% confidence interval? Or your new results showed that your model detected less than 70 patients correctly. Is it possible? Or you should start optimizing your parameters again?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Number of patients responding to a treatment.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s say you have a new therapy for cancer which has 10% probability to cure a patient. You have 500 patients which took the drug. The expected number of recovering patients is 50. But you found that 75 patients responded. Is that due to chance or a significant effect? Or you should start looking underlying factors if there is something about the therapy or the patient group?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Think about a hospital emergency station.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You are a hospital manager and you want to organize the staff numbers correctly for different weekdays. You know total number of patients came in to a emergency station because of alcohol poisoning in a given time period. You can analyse the distribution of patient numbers for each day of the week. Most likely you will have more such cases in the weekend and you need larger staff.&lt;/p&gt;
&lt;p&gt;This will be also true for other businesses. They can use binomial distributions to calculate changes in demand and plan accordingly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If you are running a webserver.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can allocate your resources better by identifying times when traffic will be higher.&lt;/p&gt;
&lt;p&gt;Some other questions in which binomial distributions will come in handy are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Number of people who answered ‘yes’ to a survey question&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How many games a team will win in one season?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vote counts for a candidate in an election.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Number of defective products in a production run.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Binomial distributions are common and they have many applications of real life situations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s use some real life data to apply our knowledge so far. The data comes from TidyTuesday which I introduced in my last &lt;a href=&#34;https://dataatomic.com/r/tidytuesday-which-are-the-best-family-cars/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It contains information about Horror Movies released since 2012. And the question I asked was whether horror movies are more likely be released at the 13th each month?&lt;/p&gt;
&lt;p&gt;Being in &lt;strong&gt;the right mindset&lt;/strong&gt; for anything gives us a better feeling of it. &lt;strong&gt;If you go to the cinema at the 13th to watch a horror movie, do you like it more than other days?&lt;/strong&gt; We don’t know if this is true but movie makers might be counting on that. I analyzed Horror movies data and calculated number of releases in different days of the month. &lt;strong&gt;This is a good example of a binomial probability distribution.&lt;/strong&gt; Let’s look at the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;horror_movies &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv&amp;quot;)

dim(horror_movies)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3328   12&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(horror_movies)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 12
##   title genres release_date release_country movie_rating review_rating
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;
## 1 Gut ~ Drama~ 26-Oct-12    USA             &amp;lt;NA&amp;gt;                   3.9
## 2 The ~ Horror 13-Jan-17    USA             &amp;lt;NA&amp;gt;                  NA  
## 3 Slee~ Horror 21-Oct-17    Canada          &amp;lt;NA&amp;gt;                  NA  
## 4 Trea~ Comed~ 23-Apr-13    USA             NOT RATED              3.7
## 5 Infi~ Crime~ 10-Apr-15    USA             &amp;lt;NA&amp;gt;                   5.8
## 6 In E~ Horro~ 2017         UK              &amp;lt;NA&amp;gt;                  NA  
## # ... with 6 more variables: movie_run_time &amp;lt;chr&amp;gt;, plot &amp;lt;chr&amp;gt;, cast &amp;lt;chr&amp;gt;,
## #   language &amp;lt;chr&amp;gt;, filming_locations &amp;lt;chr&amp;gt;, budget &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I need some &lt;strong&gt;data pre-processing&lt;/strong&gt; before I can make my visualizations. Dates are given in &lt;code&gt;day:month:year&lt;/code&gt; format. I need to split them to individual columns. Also couple of movies do not have the day of the month. I will remove them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;horror_date &amp;lt;-  horror_movies %&amp;gt;% 
                separate(
                  release_date, 
                  c(&amp;quot;day&amp;quot;, &amp;quot;month&amp;quot;, &amp;quot;year&amp;quot;),
                  sep = &amp;quot;-&amp;quot;)

horror_date$day &amp;lt;- as.numeric(horror_date$day)

# Remove rows without Date of the month

horror_date &amp;lt;- horror_date %&amp;gt;% filter(day &amp;lt; 32) 

# I am excluding Day 1 from the analysis (Most aggreements starts at 1st)

horror_date_table &amp;lt;- horror_date %&amp;gt;% filter(day &amp;gt; 1)

# Let&amp;#39;s check what is the most common day in the month for a horror movie release
horror_date_table &amp;lt;-  horror_date_table %&amp;gt;%
  group_by(day) %&amp;gt;% 
  count() %&amp;gt;% 
  arrange(desc(n))
horror_date_table&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 2
## # Groups:   day [30]
##      day     n
##    &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
##  1    13   124
##  2    18   119
##  3    25   119
##  4    21   110
##  5    31   107
##  6    28   102
##  7    10   100
##  8    20   100
##  9     5    99
## 10     7    98
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s visualize the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Final
horror_date_table$day &amp;lt;- as.character(horror_date_table$day)

my_title &amp;lt;- &amp;quot;Highest number of Horror movies are released at the 13th&amp;quot;

p &amp;lt;- horror_date_table %&amp;gt;% 
    ungroup() %&amp;gt;% 
    mutate(day=fct_reorder(day, n, .desc=TRUE)) %&amp;gt;% 
    ggplot(aes(x=day, y=n)) +
    geom_col(aes(fill=n)) +
    scale_fill_viridis( direction =-1) + 
    theme(
      plot.title = element_text(size=24, color= &amp;quot;black&amp;quot;, hjust=0.5, vjust = -1),
      plot.subtitle = element_text(size=36, color= &amp;quot;red&amp;quot;, hjust=0.5, vjust = -1),
      panel.background = element_rect(fill = &amp;quot;white&amp;quot;), 
      plot.background = element_rect(fill = &amp;quot;white&amp;quot;),
      panel.grid = element_blank(),
      legend.position = &amp;quot;none&amp;quot;, 
      text = element_text(size=18), 
      axis.text.x =element_text(vjust=12, size=17, colour= &amp;quot;white&amp;quot;, face= &amp;quot;bold&amp;quot;),
      axis.title.x = element_text(vjust=9.5), 
      axis.text.y=element_blank(),
      axis.ticks= element_blank(), 
      plot.caption = element_text(hjust = 1, vjust = 10)) +
    labs(
          caption= &amp;quot;Source: IMDb, Plot: @dataatomic&amp;quot;,
          x = &amp;quot;Day of the Month&amp;quot;, 
          y = &amp;quot;Number of movies released&amp;quot;,
          title = my_title) +
    geom_label(aes(label = n), size=5, fill=&amp;quot;yellow&amp;quot;, alpha=0.9) 
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;is-this-significant&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Is this significant?&lt;/h1&gt;
&lt;p&gt;In the data, there were &lt;strong&gt;2782&lt;/strong&gt; movies associated with a release date. So expected movie release per day is &lt;strong&gt;92&lt;/strong&gt; (2782 / 30).&lt;/p&gt;
&lt;p&gt;But, we see above that some days are much higher than that. What we want to know is, which days are in the &lt;strong&gt;range of random chance&lt;/strong&gt; and which days there is a &lt;strong&gt;significant preference or an aversion&lt;/strong&gt; to release a movie. So that we can conclude our insight about movie makers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Size of our distribution is the total number of movies released 
n_value &amp;lt;- horror_date_table %&amp;gt;% ungroup() %&amp;gt;% summarize(n2 = sum(n))
size &amp;lt;- n_value$n2
size&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2782&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The probability (= success rate = a given outcome to occur = movie released)
p &amp;lt;-  1/30  # Since it can occur any of the 30 days in a months&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can simulate this 2782 movie release dates events 100.000 times with rbinom function and calculate the mean and variance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Simulated statistics
 
estimates &amp;lt;-  rbinom(100000, 2782, 1/30)

# Simulated mean
mean(estimates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 92.70875&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Simulated variance
var(estimates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 89.51934&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The average value is around 92 movies released in one day.&lt;/p&gt;
&lt;p&gt;We can also calculate theoretical values by the derived mathematical formulas that define the binomial function:&lt;/p&gt;
&lt;p&gt;Mean = size * p&lt;br /&gt;
Variance = size * p * (1 - p)&lt;/p&gt;
&lt;p&gt;Let’s calculate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Theoretical statistics

# Expected mean = size * p
mean_theoretical &amp;lt;- 2782 * 1/30
mean_theoretical&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 92.73333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Expected Variance = size * p * (1-p)
var_theoretical &amp;lt;- size * 1/30 * (1-1/30)
var_theoretical&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 89.64222&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, simulated and theoretical values are almost the same. So, I can use my simulations to find out 95% confidence interval which will contain the values that can happen due to random chance.&lt;/p&gt;
&lt;p&gt;I will define an interval that contains 95% of probabilities in our simulated distributions. And the values outside will be the ones which were not due to random chance. To do this I need 2.5th and 97.5th quantiles of the distribution.&lt;/p&gt;
&lt;p&gt;We can do this by the qbinom() function in r. For example qbinom(0.975, size, p) will return the value which will define the cut off which contains 0.975 of the probabilities. And our confidence interval will be the interval between:&lt;/p&gt;
&lt;p&gt;qbinom(0.025, size, p) &amp;lt; Confidence Interval &amp;lt; qbinom(0.975, size, p)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Boundaries for p values smaller than 0.05

lower &amp;lt;- qbinom(0.975, 2782, 1/30)
lower&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 112&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;upper &amp;lt;- qbinom(0.025, 2782, 1/30)
upper&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 75&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;movies &amp;lt;- rbinom(100000, 2782, 1/30)
movies &amp;lt;- data.frame(movies)
movies &amp;lt;- movies %&amp;gt;% mutate(events = ifelse(movies &amp;gt; qbinom(.025, 2782, 1/30) &amp;amp; movies &amp;lt;  qbinom(.975, 2782, 1/30), &amp;quot;95% Conf. Int.&amp;quot;, &amp;quot;significant&amp;quot;))
movies %&amp;gt;%  ggplot(aes(x=movies, fill = events)) + 
  geom_histogram(binwidth = 0.5) + 
  scale_fill_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;)) +
  theme_classic() +
  theme(text = element_text(size = 18),
        legend.position = c(0.85, 0.85)) +
  labs(x = &amp;quot;Number of movie releases in a day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;95% of the time, days in one month will have between 75 and 112 movie releases. Higher or lower values than this range can not happen due to random chance according to our binomial distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-calculate-the-p-value-for-a-binomial-test-using-pbinom&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to calculate the p-value for a binomial test using pbinom?&lt;/h1&gt;
&lt;p&gt;Our observed value for the 13th is 124. Above the 97.5th quantile. So it is significant. But what is the exact p value? Let’s define p value first.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    P value is the sum of the probability of that event plus the sum of the probabilities of similar events that are equally likely or less likely.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;For example in coin flipping, probability of heads is (0.5). If we follow our definition, p value is the sum of the probability of that event (0.5) and similar events which is equally or less likely i.e. tails (0.5). This makes our p value 0.5 + 0.5 = 1.&lt;/p&gt;
&lt;p&gt;Similarly, in our horror movie data this will be the sum of the probabilities of getting 124 movie releases or events that are equally probable or rarer.&lt;/p&gt;
&lt;p&gt;In R, &lt;strong&gt;pbinom&lt;/strong&gt; function defines the cumulative probabilities. For example, pbinom(124, 2782, 1/30) will give us the cumulative probabilities of any number of movie releases up to 124. By using 1-pbinom(124, 2782, 1/30) we can find the sum of the probabilities with equal or lower chance than having 124.&lt;/p&gt;
&lt;p&gt;Thus, p value for getting at least 124 movie release is;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Probability of getting 124 movie releases in a day like here it happened on the 13th. # Probability of getting at least 124 success

p_val_binom &amp;lt;- 2 * (1 - pbinom(124, 2782, 1/30))
p_val_binom&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.001335455&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We multiplied by two because same rare events can happen in the left side of our confidence interval as well.&lt;/p&gt;
&lt;p&gt;Let’s put those p values on our barplot to highlight the significant days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I will add a new column so I can separately define values outside the 95% confidence interval.

horror_date_table &amp;lt;- horror_date_table %&amp;gt;% 
                     mutate(p_val = 2 * (1 - pbinom(n, 2782, 1/30, 
                            lower.tail = ifelse(n&amp;gt;93, TRUE, FALSE)))) %&amp;gt;% 
                     mutate(p_val = cut(p_val, breaks = c(-Inf, 0.001, 0.01, 0.05, Inf), 
                                        labels = c(&amp;quot;&amp;lt; 0.001&amp;quot;,&amp;quot;&amp;lt; 0.01&amp;quot;, &amp;quot;&amp;lt; 0.05&amp;quot;, &amp;quot;NS&amp;quot;)))      

# Visualize the significant days 
p_ci &amp;lt;- horror_date_table %&amp;gt;% 
    ungroup() %&amp;gt;% 
    mutate(day=fct_reorder(day, n, .desc=TRUE)) %&amp;gt;% 
    ggplot(aes(x=day, y=n)) +
    geom_col(aes(fill=p_val)) +
    scale_fill_manual(values = viridis(4))  + 
    theme(
        plot.title = element_text(size=24, color= &amp;quot;black&amp;quot;, hjust=0.5, vjust = -1),
        plot.subtitle = element_text(size=36, color= &amp;quot;red&amp;quot;, hjust=0.5, vjust = -1),
        panel.background = element_rect(fill = &amp;quot;white&amp;quot;), 
        plot.background = element_rect(fill = &amp;quot;white&amp;quot;),
        panel.grid = element_blank(),
        text = element_text(size=18), 
        axis.text.x =element_text(vjust=12, size=17, colour= &amp;quot;white&amp;quot;, face= &amp;quot;bold&amp;quot;),
        axis.title.x = element_text(vjust=9.5), 
        axis.text.y=element_blank(),
        axis.ticks= element_blank(), 
        plot.caption = element_text(hjust = 1, vjust = 10)) +
    labs(
        caption= &amp;quot;&amp;quot;,
        x = &amp;quot;Day of the Month&amp;quot;, 
        y = &amp;quot;Number of movies released&amp;quot;,
        title = &amp;quot;Calculating p values in binomial distributions&amp;quot;) +
    geom_label(aes(label = n), size=5, fill=&amp;quot;yellow&amp;quot;, alpha=0.9) 
p_ci&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/6-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We performed a hypothesis testing by calculating the p value by using the pbinom() function and found couple of other days where movies are more or less likely to be released.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;However, another widely used way to do so is to calculate the mean (the expected probability) of our distribution and its standard deviation and to verify how many standard deviations the observed value is away from the mean (the z score).&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;calculating-the-p-value-by-normal-approximation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculating the p-value by normal approximation&lt;/h3&gt;
&lt;p&gt;When the sample size is large, binomial distributions can be approximated by a normal distribution. To build the normal distribution, I need mean and standard deviation. I can calculate this from the horror movie data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_mean &amp;lt;- horror_date_table %&amp;gt;% ungroup() %&amp;gt;% summarise(n=mean(n))
sample_mean&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       n
##   &amp;lt;dbl&amp;gt;
## 1  92.7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- 1/30

sample_variance &amp;lt;-  2782 * p * (1-p)
sample_variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 89.64222&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_sd &amp;lt;- sqrt(sample_variance)
sample_sd&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9.467958&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can calculate the z-score for our observation of 124 movies that are released on the 13th. &lt;strong&gt;Simply, z-score is: how many standard deviations an observation is away from the mean.&lt;/strong&gt; Since 95% of the observations will fall within 1.96 standard deviations from the mean in a normal distribution, a higher z-score will show that our p value is indeed significant.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate z-score for observation 13th of the month = 124 movies are 
# released
observation &amp;lt;- 124
z_score &amp;lt;- (observation - sample_mean) / sample_sd
z_score&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          n
## 1 3.302367&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can calculate the exact p value by using a normal distribution function pnorm() and the z score we found.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate the p-value of observing 124 or more movie releases in a day

p_val_nor &amp;lt;- 2 * pnorm(3.302, lower.tail = FALSE)
p_val_nor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0009599807&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, I found similar values (Normal: &lt;strong&gt;0.00095&lt;/strong&gt;, Binomial: &lt;strong&gt;0.00133&lt;/strong&gt;) by using an approximation of a normal distribution and by using binomial distributions. Both methods proves that Horror movies are more likely to be released at the 13th.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;future-thoughts-conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Future thoughts / Conclusions&lt;/h1&gt;
&lt;p&gt;Many events in real life can be explained by binomial probability distributions, and they allow us to calculate whether or not the events happened due to random chance and test our hypotheses.&lt;/p&gt;
&lt;p&gt;It can be a fun data analysis such as in horror movies, or more serious subjects like testing of new medicines or predicting accuracy of machine learning algorithms detecting diseases.&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>#TidyTuesday: Which are the best family cars for your weekend trip?</title>
      <link>/r/tidytuesday-which-are-the-best-family-cars/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/tidytuesday-which-are-the-best-family-cars/</guid>
      <description>


&lt;p&gt;This week, I will analyze Car Fuel Economy &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-10-15&#34;&gt;dataset&lt;/a&gt; from TidyTuesday.&lt;/p&gt;
&lt;div id=&#34;what-is-tidytuesday&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is TidyTuesday?&lt;/h2&gt;
&lt;p&gt;TidyTuesday is a weekly social data project in R organized by the &lt;a href=&#34;https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/&#34;&gt;R for Data Science community&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is a great way of improving your Data wrangling and visualization techniques, &lt;strong&gt;sharing and learning from others&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can find more information on their &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fuel economy &lt;a href=&#34;https://www.fueleconomy.gov/feg/download.shtml&#34;&gt;data&lt;/a&gt; are the result of the work done by the US Environmental Protection Agency. Full data dictionary can be found at &lt;a href=&#34;https://www.fueleconomy.gov/feg/ws/index.shtml#fuelType1&#34;&gt;fueleconomy.gov&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The data contains 83 parameters of more than 40.000 Vehicles. That’s a lot of information!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;going-for-your-next-family-camping-adventure-first-check-your-car-model.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Going for your next family camping adventure? First, check your car model.&lt;/h1&gt;
&lt;p&gt;Better Fuel economy and recent developments on longer running electric car batteries are great. But one thing which does not change in families’ lives is the &lt;strong&gt;need for space&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you don’t want crying kids running around because of &lt;strong&gt;a missing teddy bear&lt;/strong&gt; which did not fit in the baggage. Check, which brands will serve you best.&lt;/p&gt;
&lt;p&gt;Especially, if you have a daughter who likes to travel with a lot of toys.&lt;img src=&#34;/img/raisa.jpg&#34; alt=&#34;raisa.jpg&#34; /&gt;&lt;br /&gt;
Let’s figure out a solution for peaceful weekend trip.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;which-brand-produce-most-family-friendly-cars-in-terms-of-baggage-volume.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Which brand produce most family friendly cars? In terms of baggage volume.&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
big_epa_cars &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv&amp;quot;)
dim(big_epa_cars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 41804    83&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will subset my data for easier computation.&lt;/p&gt;
&lt;p&gt;Let’s keep the following columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;year - model year&lt;/li&gt;
&lt;li&gt;make - manufacturer (division)&lt;/li&gt;
&lt;li&gt;model - model name (carline)&lt;/li&gt;
&lt;li&gt;VClass - EPA vehicle size class&lt;/li&gt;
&lt;li&gt;hlv - hatchback luggage volume (cubic feet)&lt;/li&gt;
&lt;li&gt;hpv - hatchback passenger volume (cubic feet)&lt;/li&gt;
&lt;li&gt;displ - engine displacement in liters&lt;/li&gt;
&lt;li&gt;lv4 - 4 door luggage volume (cubic feet)&lt;/li&gt;
&lt;li&gt;pv4 - 4-door passenger volume&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;big_sub &amp;lt;- big_epa_cars %&amp;gt;% 
  select(fuelType, year, make, model, VClass, hlv, hpv,lv4,pv4,displ)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will start exploring the data. For the moment, first I will focus on &lt;strong&gt;Midsize cars&lt;/strong&gt; (VClass).&lt;/p&gt;
&lt;p&gt;I will filter for the main pool of Midsize cars with 4 door and luggage volume of bigger than 6 and passenger volume larger than 75.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posn.j &amp;lt;- position_jitter(width=0.2)
big_sw &amp;lt;- big_sub %&amp;gt;% 
  filter(VClass == &amp;quot;Midsize Cars&amp;quot; &amp;amp; pv4 &amp;gt; 75 &amp;amp; lv4 &amp;gt; 6) 

big_sw %&amp;gt;%
  ggplot(aes(x=pv4, y=lv4)) + 
  geom_point(shape=21,
             alpha=0.4,size =3, 
             position = posn.j) + 
  theme(plot.caption=element_text(size=11), 
        text = element_text(size=18),
        plot.title = element_text(size=32), 
        legend.position = &amp;quot;none&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, color =&amp;quot;red&amp;quot;) + 
  coord_fixed() +
    labs(x = &amp;quot;Passenger Vol (Cubic feet)&amp;quot;, 
         y = &amp;quot;Luggage Vol (Cubic feet)&amp;quot;, 
         title = 
    &amp;quot;Luggage space negatively \ncorrelates with passenger space&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is not unexpected. But good to see.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Insight 1: Negative correlation suggests that producers sacrifice passenger space to produce bigger room for the luggage or vice versa.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;First, I will look at the luggage volume in Mid sized cars and I will order them according to highest average.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pp &amp;lt;- big_sw %&amp;gt;% 
  mutate(make = fct_reorder(make, lv4)) %&amp;gt;%
  ggplot(aes(x=make, y=lv4, col=make)) + 
  geom_boxplot(varwidth=TRUE) +
  theme(plot.caption=element_text(size=11), 
        text = element_text(size=18),    
        plot.title = element_text(size=32), 
        legend.position = &amp;quot;none&amp;quot;) +
  coord_flip() + 
  labs(x = element_blank(), 
       y = &amp;quot;Luggage size (cubic feet)&amp;quot;, 
       title = &amp;quot;Average luggage volumes in Midsized cars&amp;quot;)
  pp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you follow the mean lines from bottom to top, you will see that cars cluster into three groups according to their mean of luggage sizes. But differences are not huge.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Insight 2: Cars cluster into three groups according to their mean luggage size.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s focus. I am looking for the car with the biggest luggage space. Let’s see what other VClass types are in our dataset that we can include our exploration.&lt;/p&gt;
&lt;p&gt;There are 34 types of vehicle classes (Vlass) in our dataset. I will subset all the relevant ones, leaving some specialty vehicles and vans aside.&lt;/p&gt;
&lt;p&gt;You can have a look at other VClass types with this code here.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;big_epa_cars %&amp;gt;% group_by(VClass) %&amp;gt;% count() %&amp;gt;% arrange(desc(n))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I will also remove minor brands with less than 10 models in total.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;big_filtered &amp;lt;- big_sub %&amp;gt;% 
  filter(VClass %in% c(&amp;quot;Large Cars&amp;quot;, &amp;quot;Compact Cars&amp;quot;, &amp;quot;Midsize Cars&amp;quot;, 
                       &amp;quot;Midsize Station Wagons&amp;quot;, &amp;quot;Midsize-Large Station Wagons&amp;quot;,
                       &amp;quot;Minivan - 2WD&amp;quot;, &amp;quot;Minivan - 4WD&amp;quot;)) %&amp;gt;% 
  group_by(make) %&amp;gt;% 
  mutate(n=n()) %&amp;gt;% 
  filter(n &amp;gt; 10) %&amp;gt;% 
  ungroup()

dim(big_filtered)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 14710    11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To be on the safe side for the family trip, I will choose cars not older than 5 years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Cars ordered with luggage volume, but not older than 5 years 
# and lv4 bigger than 5

q &amp;lt;- big_filtered %&amp;gt;% 
  filter(year &amp;gt; 2016, lv4 &amp;gt; 5) %&amp;gt;%
  mutate(make = fct_reorder(make, lv4)) %&amp;gt;%
  ggplot(aes(x=make, y=lv4, col=make)) + 
  geom_boxplot(varwidth=TRUE) +
  theme(text = element_text(size=15),
        legend.position = &amp;quot;none&amp;quot;) +
  coord_flip()
q&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are not big differences between average luggage size of different brands. Although, you will probably get more space if you choose a Volkswagen or Ford rather than a BMW or Chevrolet.&lt;/p&gt;
&lt;p&gt;The real XL luggage volume cars are plenty and seem to be more outlier models. To find our dream car let’s focus on those outliers.&lt;/p&gt;
&lt;p&gt;I will create a new data frame &lt;strong&gt;boot_space&lt;/strong&gt; containing the top 50 cars according to the luggage volume.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_space &amp;lt;- big_filtered %&amp;gt;% 
  filter(year &amp;gt; 2016) %&amp;gt;% 
  arrange(desc(lv4)) %&amp;gt;% 
  top_n(50, lv4)

# Top family cars - geom_point()
bs &amp;lt;- boot_space %&amp;gt;% 
  mutate(model = fct_reorder(model, lv4)) %&amp;gt;%
  mutate(make = fct_reorder(make, lv4)) %&amp;gt;% 
  ggplot(aes(x=make,y= model, size=lv4, col=VClass)) + 
  geom_point() +
  theme(plot.caption=element_text(size=12),
        axis.text.x=element_text(angle=45, hjust=1),
        text = element_text(size=18), 
        plot.title = element_text(size=32)) +
labs(caption= &amp;quot;Data: https://fueleconomy.gov&amp;quot;, 
     size=&amp;quot;Luggage Vol\n(Cubic feet)&amp;quot;,
     x = element_blank(), 
     y = element_blank(), 
     title = &amp;quot;Which are the best family cars?&amp;quot;) + 
  guides(size = guide_legend(order = 1), 
         shape = guide_legend(order = 2)) +
  scale_size(range=c(2, 9))
bs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Mercedes AMG GLA45 is the winner with 42 cubic feet space!&lt;/p&gt;
&lt;p&gt;Here is another presentation, for easier comparision.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Top family cars - geom_Col()
bs_col &amp;lt;- boot_space %&amp;gt;% 
    mutate(model = fct_reorder(model, lv4)) %&amp;gt;%
    mutate(make = fct_reorder(make, lv4)) %&amp;gt;% 
    ggplot(aes(x=model, y=lv4, fill=make)) + 
    geom_col(position=&amp;quot;dodge&amp;quot;)+coord_flip() + 
    theme(plot.caption=element_text(size=11), 
          text = element_text(size=18), 
          plot.title = element_text(size=32)) +
labs(caption= &amp;quot;Data source: https://fueleconomy.gov&amp;quot;, 
     size=&amp;quot;Luggage Vol\n(Cubic feet)&amp;quot;, 
     x = element_blank(), 
     y = &amp;quot;Luggage Vol (Cubic feet)&amp;quot;, 
     title = &amp;quot;Which are the best family cars?&amp;quot;) +
    scale_size(range=c(2, 9)) 

bs_col&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We found our answer and our camping gear is ready. Let’s tackle some other questions. We hear a lot about them but how does the future looks like for Electric cars?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-do-electric-cars-evolving-in-the-last-years-compared-to-non-electric-cars&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How do Electric cars evolving in the last years compared to non electric cars?&lt;/h1&gt;
&lt;p&gt;There are many of different types of engines capable of using one or two different fuel sources. Let’s look at how their numbers compare during the last years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Using Varwidth: Ordered
pp  &amp;lt;- big_epa_cars %&amp;gt;% 
  mutate(fuelType=fct_reorder(fuelType, year)) %&amp;gt;% 
  ggplot(aes(x=fuelType, y =year, fill=fuelType)) + 
  geom_boxplot(varwidth=TRUE) + 
  coord_flip() + 
  theme(legend.position = &amp;quot;none&amp;quot;, 
        text = element_text(size=18), 
        plot.title = element_text(size=32),
        axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(x = &amp;quot;Fuel Type&amp;quot;,
       y = &amp;quot;Year&amp;quot;, 
       title = 
         &amp;quot;How does prominence of Fuel Types \nchange with the year?&amp;quot;)

pp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;group-electric-vs-non-electric-cars&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Group Electric vs Non Electric cars&lt;/h3&gt;
&lt;p&gt;I will group cars whehter or not they can use electricity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Grouped: Electric vs no electric:
big_epa_cars$fuelType &amp;lt;- ifelse(big_epa_cars$fuelType %in%
               c(&amp;quot;Regular Gas and Electricity&amp;quot;,
                &amp;quot;Premium Gas or Electricity&amp;quot;,
                 &amp;quot;Premium and Electricity&amp;quot;, 
                &amp;quot;Regular Gas or Electricity&amp;quot;,
                &amp;quot;Electricity&amp;quot;), &amp;quot;Electric&amp;quot;, &amp;quot;Non-Electric&amp;quot;)

pp  &amp;lt;- big_epa_cars %&amp;gt;% 
  mutate(fuelType=fct_reorder(fuelType, year)) %&amp;gt;% 
  ggplot(aes(x=fuelType, y =year, fill=fuelType)) + 
  geom_boxplot(varwidth=TRUE) +
  coord_flip() + 
  theme(text = element_text(size=18), 
        plot.title = element_text(size=32), legend.position = &amp;quot;none&amp;quot;)+
  theme(text = element_text(size=15)) +
  labs(x = &amp;quot;Fuel Type&amp;quot;,
       y = &amp;quot;Year&amp;quot;,
       title = &amp;quot;How does prominence of Fuel Types \nchange with the year?&amp;quot;)

pp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the last couple of years, number of electric car models are increasing but they are still a minority.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;big3 &amp;lt;- big_epa_cars %&amp;gt;% 
  group_by(year, fuelType) %&amp;gt;% 
  mutate(n = n())

big3 %&amp;gt;% 
    ggplot(aes(x=n, y =year, col=fuelType)) +
    geom_point(size=4) +
    theme(legend.position = c(0.9,0.9),
          legend.title= element_blank(), 
          legend.background = element_blank(),
          plot.title = element_text(size=32), 
          text = element_text(size=15)) + 
  coord_flip() +
    labs(x = &amp;quot;Number of Car models&amp;quot;, 
         y = &amp;quot;Year&amp;quot;, 
         title = &amp;quot;How does the Numbers of Electric vs Non Electric cars \nchange by year?&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-23-tidytuesday-which-are-the-best-family-cars_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both Electric and Non Electric car models follows a similar increase in the last 10 years&lt;/p&gt;
&lt;p&gt;Increases in Electric car models in the last years might be a reflection of a general increase in total number of model types&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-future-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions / Future thoughts&lt;/h1&gt;
&lt;p&gt;This was a huge dataset. You can answer many other questions such as mileage of different car models, carbon dioxide emissions, fuel savings.&lt;/p&gt;
&lt;p&gt;I have selected some car models which might be a good option if luggage space is a priority for you!&lt;/p&gt;
&lt;p&gt;To see other examples of how people used this dataset follow the &lt;strong&gt;Twitter&lt;/strong&gt; hashtag &lt;a href=&#34;https://twitter.com/hashtag/tidytuesday?lang=en&#34;&gt;#TidyTuesday&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please share if you have other ideas in the comments below!&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Add custom summary statistics in ggplot2</title>
      <link>/r/stats-ggplot/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/stats-ggplot/</guid>
      <description>


&lt;p&gt;It is hard to understand your data by looking at the numbers on a csv file. You need to plot it. And adding statistics to your plots will make it more informative.&lt;/p&gt;
&lt;p&gt;To evaluate data, we typically use &lt;strong&gt;mean&lt;/strong&gt; and &lt;strong&gt;median&lt;/strong&gt; to define its central tendency and &lt;strong&gt;range, quartiles, variance&lt;/strong&gt; and &lt;strong&gt;standard deviation&lt;/strong&gt; to define how spread it is.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt; and &lt;strong&gt;standard deviation&lt;/strong&gt; is a good representation of the data if we don’t have extreme values that result in a skewed distribution. But, if we have outliers they might misguide us. In those conditions, &lt;code&gt;median&lt;/code&gt; and &lt;code&gt;quartiles&lt;/code&gt; will serve us better.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Median&lt;/strong&gt; is the central point which divides the data into half. &lt;strong&gt;Quartiles&lt;/strong&gt; are used to describe the spread of the data. The word comes from the Medieval Latin “quartilis” which means fourth and &lt;strong&gt;quartiles break the data into four equal parts&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The advantage is that they are much less effected by the outliers or skeweness of the data.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;For this reason, &lt;strong&gt;quartiles are often used along with the median as the best measures of spread.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;They are often expressed as an &lt;strong&gt;Interquartile range (IQR)&lt;/strong&gt;, which is the interval between first and third quartiles and represents 50% of the data points.&lt;/p&gt;
&lt;p&gt;For example, you measured height of adults in a population, with Interquartile range you can describe a discrete interval centered around the median including 50% of the measurements.&lt;/p&gt;
&lt;p&gt;Here is a representative graph.&lt;img src=&#34;/img/quartiles.png&#34; alt=&#34;graph:wikipedia&#34; /&gt;[source:wikipedia]&lt;/p&gt;
&lt;div id=&#34;how-to-include-statistics-in-ggplot2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to include statistics in ggplot2&lt;/h1&gt;
&lt;p&gt;Stats make it easier to grasp the data. And &lt;strong&gt;different statistics are suited for different data types&lt;/strong&gt;. For example, you may want to show &lt;code&gt;a 95% confidence interval? or mean? median?&lt;/code&gt; or any other statistics which captures the details best for your data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So let’s go through on an example data&lt;/strong&gt; to understand how statistics can be overlayed in ggplot2. The data is about the effects of two Herbicides (glyphosate &amp;amp; bentazone) on the yield of white mustard (Sinapis alba) seeds.&lt;/p&gt;
&lt;p&gt;First, import ggplot2 package and read in the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
path &amp;lt;- &amp;quot;C:/Users/serda/Downloads/S.alba.csv&amp;quot;
data &amp;lt;- read.csv(path)
str(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    68 obs. of  4 variables:
##  $ X        : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Dose     : int  0 0 0 0 0 0 0 0 10 10 ...
##  $ Herbicide: Factor w/ 2 levels &amp;quot;Bentazone&amp;quot;,&amp;quot;Glyphosate&amp;quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ DryMatter: num  4.7 4.6 4.1 4.4 3.2 3 3.8 3.9 3.8 3.8 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These chemicals used at 8 different doses and the yield is measured. I will convert the dose variable as a factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data$Dose &amp;lt;- as.factor(data$Dose)
levels(data$Dose)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;0&amp;quot;   &amp;quot;10&amp;quot;  &amp;quot;20&amp;quot;  &amp;quot;40&amp;quot;  &amp;quot;80&amp;quot;  &amp;quot;160&amp;quot; &amp;quot;320&amp;quot; &amp;quot;640&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can make an initial plot to visualize the data. We’ll plot the yield variable &lt;code&gt;DryMatter&lt;/code&gt; against &lt;code&gt;Dose&lt;/code&gt; of the Herbicides. We can assign &lt;code&gt;col&lt;/code&gt; argument to map different chemical compounds to different colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I will define a dodge and jitterdodge object to avoid overlapping data points 
# or stats that we will overlay later
posn.d &amp;lt;- position_dodge(width=0.2)
posn.jd &amp;lt;- position_jitterdodge(jitter.width = 0.1, dodge.width=0.2)
p &amp;lt;- ggplot(data, aes(x=Dose, y=DryMatter, col=Herbicide, fill=Herbicide, 
                      group=Herbicide ))
p + geom_point(position =posn.jd)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-16-add-custom-summary-statistics-into-your-ggplot_files/figure-html/visualize%20the%20data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What we see here is that, at low doses both Herbicides led similar yields but starting from Dose 40 we see a drastic negative impact of Benzoate on yield.&lt;/p&gt;
&lt;p&gt;On top of that plot, I want to overlay the &lt;code&gt;min&lt;/code&gt;, &lt;code&gt;max&lt;/code&gt; and also &lt;code&gt;median&lt;/code&gt; and &lt;code&gt;Interquartile range&lt;/code&gt; for each set of yield measurements.&lt;/p&gt;
&lt;p&gt;There are many default functions in ggplot2 which can be used directly such as &lt;strong&gt;mean_sdl(), mean_cl_normal()&lt;/strong&gt; to add stats in stat_summary() layer. But, I will create custom functions here so that we can grasp better what is happening behind the scenes on ggplot2.&lt;/p&gt;
&lt;p&gt;I will create one function to calculate the &lt;strong&gt;median&lt;/strong&gt; and the &lt;strong&gt;interquartile range(IQR) 1-3&lt;/strong&gt;, and another to calculate min(), max() values.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    In order to use the results of a function directly in ggplot2 we need to &lt;strong&gt;ensure that the names of the variables match the aesthetics needed for our respective geoms&lt;/strong&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Function for median and IQR

median_IQR &amp;lt;- function(x) {
  data.frame(y = median(x), # Median
             ymin = quantile(x)[2], # 1st quartile
             ymax = quantile(x)[4])  # 3rd quartile
}

# Function for min, max values
range &amp;lt;- function(x) {
  data.frame(ymin=min(x),
             ymax=max(x))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s replot with the statistics we wanted to overlay. You can use two &lt;code&gt;stat_summary()&lt;/code&gt; layers to add our stats. You can set the &lt;code&gt;fun.data&lt;/code&gt; argument to the specific function defined above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Updated plot
p + 
  stat_summary(geom = &amp;quot;linerange&amp;quot;,
                 fun.data = median_IQR, 
                 position = posn.d, 
                 size=3) + 
  stat_summary(geom = &amp;quot;linerange&amp;quot;, 
               fun.data = range, 
               position = posn.d, 
               size=3, 
               alpha=0.5)+ 
  stat_summary(geom = &amp;quot;point&amp;quot;, 
               fun.y = &amp;quot;median&amp;quot;, 
               position = posn.d, 
               size = 3, 
               col = &amp;quot;black&amp;quot;, 
               shape = &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-16-add-custom-summary-statistics-into-your-ggplot_files/figure-html/visualize%20with%20stats-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In contrast, to the first plot here we easily see where the median and IQR lays. We can make our comparisions easier. Starting from dose 20, we see that glyphosate clearly outperforms bentazone. Big separation between the IQRs are obvious at doses 40 and 80. At higher doses, differences in IQRs starts to disappear.&lt;/p&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;Ggplot2 is a flexible package and knowing its intricacies will help you level up your visuals. To understand your data and to convey the insights you want to point out, you can include your choice of custom functions in ggplot &lt;code&gt;stat_summary()&lt;/code&gt; layer similarly as we did above or use the default functions.&lt;/p&gt;
&lt;p&gt;The data we have here was small. With bigger data, it is more crucial to overlay summary statistics of interest for effective visuals.&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Preparation: Web Scraping html tables with rvest</title>
      <link>/r/scrape-tables-rvest/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/scrape-tables-rvest/</guid>
      <description>


&lt;div id=&#34;accessing-different-data-sources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accessing different data sources&lt;/h2&gt;
&lt;p&gt;Sometimes, the data you need is available on the web. Accessing those will ease your life as a data scientist.&lt;/p&gt;
&lt;p&gt;I want to perform an exploratory data analysis on &lt;strong&gt;2018/19 Season of England Premier league&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are there changes in team performances during the season timeline?&lt;/li&gt;
&lt;li&gt;Does some teams cluster?&lt;/li&gt;
&lt;li&gt;Which is the earliest week we can predict team’s final positions?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I need the &lt;strong&gt;standings table&lt;/strong&gt; for each week of the season and integrate them in a way that will allow me to plot the graphs that I want.
We will scrap those tables from &lt;a href=&#34;https://www.weltfussball.de/&#34; class=&#34;uri&#34;&gt;https://www.weltfussball.de/&lt;/a&gt;.&lt;img src=&#34;/img/welt.png&#34; alt=&#34;welt&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For example standings table for the Week 1 is at the url:&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&#34; class=&#34;uri&#34;&gt;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the consequent weeks only the number at the end changes e.g.&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/2&#34;&gt;../spielplan/eng-premier-league-2018-2019-spieltag/&lt;strong&gt;2&lt;/strong&gt;&lt;/a&gt; ←&lt;br /&gt;
&lt;a href=&#34;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/3&#34;&gt;../spielplan/eng-premier-league-2018-2019-spieltag/&lt;strong&gt;3&lt;/strong&gt;&lt;/a&gt; ←&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Pull the necessary packages  

library(rvest)     # xml2
library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
library(gganimate)
library(RColorBrewer)
library(kableExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define the remote url
baseUrl &amp;lt;- &amp;quot;https://www.weltfussball.de/&amp;quot;
path &amp;lt;- &amp;quot;spielplan/eng-premier-league-2018-2019-spieltag/&amp;quot;
fileName &amp;lt;- 1
url &amp;lt;- paste0(baseUrl, path, fileName)
url&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;https://www.weltfussball.de/spielplan/eng-premier-league-2018-2019-spieltag/1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We start by downloading and parsing the file with &lt;strong&gt;read_html()&lt;/strong&gt; function from the rvest package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tables &amp;lt;- read_html(url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To extract the html table individually you can use &lt;strong&gt;XPath&lt;/strong&gt; syntax which defines parts on XML documents.&lt;/p&gt;
&lt;p&gt;To get the XPath for standings table open the url on google chrome,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hover the mouse over the table &amp;gt; right click &amp;gt; inspect&lt;/strong&gt;&lt;br /&gt;
# This will open inspector&lt;/li&gt;
&lt;li&gt;Move your mouse a few lines up or down to find the line where whole table is highlighted&lt;/li&gt;
&lt;li&gt;Right click &amp;gt; Copy &amp;gt; Copy full XPath&lt;img src=&#34;/img/weltxpath.png&#34; alt=&#34;weltxpath&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can feed that XPath we copied to html_nodes() function and extract the node which contains the table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xpath = &amp;quot;/html/body/div[3]/div[2]/div[4]/div[2]/div[1]/div/div[7]/div/table[1]&amp;quot;
nodes &amp;lt;- html_nodes(tables, xpath = xpath)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end, html_table() function will extract us the individual table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;html_table(nodes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##     # Mannschaft              Mannschaft Sp. S. U. N. Tore Dif. Pk.
## 1   1         NA            Liverpool FC   1  1  0  0  4:0    4   3
## 2   2         NA              Chelsea FC   1  1  0  0  3:0    3   3
## 3   3         NA         AFC Bournemouth   1  1  0  0  2:0    2   3
## 4  NA         NA          Crystal Palace   1  1  0  0  2:0    2   3
## 5  NA         NA         Manchester City   1  1  0  0  2:0    2   3
## 6  NA         NA              Watford FC   1  1  0  0  2:0    2   3
## 7   7         NA       Manchester United   1  1  0  0  2:1    1   3
## 8  NA         NA       Tottenham Hotspur   1  1  0  0  2:1    1   3
## 9   9         NA              Everton FC   1  0  1  0  2:2    0   1
## 10 NA         NA Wolverhampton Wanderers   1  0  1  0  2:2    0   1
## 11 11         NA              Burnley FC   1  0  1  0  0:0    0   1
## 12 NA         NA          Southampton FC   1  0  1  0  0:0    0   1
## 13 13         NA          Leicester City   1  0  0  1  1:2   -1   0
## 14 NA         NA        Newcastle United   1  0  0  1  1:2   -1   0
## 15 15         NA              Arsenal FC   1  0  0  1  0:2   -2   0
## 16 NA         NA  Brighton &amp;amp; Hove Albion   1  0  0  1  0:2   -2   0
## 17 NA         NA            Cardiff City   1  0  0  1  0:2   -2   0
## 18 NA         NA               Fulham FC   1  0  0  1  0:2   -2   0
## 19 19         NA       Huddersfield Town   1  0  0  1  0:3   -3   0
## 20 20         NA         West Ham United   1  0  0  1  0:4   -4   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wonderful, we scraped the standings table for the first week, but we want tables for each 38 week of the season.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You can make this easily by packing what we have done so far in a for loop.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As only the last number in our url link changes, we can code different url addresses as in &lt;code&gt;url[[i]] &amp;lt;- paste0(baseUrl, path, i)&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create emtpy lists
url &amp;lt;- list()
pages &amp;lt;- list()
nodes &amp;lt;- list()
final &amp;lt;- list()
start &amp;lt;- Sys.time()
# For loop.
# It will connect one by one to 38 different url links predefined 
# by the line starting with url[[i]]
# Collect the information with read_html(), html_nodes() and html_table()
# Finally each table will be converted to a data frame
for(i in 1:38){
url[[i]] &amp;lt;- paste0(baseUrl, path, i)
pages[[i]] &amp;lt;- read_html(url[[i]])
nodes[[i]] &amp;lt;- html_nodes(pages[[i]], xpath = xpath)
final[[i]] &amp;lt;- data.frame(html_table(nodes[[i]]))
}

# By coding start and end times of the whole process 
# I can keep an eye on how fast my code is.
end &amp;lt;- Sys.time()
end-start&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 22.62705 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, &lt;code&gt;final[[19]]&lt;/code&gt; will give me standings of mid season:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final[[19]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    X. Mannschaft            Mannschaft.1 Sp. S. U. N.  Tore Dif. Pk.
## 1   1         NA            Liverpool FC  19 16  3  0  43:7   36  51
## 2   2         NA       Tottenham Hotspur  19 15  0  4 42:18   24  45
## 3   3         NA         Manchester City  19 14  2  3 51:15   36  44
## 4   4         NA              Chelsea FC  19 12  4  3 37:16   21  40
## 5   5         NA              Arsenal FC  19 11  5  3 41:25   16  38
## 6   6         NA       Manchester United  19  9  5  5 37:31    6  32
## 7   7         NA          Leicester City  19  8  4  7 24:22    2  28
## 8   8         NA              Everton FC  19  7  6  6 31:29    2  27
## 9   9         NA         West Ham United  19  8  3  8 27:28   -1  27
## 10 10         NA              Watford FC  19  8  3  8 26:27   -1  27
## 11 11         NA Wolverhampton Wanderers  19  7  5  7 20:22   -2  26
## 12 12         NA         AFC Bournemouth  19  8  2  9 27:33   -6  26
## 13 13         NA  Brighton &amp;amp; Hove Albion  19  6  4  9 21:27   -6  22
## 14 14         NA          Crystal Palace  19  5  4 10 17:25   -8  19
## 15 15         NA        Newcastle United  19  4  5 10 14:26  -12  17
## 16 16         NA          Southampton FC  19  3  6 10 20:35  -15  15
## 17 17         NA            Cardiff City  19  4  3 12 18:38  -20  15
## 18 18         NA              Burnley FC  19  3  3 13 17:41  -24  12
## 19 19         NA               Fulham FC  19  2  5 12 17:43  -26  11
## 20 20         NA       Huddersfield Town  19  2  4 13 12:34  -22  10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don’t mind the NAs in the second column, we will remove them soon.
Now, we have all 38 table in our list &lt;strong&gt;final&lt;/strong&gt;, we can combine them to a new data frame which will contain standings of the whole season.&lt;/p&gt;
&lt;p&gt;To be able to plot e.g. timeline, let’s keep the tidy data principles:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Each observation has its own row.&lt;/li&gt;
&lt;li&gt;Each variable has its own column.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since we have same column names in each table, we can use &lt;strong&gt;rbind&lt;/strong&gt; function to add rows of each table to the bottom of the first one. How to do that? We can’t use lapply() function here. It will not combine elements in a list. We can use &lt;strong&gt;do.call() function to perform the rbind() operation and combine all data frames we have&lt;/strong&gt;*.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk18 &amp;lt;-  do.call(&amp;quot;rbind&amp;quot;, final)
dim(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 760  10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X. Mannschaft    Mannschaft.1 Sp. S. U. N. Tore Dif. Pk.
## 1  1         NA    Liverpool FC   1  1  0  0  4:0    4   3
## 2  2         NA      Chelsea FC   1  1  0  0  3:0    3   3
## 3  3         NA AFC Bournemouth   1  1  0  0  2:0    2   3
## 4 NA         NA  Crystal Palace   1  1  0  0  2:0    2   3
## 5 NA         NA Manchester City   1  1  0  0  2:0    2   3
## 6 NA         NA      Watford FC   1  1  0  0  2:0    2   3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Column names/shorcuts were in German, let’s replace them with the English words.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Correct final table
uk18 &amp;lt;- uk18  %&amp;gt;% select(3:10)
new_names &amp;lt;- c(&amp;quot;team&amp;quot;, &amp;quot;week&amp;quot;, &amp;quot;won&amp;quot;, &amp;quot;drawn&amp;quot;, &amp;quot;lost&amp;quot;, &amp;quot;goals&amp;quot;, 
               &amp;quot;difference&amp;quot;, &amp;quot;points&amp;quot;)
colnames(uk18) &amp;lt;- new_names&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Goals variable is contains two different data separated with “:”. &lt;code&gt;E.g. (4:0)&lt;/code&gt;. Those represent goals scored:goals scored against. Let’s split goals column into two by &lt;strong&gt;separate() function from tidyr&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk18 &amp;lt;- uk18 %&amp;gt;% separate(goals, c(&amp;quot;scored&amp;quot;, &amp;quot;against&amp;quot;), sep=&amp;quot;\\:&amp;quot;)
head(uk18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              team week won drawn lost scored against difference points
## 1    Liverpool FC    1   1     0    0      4       0          4      3
## 2      Chelsea FC    1   1     0    0      3       0          3      3
## 3 AFC Bournemouth    1   1     0    0      2       0          2      3
## 4  Crystal Palace    1   1     0    0      2       0          2      3
## 5 Manchester City    1   1     0    0      2       0          2      3
## 6      Watford FC    1   1     0    0      2       0          2      3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;I want to order my legend with the same order of teams final positions&lt;/strong&gt;. Let’s filter for the last week of the season and arrange them in descending order. I will assign this list to the factor levels of the team variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract team names in the order as the season end
uk18_filt &amp;lt;- uk18 %&amp;gt;% 
  filter(week == 38) %&amp;gt;%
  arrange(desc(points))
knitr::kable(uk18_filt)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
team
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
week
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
won
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
drawn
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lost
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
scored
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
against
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
difference
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
points
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Manchester City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
95
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
98
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Liverpool FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
89
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
97
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chelsea FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tottenham Hotspur
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Arsenal FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Manchester United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wolverhampton Wanderers
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
47
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Everton FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Leicester City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
West Ham United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Watford FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Crystal Palace
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
51
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Newcastle United
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AFC Bournemouth
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
45
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burnley FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Southampton FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
45
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brighton &amp;amp; Hove Albion
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
35
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Cardiff City
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
34
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Fulham FC
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
34
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Huddersfield Town
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;finallevels &amp;lt;- as.character(uk18_filt$team)
uk18$team &amp;lt;- factor(uk18$team, levels = finallevels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also create a color palette which fits to your needs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We need a color palette with 20 colors
colorCount &amp;lt;- length(unique(uk18$team))
# colorRampPalette creatas a getPalette() function
# This can modify an existing palette to include as many colors we want
getPalette &amp;lt;- colorRampPalette(brewer.pal(9, &amp;quot;Set1&amp;quot;))
getPalette(colorCount)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;#E41A1C&amp;quot; &amp;quot;#9B445D&amp;quot; &amp;quot;#526E9F&amp;quot; &amp;quot;#3C8A9B&amp;quot; &amp;quot;#469F6C&amp;quot; &amp;quot;#54A453&amp;quot; &amp;quot;#747B78&amp;quot;
##  [8] &amp;quot;#94539E&amp;quot; &amp;quot;#BD6066&amp;quot; &amp;quot;#E97422&amp;quot; &amp;quot;#FF990A&amp;quot; &amp;quot;#FFCF20&amp;quot; &amp;quot;#FAF632&amp;quot; &amp;quot;#D4AE2D&amp;quot;
## [15] &amp;quot;#AF6729&amp;quot; &amp;quot;#BF6357&amp;quot; &amp;quot;#E17597&amp;quot; &amp;quot;#E884B9&amp;quot; &amp;quot;#C08EA9&amp;quot; &amp;quot;#999999&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot season timeline using the palette we just created
uk &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) +   
  geom_point(size=3) + 
  theme(text = element_text(size=15)) + 
  scale_color_manual(values = getPalette(colorCount))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the regression lines&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot season timeline
uk &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) + 
  geom_smooth(se=TRUE) + 
  theme(text = element_text(size=15)) + 
  scale_color_manual(values = getPalette(colorCount))

uk&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/Season%20timeline%20linear%20model-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk_facet &amp;lt;- ggplot(uk18, aes(x=week, y=points, col=team)) + 
  geom_smooth(se=FALSE) + 
  theme(text = element_text(size=10)) + 
  scale_color_manual(values = getPalette(colorCount)) + 
  facet_wrap(ncol = 4, team~.)

uk_facet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/Season%20timeline%20linear%20model-2.png&#34; width=&#34;672&#34; /&gt;
Some insights from the plots:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I see three clusters here. Two teams (Man. City and Liverpool) competed head to head for the championship and next three teams (Chelsea, Tottenham and Arsenal) for the 3rd position.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;We can predict 4 out of 5 teams which will take first 5 place at the end of the season early as week 10.&lt;/li&gt;
&lt;li&gt;Manchester United showed peak performance mid season, Everton have improved performances while Tottenham slowed down (which costed them 3rd position) in the second part of the season.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I can plot points against goal differences in the same plot. Same clusters pop up here as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk &amp;lt;- ggplot(uk18, aes(x=difference, y=points, col=team)) + 
  geom_point(size=2) + 
  scale_color_manual(values = getPalette(colorCount)) + 
  theme(text = element_text(size=15))
uk&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/points%20vs%20goal%20differences-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s visualize this in a small animation. You can create an animated plot of the teams progress during the season. Gganimate does good job.`&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Add a shadow tail
# anim + shadow_wake(wake_length = 0.3, alpha = FALSE)
 
anim &amp;lt;- uk + 
             transition_time(week) + 
             labs(title = &amp;quot;week: {round(frame_time,0)}&amp;quot;) + 
             shadow_wake(wake_length = 0.1, alpha = 0.5)

fullanimation &amp;lt;- animate(anim, fps= 7, nframes=100, 
                         height=500, width=800, res=0.8)

fullanimation&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-10-data-preparation-web-scraping-data-tables-with-rvest_files/figure-html/gganimate-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions-future-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions / Future Thoughts&lt;/h1&gt;
&lt;p&gt;One of the most important steps to answer a research question is gathering and pre-processing data that fits best for the planned analysis.&lt;/p&gt;
&lt;p&gt;Some of the questions we tackled were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to find the &lt;strong&gt;XPath&lt;/strong&gt; for an &lt;strong&gt;html table&lt;/strong&gt; in a website?&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;combine data frames&lt;/strong&gt; from &lt;strong&gt;a list&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;split columns&lt;/strong&gt; containing more than one variable?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The earliest time, we can predict top teams final positions was around 10th. We can collect data from previous years or compare other countries leagues to check if we can generalize this finding.&lt;/p&gt;
&lt;p&gt;What else we can ask? For example, we can connect performance changes to new transfers. Or whether changing coaches benefited any team.&lt;/p&gt;
&lt;p&gt;Please share if you have other ideas in the comments below!&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;p&gt;PS: If you are looking for more blogs to learn R you might check also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.r-bloggers.com&#34;&gt;https://www.r-bloggers.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rweekly.org&#34;&gt;https://rweekly.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What is aesthetics and attributes in ggplot&#39;s world?</title>
      <link>/r/ggplot-shiny-app/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/r/ggplot-shiny-app/</guid>
      <description>


&lt;p&gt;ggplot2 is a powerful data visualization tool of R. Make quick visualizations to explore or share your insights.&lt;/p&gt;
&lt;p&gt;Learning how aesthetics and attributes are defined in ggplot will give you an edge to develop your skills quickly.&lt;/p&gt;
&lt;div id=&#34;ggplot2-tips-distinction-between-aesthetics-and-attributes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ggplot2 tips: distinction between aesthetics and attributes&lt;/h3&gt;
&lt;p&gt;Aesthetics are defined inside &lt;strong&gt;aes()&lt;/strong&gt; in ggplot syntax and attributes are outside the aes().&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;e.g. ggplot(data, aes(x, y, &lt;strong&gt;color=var1&lt;/strong&gt;) + geom_point&lt;strong&gt;(size=6)&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We typically understand &lt;strong&gt;aesthetics&lt;/strong&gt; as how something looks, color, size etc.&lt;br /&gt;
But in ggplot’s world how things look is just an &lt;strong&gt;attribute.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Aesthetics do not refer how something looks, &lt;strong&gt;but to which variable is mapped onto it.&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;I will create an imaginary data frame to apply those concepts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
points &amp;lt;- 500
# Defining the Golden Angle
angle &amp;lt;- pi*(3-sqrt(5))
t &amp;lt;- (1:points) * angle
x &amp;lt;- sin(t/2)
y &amp;lt;-cos(t/2)
z &amp;lt;- rep(c(1,2,3,4,5,6,7,8,9,10), times=50)
w &amp;lt;- rep(c(1,2), times=250)
df &amp;lt;- data.frame(t, x, y, z, w)
# Have a look at the data
head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           t          x           y z w
## 1  2.399963  0.9320324  0.36237489 1 1
## 2  4.799926  0.6754903 -0.73736888 2 2
## 3  7.199890 -0.4424710 -0.89678282 3 1
## 4  9.599853 -0.9961710  0.08742572 4 2
## 5 11.999816 -0.2795038  0.96014460 5 1
## 6 14.399779  0.7936008  0.60843886 6 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataframe we created has 3 numeric (t, x, y) variables and 2 discrete variables (z, w). With ggplot2 I can map any of the variables on my plot by defining them inside the &lt;strong&gt;aes().&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a scatter plot of points of a spiral
p &amp;lt;- ggplot(df, aes(x*t, y*t))
p + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-08-what-is-aesthetics-and-atributes-in-ggplot-s-world_files/figure-html/ggplot%20main%20spiral-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-use-of-an-aesthetics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example use of an aesthetics&lt;/h3&gt;
&lt;p&gt;By defining col=factor(z) inside aes(), I can map z to colors. So now the graph shows x, y and also values z.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a scatter plot of points in a spiral
p &amp;lt;- ggplot(df, aes(x*t, y*t, col=factor(z)))
p + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-08-what-is-aesthetics-and-atributes-in-ggplot-s-world_files/figure-html/Map%20z%20on%20color-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each different color now represents different values of z.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-use-of-an-attribute&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example use of an attribute&lt;/h3&gt;
&lt;p&gt;Attribute is how somethings looks. e.g. you can the points bigger by defining size=4. But it does not give any extra information about data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a scatter plot of points in a spiral
p &amp;lt;- ggplot(df, aes(x*t, y*t, col=factor(z)))
p + geom_point(size = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-08-what-is-aesthetics-and-atributes-in-ggplot-s-world_files/figure-html/main%20spiral%20colored-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-shape-as-an-attribute&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use shape as an attribute&lt;/h3&gt;
&lt;p&gt;Same goes here. I am changing how something looks like. The data point shape change to 24 which defines a empty triangle. But nothing is mapped onto it. It is just an attribute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make a scatter plot of points in a spiral
p &amp;lt;- ggplot(df, aes(x*t, y*t, color=factor(z)))
p + geom_point(shape=24, size=4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-08-what-is-aesthetics-and-atributes-in-ggplot-s-world_files/figure-html/spiral%20colors%20with%20triangles-1.png&#34; width=&#34;672&#34; /&gt;
Here, x&lt;em&gt;t, y&lt;/em&gt;t and factor(z) is mapped on to our graph.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-shape-as-an-aesthetics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using shape as an aesthetics&lt;/h3&gt;
&lt;p&gt;By defining shape and color inside aes() I can map w and z to my plot as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points &amp;lt;- 500
# Defining the Golden Angle
angle &amp;lt;- pi*(3-sqrt(5))
t &amp;lt;- (1:points) * angle
x &amp;lt;- sin(t)
y &amp;lt;-cos(t)
z &amp;lt;- rep(c(1,2,3,4,5,6,7,8,9,10), times=50)
w &amp;lt;- rep(c(1,2), times=250)
df &amp;lt;- data.frame(t, x, y, z, w)

p &amp;lt;- ggplot(df, aes(x*t, y*t, shape=factor(w), color=factor(z)))
p + geom_point(size=3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-08-what-is-aesthetics-and-atributes-in-ggplot-s-world_files/figure-html/aa-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Spirals look nice and we got some basics of ggplot. Now let’s use it to create a pattern designer, with Shiny. Many patterns in Nature can be explained by mathematical terms, Shapes of sunflowers, dandelions or snowflakes etc.&lt;/p&gt;
&lt;p&gt;I will tell the rest of the story in the next update. Now you can play with the app to create your patterns!&lt;/p&gt;
&lt;iframe width=&#34;1000&#34; height=&#34;800&#34; scrolling=&#34;no&#34; frameborder=&#34;no&#34; src=&#34;https://korur.shinyapps.io/designapattern/&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;Until next time!&lt;br /&gt;
Serdar&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
