<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | SERDAR KORUR</title>
    <link>/post/</link>
      <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>Posts</title>
      <link>/post/</link>
    </image>
    
    <item>
      <title>Can machine learning change your lifestyle? Predicting Diabetes</title>
      <link>/2019/10/01/predict-diseases/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/2019/10/01/predict-diseases/</guid>
      <description>


&lt;p&gt;Would you be taking care of yourself better if your doctor told today that you have &lt;strong&gt;high risk of diabetes?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Advances in fields, such as omics and internet of things (sensors that collect data), and centralization of healthcare information (e.g. &lt;a href=&#34;https://www.ohdsi.org/data-standardization/the-common-data-model/&#34;&gt;OMOP common data model&lt;/a&gt;) enable us to access much wider data sources.&lt;/p&gt;
&lt;p&gt;Gaining insights from those we can improve our well being with better healthcare. Some applications of machine learning tools are;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diagnosing diseases earlier&lt;/li&gt;
&lt;li&gt;Identifiying drugs with reduced side effects&lt;/li&gt;
&lt;li&gt;Select patient groups responding to an experimental therapy&lt;/li&gt;
&lt;li&gt;Utilize existing therapies better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Let’s look at an example and try to help some doctors in diagnosing their patients.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;problem-formulation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Problem formulation&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we build a Machine learning algorithm to predict which patients will develop Diabetes?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The goal is to predict a Binary &lt;strong&gt;Outcome&lt;/strong&gt;: &lt;code&gt;Diabetes&lt;/code&gt; vs &lt;code&gt;Healthy&lt;/code&gt;
by using 8 medical indicators.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overview-of-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview of the data&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The Pima Indians of Arizona and Mexico&lt;/strong&gt; have contributed to numerous scientific gains. Their involvement has led to significant findings on genetics of both &lt;strong&gt;type 2 diabetes&lt;/strong&gt; and &lt;strong&gt;obesity.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The medical indicators recorded are;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pregnancies:&lt;/strong&gt; Number of times pregnant&lt;br /&gt;
&lt;strong&gt;Glucose:&lt;/strong&gt; Plasma glucose concentration a 2 hours in an oral glucose tolerance test&lt;br /&gt;
&lt;strong&gt;BloodPressure:&lt;/strong&gt; Diastolic blood pressure (mm Hg)&lt;br /&gt;
&lt;strong&gt;SkinThickness:&lt;/strong&gt; Triceps skin fold thickness (mm)&lt;br /&gt;
&lt;strong&gt;Insulin:&lt;/strong&gt; 2-Hour serum insulin (mu U/ml)&lt;br /&gt;
&lt;strong&gt;BMI:&lt;/strong&gt; Body mass index (weight in kg/(height in m)^2)&lt;br /&gt;
&lt;strong&gt;DiabetesPedigreeFunction:&lt;/strong&gt; Diabetes pedigree function&lt;br /&gt;
&lt;strong&gt;Age:&lt;/strong&gt; Age (years)&lt;br /&gt;
&lt;strong&gt;Outcome:&lt;/strong&gt; Class variable (0 or 1)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-acquisition&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data acquisition&lt;/h1&gt;
&lt;p&gt;I downloaded the &lt;a href=&#34;https://www.kaggle.com/uciml/pima-indians-diabetes-database&#34;&gt;Pima Indians Diabetes Dataset&lt;/a&gt; from Kaggle and imported it from my local directory.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diabetes &amp;lt;- read.csv(&amp;quot;posts_data/diabetes.csv&amp;quot;)

library(dplyr)
library(tidyr)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
library(pROC)
library(lattice)
library(caret)
library(waffle)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-quality-control&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Quality control&lt;/h1&gt;
&lt;p&gt;Before counting on any algorithm a good starting point is to &lt;strong&gt;check obvious mistakes and abnormalities in your data.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here, I would look at &lt;strong&gt;Missing values&lt;/strong&gt;, variable ranges (&lt;strong&gt;min, max values&lt;/strong&gt;). A very extreme value might be basically a sign of typing error.&lt;/p&gt;
&lt;div id=&#34;understand-your-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Understand your Data&lt;/h2&gt;
&lt;p&gt;How big is the data? Checking the size and also type of variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 768   9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(sapply(diabetes, class))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pregnancies&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Glucose&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;BloodPressure&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;SkinThickness&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Insulin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;BMI&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;DiabetesPedigreeFunction&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Outcome&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Next, what catches my attention is &lt;strong&gt;unexpected zero values in Insulin&lt;/strong&gt; below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(head(diabetes))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Pregnancies&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Glucose&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BloodPressure&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SkinThickness&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Insulin&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BMI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;DiabetesPedigreeFunction&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;148&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.351&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;183&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.672&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.167&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;168&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;116&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.201&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;missing-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Missing Values&lt;/h2&gt;
&lt;p&gt;Summary gives a good overview of the variables. Any missing data will show up here listed as &lt;strong&gt;“NA’s”&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Pregnancies        Glucose      BloodPressure    SkinThickness  
##  Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  
##  1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  
##  Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  
##  Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  
##  3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  
##  Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  
##     Insulin           BMI        DiabetesPedigreeFunction      Age       
##  Min.   :  0.0   Min.   : 0.00   Min.   :0.0780           Min.   :21.00  
##  1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00  
##  Median : 30.5   Median :32.00   Median :0.3725           Median :29.00  
##  Mean   : 79.8   Mean   :31.99   Mean   :0.4719           Mean   :33.24  
##  3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  
##  Max.   :846.0   Max.   :67.10   Max.   :2.4200           Max.   :81.00  
##     Outcome     
##  Min.   :0.000  
##  1st Qu.:0.000  
##  Median :0.000  
##  Mean   :0.349  
##  3rd Qu.:1.000  
##  Max.   :1.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will make visualizations of the variables to see how they are distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- melt(diabetes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No id variables; using all as measure variables&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(gg, aes(x=value, fill=variable)) +
  geom_histogram(binwidth=5)+ 
  facet_wrap(~variable) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/Check%20out%20how%20variables%20are%20distributed-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Peaks at zero of Skin Thickness and Insulin is obvious here.&lt;/p&gt;
&lt;p&gt;In cases where the numbers are small we might remove them. &lt;strong&gt;Let’s figure it out with a for loop.&lt;/strong&gt; and then visualize on a waffle plot.&lt;/p&gt;
&lt;p&gt;This will bring me the number of zero containing rows in variables from 2 to 6.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zero_rows &amp;lt;- list()
for(i in 2:6){
zero_rows[[i]] &amp;lt;- length(which(diabetes[,i] == 0))  
}
rows_with_zero &amp;lt;- unlist(zero_rows)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Feed those numbers to a waffle plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zeros &amp;lt;- c(&amp;quot;Glucose&amp;quot; =rows_with_zero[1], &amp;quot;Blood Pressure&amp;quot; = rows_with_zero[2], 
           &amp;quot;Skin Thickness&amp;quot;= rows_with_zero[3], &amp;quot;Insulin&amp;quot; =rows_with_zero[4], 
           &amp;quot;BMI&amp;quot; = rows_with_zero[5])
waffle(zeros, rows=20) + theme(text = element_text(size=15)) + ggtitle(&amp;quot;Number of rows with zero&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/waffle%20plot%20of%20zero%20values-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(rows_with_zero, row.names = names(diabetes[2:6]))
df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               rows_with_zero
## Glucose                    5
## BloodPressure             35
## SkinThickness            227
## Insulin                  374
## BMI                       11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, in Insulin &lt;strong&gt;374&lt;/strong&gt; values are zero. Other variables also contain zeros. It is impossible to have Blood Pressure or Glucose levels at 0. It is unlikely that those are simply entry mistakes. It seems missing values are filled with &lt;strong&gt;zeros&lt;/strong&gt; in the data collection phase.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to circumwent this?&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;convert-all-zeroes-to-nas-and-then-perform-median-imputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Convert all &lt;strong&gt;zeroes&lt;/strong&gt; to &lt;strong&gt;NAs&lt;/strong&gt; and then perform &lt;strong&gt;Median Imputation&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;I will use a for loop to remove zeros in all the predictors except Pregnancy and Pedigree function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 2:6){
# Convert zeros to NAs
diabetes[, i][diabetes[, i] == 0] &amp;lt;- NA
# Calculate median
median &amp;lt;- median(diabetes[, i], na.rm = TRUE)
diabetes[, i][is.na(diabetes[, i])] &amp;lt;- median
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check if it really happened&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(head(diabetes))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Pregnancies&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Glucose&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BloodPressure&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SkinThickness&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Insulin&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BMI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;DiabetesPedigreeFunction&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;148&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.351&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;183&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.672&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;66&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;94&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.167&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;137&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;168&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;116&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;125&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.201&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For instance, I see that zero values in the insulin variable is replaced with median of insulin which is 125.&lt;/p&gt;
&lt;p&gt;Now, the data is clean and ready for the modeling phase.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-the-data-build-fit-and-validate-a-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Modeling the data (build, fit and validate a model)&lt;/h1&gt;
&lt;p&gt;Before going into any complicated model starting with a simple mode is a good idea. It might do surprisingly well and will give us more insights about the data.&lt;/p&gt;
&lt;div id=&#34;linear-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear Regression Model&lt;/h2&gt;
&lt;p&gt;We will create two random subsets of our data in 80/20 proportion as &lt;strong&gt;training and test data.&lt;/strong&gt;&lt;br /&gt;
Training data will be used to build our model and test data will be reserved to validate it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(22)
# Create train test split
sample_rows &amp;lt;- sample(nrow(diabetes), nrow(diabetes) * 0.8)
# Create the training dataset
dia_train &amp;lt;- diabetes[sample_rows, ]
# Create the test dataset
dia_test &amp;lt;- diabetes[-sample_rows, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Build a linear model with the train data
lm_dia &amp;lt;- lm(Outcome ~ .,data = dia_train)
summary(lm_dia)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Outcome ~ ., data = dia_train)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.01862 -0.28264 -0.07603  0.29983  0.86403 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)              -1.0441425  0.1180483  -8.845  &amp;lt; 2e-16 ***
## Pregnancies               0.0173561  0.0056433   3.076 0.002196 ** 
## Glucose                   0.0063034  0.0006150  10.250  &amp;lt; 2e-16 ***
## BloodPressure            -0.0013212  0.0014700  -0.899 0.369137    
## SkinThickness             0.0008966  0.0023291   0.385 0.700395    
## Insulin                  -0.0003233  0.0002088  -1.548 0.122077    
## BMI                       0.0150019  0.0030523   4.915 1.15e-06 ***
## DiabetesPedigreeFunction  0.1661357  0.0489591   3.393 0.000736 ***
## Age                       0.0036157  0.0017283   2.092 0.036845 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.3966 on 605 degrees of freedom
## Multiple R-squared:  0.3174, Adjusted R-squared:  0.3084 
## F-statistic: 35.17 on 8 and 605 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We will predict the Outcome for the test data
p&amp;lt;-predict(lm_dia, dia_test)
# Choose a threshold 0.5 to calculate the accuracy of our model
p_05 &amp;lt;- ifelse(p &amp;gt; 0.5, 1, 0)
table(p_05, dia_test$Outcome)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     
## p_05  0  1
##    0 85 17
##    1 15 37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will build a confusion matrix to calculate how accurate our model is in this particular random train/test split and at 0.5 thereshold level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat &amp;lt;- table(p_05, dia_test$Outcome)
accuracy &amp;lt;- sum(diag(conf_mat))/sum(conf_mat)
accuracy&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7922078&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;roc&lt;/strong&gt; function pROC package, can plot us a ROC curve which tests accuracy of our model at multiple threshold levels and is a good estimate on how well our model is performing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Calculate AUC(Area under the curve)
roc(dia_test$Outcome, p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting levels: control = 0, case = 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting direction: controls &amp;lt; cases&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## roc.default(response = dia_test$Outcome, predictor = p)
## 
## Data: p in 100 controls (dia_test$Outcome 0) &amp;lt; 54 cases (dia_test$Outcome 1).
## Area under the curve: 0.8498&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this process is little fragile, presence or absence of a single outlier might vastly change the results you might get from a given random train/test split.&lt;/p&gt;
&lt;p&gt;A better approach than a simple train/test split is using multiple test sets and averaging their accuracies.&lt;/p&gt;
&lt;p&gt;Let’s test that. I will create 1, 30 or 1000 random test sets, build models and compare their accuracies.&lt;/p&gt;
&lt;div id=&#34;how-to-apply-linear-model-with-multiple-traintest-split&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How to apply linear model with multiple train/test split&lt;/h4&gt;
&lt;p&gt;To do this, I will &lt;strong&gt;write a function&lt;/strong&gt; where I can choose number of independent train/test splits.&lt;/p&gt;
&lt;p&gt;It will return me an average value of the accuracy(auc) of the model after chosen number of iteration. The higher the number of random splits the more stable your estimated AUC will be.&lt;/p&gt;
&lt;p&gt;Let’s see how it will work out for our diabetes patients.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I will define my function as follows
multi_split &amp;lt;- function(x){
sample_rows &amp;lt;- list()
dia_train &amp;lt;- list()
dia_test &amp;lt;- list()
lm &amp;lt;- list()
p &amp;lt;-  list()
roc_auc &amp;lt;- list()
for(i in 1:x){
  sample_rows[[i]] &amp;lt;- sample(nrow(diabetes), nrow(diabetes) * 0.8)
  # Create the training dataset
  dia_train[[i]] &amp;lt;- diabetes[sample_rows[[i]], ]
  # Create the test dataset
  dia_test[[i]] &amp;lt;- diabetes[-sample_rows[[i]], ]
  lm[[i]] &amp;lt;- lm(Outcome ~ .,data = dia_train[[i]])
  p[[i]] &amp;lt;- predict(lm[[i]], dia_test[[i]])
  
  # Calculate AUC for all &amp;quot;x&amp;quot; number of random splits
  roc_auc[[i]] &amp;lt;- roc(dia_test[[i]]$Outcome, p[[i]])$auc[1]
  lm_mean &amp;lt;- mean(unlist(roc_auc))
}
print(mean(unlist(roc_auc)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s calculate the average AUC of our model after different number of random splits.&lt;/p&gt;
&lt;p&gt;I will run my &lt;strong&gt;multi_split() function&lt;/strong&gt; 3x for 1, 30 and 1000 random train/test splits. I can then compare variances at each level of sampling.&lt;/p&gt;
&lt;p&gt;Here are the results from my multi_site function at each randomization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_1 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8769133&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_2 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8283688&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1_3 &amp;lt;- multi_split(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8216108&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_1 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.840713&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_2 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8501071&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_30_3 &amp;lt;- multi_split(30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8294741&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_1 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8362065&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_2 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8364364&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auc_1000_3 &amp;lt;- multi_split(1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compare Variance levels at &lt;strong&gt;1, 30 and 1000&lt;/strong&gt; random splits&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_1_1, auc_1_2, auc_1_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0009101001&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_30_1, auc_30_2, auc_30_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0001067148&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(c(auc_1000_1, auc_1000_2, auc_1000_3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.672518e-07&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What we see here as we increase the number of iterations to 30 and 1000 the variability
gradually stabilizes around a trustable AUC of &lt;code&gt;0.836&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Seeing is believing. Let’s plot it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a data.frame containing accuracies
random_1X &amp;lt;- c(auc_1_1, auc_1_2, auc_1_3)
random_30X &amp;lt;- c(auc_30_1, auc_30_2, auc_30_3)
random_1000X &amp;lt;- c(auc_1000_1, auc_1000_2, auc_1000_3)

df_r &amp;lt;- data.frame(random_1X, random_30X, random_1000X)
df_r&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   random_1X random_30X random_1000X
## 1 0.8769133  0.8407130    0.8362065
## 2 0.8283688  0.8501071    0.8364364
## 3 0.8216108  0.8294741    0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Here, I will reformat my data for easy plotting by using gather() function from tidyr
# It takes multiple columns, and gathers them into key-value pairs: it makes “wide” data longer.
df_long &amp;lt;- gather(df_r, sampling, auc)
df_long&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       sampling       auc
## 1    random_1X 0.8769133
## 2    random_1X 0.8283688
## 3    random_1X 0.8216108
## 4   random_30X 0.8407130
## 5   random_30X 0.8501071
## 6   random_30X 0.8294741
## 7 random_1000X 0.8362065
## 8 random_1000X 0.8364364
## 9 random_1000X 0.8350323&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_long$sampling &amp;lt;- factor(df_long$sampling, levels = c(&amp;quot;random_1X&amp;quot;, &amp;quot;random_30X&amp;quot;, &amp;quot;random_1000X&amp;quot;))

# 
model_variation &amp;lt;- ggplot(df_long, aes(y=auc, x=sampling, fill=sampling)) + geom_boxplot() + theme(text = element_text(size=15), axis.title.x=element_blank(), legend.position = &amp;quot;none&amp;quot;) + ggtitle(&amp;quot;Variation in model performance&amp;quot;)
model_variation&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-10-01-can-machine-learning-change-your-life-style_files/figure-html/change%20in%20variance%20plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Great. We have a good estimate of our linear model performance.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;logistic-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression model&lt;/h2&gt;
&lt;p&gt;I will switch here to caret package. With the &lt;strong&gt;Train()&lt;/strong&gt; function we can test different types of machine learning algorithms.&lt;/p&gt;
&lt;p&gt;I will start with a logistic regression model. But before I need to convert Outcome variable into a factor with 2 levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Convert Outcome to a factor with two levels
diabetes$Outcome &amp;lt;- factor(diabetes$Outcome)
levels(diabetes$Outcome) &amp;lt;- c(&amp;quot;H&amp;quot;, &amp;quot;D&amp;quot;)

# MyControl
myControl &amp;lt;- trainControl(
  method = &amp;quot;cv&amp;quot;, 
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = TRUE
)
# Model
model_glm &amp;lt;- train(
  Outcome~.,
  method = &amp;quot;glm&amp;quot;,
  data = diabetes,
  trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## + Fold01: parameter=none 
## - Fold01: parameter=none 
## + Fold02: parameter=none 
## - Fold02: parameter=none 
## + Fold03: parameter=none 
## - Fold03: parameter=none 
## + Fold04: parameter=none 
## - Fold04: parameter=none 
## + Fold05: parameter=none 
## - Fold05: parameter=none 
## + Fold06: parameter=none 
## - Fold06: parameter=none 
## + Fold07: parameter=none 
## - Fold07: parameter=none 
## + Fold08: parameter=none 
## - Fold08: parameter=none 
## + Fold09: parameter=none 
## - Fold09: parameter=none 
## + Fold10: parameter=none 
## - Fold10: parameter=none 
## Aggregating results
## Fitting final model on full training set&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_glm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Generalized Linear Model 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;H&amp;#39;, &amp;#39;D&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 691, 691, 691, 691, 692, 691, ... 
## Resampling results:
## 
##   ROC        Sens   Spec     
##   0.8369744  0.874  0.5521368&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, My model performance is &lt;code&gt;0.8369744&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;glmnet-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Glmnet model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Model
model_glmnet &amp;lt;- train(
  Outcome~.,
  method = &amp;quot;glmnet&amp;quot;,
  data = diabetes,
  trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_glmnet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## glmnet 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;H&amp;#39;, &amp;#39;D&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 691, 691, 691, 691, 691, 691, ... 
## Resampling results across tuning parameters:
## 
##   alpha  lambda        ROC        Sens   Spec     
##   0.10   0.0004697604  0.8383818  0.878  0.5592593
##   0.10   0.0046976036  0.8392821  0.878  0.5592593
##   0.10   0.0469760360  0.8405043  0.892  0.5368946
##   0.55   0.0004697604  0.8383105  0.876  0.5629630
##   0.55   0.0046976036  0.8395954  0.878  0.5555556
##   0.55   0.0469760360  0.8388917  0.902  0.5216524
##   1.00   0.0004697604  0.8383846  0.876  0.5629630
##   1.00   0.0046976036  0.8402650  0.882  0.5554131
##   1.00   0.0469760360  0.8266125  0.904  0.4809117
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were alpha = 0.1 and lambda
##  = 0.04697604.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Glmnet model performance is &lt;code&gt;0.8405043&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random-forest-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random forest model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Random forest model
model_rf &amp;lt;- train(
  Outcome~.,
  method = &amp;quot;ranger&amp;quot;,
  data = diabetes,
  trControl = myControl
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_rf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Random Forest 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;H&amp;#39;, &amp;#39;D&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 691, 691, 691, 691, 691, 692, ... 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   ROC        Sens   Spec     
##   2     gini        0.8343091  0.844  0.6272080
##   2     extratrees  0.8354615  0.860  0.5820513
##   5     gini        0.8295798  0.838  0.6273504
##   5     extratrees  0.8339772  0.850  0.6084046
##   8     gini        0.8270470  0.832  0.6236467
##   8     extratrees  0.8359687  0.852  0.6195157
## 
## Tuning parameter &amp;#39;min.node.size&amp;#39; was held constant at a value of 1
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 8, splitrule =
##  extratrees and min.node.size = 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Random forest performance is &lt;code&gt;0.8359687&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gradient-boost-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gradient boost model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_gbm &amp;lt;- train(
    Outcome~.,
    method = &amp;quot;gbm&amp;quot;,
    data = diabetes,
    trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_gbm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Stochastic Gradient Boosting 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;H&amp;#39;, &amp;#39;D&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 691, 691, 691, 691, 691, 691, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  ROC        Sens   Spec     
##   1                   50      0.8360014  0.890  0.5373219
##   1                  100      0.8422849  0.876  0.5749288
##   1                  150      0.8407721  0.868  0.5787749
##   2                   50      0.8362051  0.864  0.5559829
##   2                  100      0.8399658  0.856  0.6047009
##   2                  150      0.8346097  0.842  0.6195157
##   3                   50      0.8330570  0.852  0.5896011
##   3                  100      0.8310883  0.846  0.6008547
##   3                  150      0.8254929  0.846  0.5864672
## 
## Tuning parameter &amp;#39;shrinkage&amp;#39; was held constant at a value of 0.1
## 
## Tuning parameter &amp;#39;n.minobsinnode&amp;#39; was held constant at a value of 10
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 100,
##  interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gradient boost model performance is &lt;code&gt;0.8422849&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-bayes-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Naive Bayes model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_nb &amp;lt;- train(
    Outcome~.,
    method = &amp;quot;nb&amp;quot;,
    data = diabetes,
    trControl = myControl
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_nb&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Naive Bayes 
## 
## 768 samples
##   8 predictor
##   2 classes: &amp;#39;H&amp;#39;, &amp;#39;D&amp;#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 691, 691, 691, 691, 692, 691, ... 
## Resampling results across tuning parameters:
## 
##   usekernel  ROC        Sens   Spec     
##   FALSE      0.8089573  0.828  0.5964387
##    TRUE      0.8104530  0.822  0.6113960
## 
## Tuning parameter &amp;#39;fL&amp;#39; was held constant at a value of 0
## Tuning
##  parameter &amp;#39;adjust&amp;#39; was held constant at a value of 1
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were fL = 0, usekernel = TRUE
##  and adjust = 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Naive Bayes model performance is &lt;code&gt;0.810453&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- c(&amp;quot;lm&amp;quot;, &amp;quot;glm&amp;quot;, &amp;quot;glmnet&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;gbm&amp;quot;, &amp;quot;naive&amp;quot;)
lm &amp;lt;- round(mean(c(auc_1000_1, auc_1000_2, auc_1000_3)), 3)
glm &amp;lt;- max(model_glm$results$ROC)
glmnet &amp;lt;- max(model_glmnet$results$ROC)
rf &amp;lt;- max(model_rf$results$ROC)
gbm &amp;lt;- max(model_gbm$results$ROC)
naive &amp;lt;- max(model_nb$results$ROC)
AUC &amp;lt;- c(lm, glm, glmnet, rf, gbm, naive)
df &amp;lt;- data.frame(models, AUC)
knitr::kable(df[order(df[,2], decreasing=TRUE), ])&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;models&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;AUC&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;gbm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8422849&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glmnet&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8405043&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;glm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8369744&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;lm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8360000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;rf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8359687&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;naive&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8104530&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here, we found Gradient boost model performed the best, and also there are not big differences between the models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Future thoughts&lt;/h2&gt;
&lt;p&gt;I used different machine learning algorithms to predict Diabetes. Models showed similar performances except the naives bayes which performed worst here. &lt;strong&gt;As we saw, sometimes a simple model can get us far.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can help doctors to predict &lt;strong&gt;Diabetes with accuracy around 84%&lt;/strong&gt; by using 8 simple medical parameters.&lt;/p&gt;
&lt;p&gt;Given current speed in generation and collection of types data by including additonal predictors we can build even better models.&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
&lt;p&gt;Serdar&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Wrangling for Text mining: Extract individual elements from a Book</title>
      <link>/2019/09/25/text-mining-extracting-elements/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/2019/09/25/text-mining-extracting-elements/</guid>
      <description>


&lt;p&gt;My ambitious goal is to write a machine learning algorithm that predicts the authors. But let’s start with something simpler.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.gutenberg.org/&#34;&gt;Project Gutenberg&lt;/a&gt; is a library of over 60,000 free eBooks. I will work on a Poetry book called “New Poems” from D. H. Lawrence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The goal is to isolate each poem individually for text mining analysis later.&lt;/strong&gt; Hints on internet was not plenty so I decided to figure out a solution myself.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    I will use the table of contents section to &lt;strong&gt;fish out each poem separately&lt;/strong&gt; by using two &lt;strong&gt;for loops.&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;install-the-required-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Install the required packages&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(stringr)
library(stringi)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;copy-the-book-from-dh-lawrence-new-poems&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Copy the book from DH Lawrence “New Poems”&lt;/h3&gt;
&lt;p&gt;Since there were some mistakes in the .txt version of the book I copied the text from the html version at &lt;a href=&#34;http://www.gutenberg.org/files/22726/22726-h/22726-h.htm&#34;&gt;gutenbergr website&lt;/a&gt; and pasted it in a txt file and saved to my working directory.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lawrence &amp;lt;- readLines(&amp;quot;posts_data/lawrence_new_poems.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our file contains &lt;code&gt;2181&lt;/code&gt; lines. With square brackets [ ] we can view the lines we are interested. Let’s look at the first few lines;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lawrence[1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;&amp;quot;                                                                    
## [2] &amp;quot;The Project Gutenberg EBook of New Poems, by D. H. Lawrence&amp;quot;         
## [3] &amp;quot;&amp;quot;                                                                    
## [4] &amp;quot;This eBook is for the use of anyone anywhere at no cost and with&amp;quot;    
## [5] &amp;quot;almost no restrictions whatsoever.  You may copy it, give it away or&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;a href=&#34;http://www.gutenberg.org/files/22726/22726-h/22726-h.htm&#34;&gt;book&lt;/a&gt; has 42 poems in total. Table of contents (TOC) starts with the line “CONTENTS” and ends with the line “ON THAT DAY”&lt;/p&gt;
&lt;p&gt;I will use those lines to extract the TOC. Stringr package comes in handy here. &lt;strong&gt;str_which()&lt;/strong&gt; function returns line index numbers for a given term.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start &amp;lt;- str_which(lawrence, pattern = fixed(&amp;quot;CONTENTS&amp;quot;))
start&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 53&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lawrence[start]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;CONTENTS&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We are choosing first appearance of &amp;quot;ON THAT DAY&amp;quot; with [1] because it appears 
# also in the Poem title later.
end &amp;lt;-  str_which(lawrence, pattern = fixed(&amp;quot;ON THAT DAY&amp;quot;))[1]
end&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 137&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lawrence[end]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;ON THAT DAY&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Slicing the lines from &lt;code&gt;54&lt;/code&gt; to &lt;code&gt;137&lt;/code&gt; will give us the TOC.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TOC &amp;lt;- lawrence[(start+1):(end)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To remove empty spaces I will use here &lt;strong&gt;stri_remove_empty()&lt;/strong&gt; function from &lt;strong&gt;stringi&lt;/strong&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TOC &amp;lt;- stri_remove_empty(TOC)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look at how the clean TOC looks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TOC &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;APPREHENSION&amp;quot;               &amp;quot;COMING AWAKE&amp;quot;              
##  [3] &amp;quot;FROM A COLLEGE WINDOW&amp;quot;      &amp;quot;FLAPPER&amp;quot;                   
##  [5] &amp;quot;BIRDCAGE WALK&amp;quot;              &amp;quot;LETTER FROM TOWN: THE&amp;quot;     
##  [7] &amp;quot;FLAT SUBURBS, S.W., IN THE&amp;quot; &amp;quot;THIEF IN THE NIGHT&amp;quot;        
##  [9] &amp;quot;LETTER FROM TOWN: ON A&amp;quot;     &amp;quot;SUBURBS ON A HAZY DAY&amp;quot;     
## [11] &amp;quot;HYDE PARK AT NIGHT, BEFORE&amp;quot; &amp;quot;GIPSY&amp;quot;                     
## [13] &amp;quot;TWO-FOLD&amp;quot;                   &amp;quot;UNDER THE OAK&amp;quot;             
## [15] &amp;quot;SIGH NO MORE&amp;quot;               &amp;quot;LOVE STORM&amp;quot;                
## [17] &amp;quot;PARLIAMENT HILL IN THE&amp;quot;     &amp;quot;PICCADILLY CIRCUS AT NIGHT&amp;quot;
## [19] &amp;quot;TARANTELLA&amp;quot;                 &amp;quot;IN CHURCH&amp;quot;                 
## [21] &amp;quot;PIANO&amp;quot;                      &amp;quot;EMBANKMENT AT NIGHT,&amp;quot;      
## [23] &amp;quot;PHANTASMAGORIA&amp;quot;             &amp;quot;NEXT MORNING&amp;quot;              
## [25] &amp;quot;PALIMPSEST OF TWILIGHT&amp;quot;     &amp;quot;EMBANKMENT AT NIGHT,&amp;quot;      
## [27] &amp;quot;WINTER IN THE BOULEVARD&amp;quot;    &amp;quot;SCHOOL ON THE OUTSKIRTS&amp;quot;   
## [29] &amp;quot;SICKNESS&amp;quot;                   &amp;quot;EVERLASTING FLOWERS&amp;quot;       
## [31] &amp;quot;THE NORTH COUNTRY&amp;quot;          &amp;quot;BITTERNESS OF DEATH&amp;quot;       
## [33] &amp;quot;SEVEN SEALS&amp;quot;                &amp;quot;READING A LETTER&amp;quot;          
## [35] &amp;quot;TWENTY YEARS AGO&amp;quot;           &amp;quot;INTIME&amp;quot;                    
## [37] &amp;quot;TWO WIVES&amp;quot;                  &amp;quot;HEIMWEH&amp;quot;                   
## [39] &amp;quot;DEBACLE&amp;quot;                    &amp;quot;NARCISSUS&amp;quot;                 
## [41] &amp;quot;AUTUMN SUNSHINE&amp;quot;            &amp;quot;ON THAT DAY&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we will extract main text containing only the poems without metadata. We need to slice the document starting from the end of the contents &lt;code&gt;(end)&lt;/code&gt; till end of the last poem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# After the last poem some metadata starts with &amp;quot;End of the Project...&amp;quot;
# We will slice until this line
end_main &amp;lt;- str_which(lawrence, &amp;quot;End of the Project Gutenberg EBook of New Poems, by D. H. Lawrence&amp;quot;)
# Capture main text
lawrence_body &amp;lt;- lawrence[(end+1):(end_main -1)]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-for-loop&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First for loop&lt;/h3&gt;
&lt;p&gt;We will use a &lt;code&gt;for loop&lt;/code&gt; to get the index numbers of the title’s of each poem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First initiate an empty list
index &amp;lt;- list()
# For loop
for (i in 1:42) {
index[[i]] &amp;lt;- str_which(lawrence_body, pattern = TOC[i])
}

index&amp;lt;- unlist(index)
index&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]    9   37   59   82  110  126  164  192  209  253  276  314  332  347
## [15]  387  428  473  496  536  570  593  621  768  664  707  745  621  768
## [29]  901  933  958  990 1057 1100 1193 1253 1286 1313 1376 1502 1527 1571
## [43] 1606 1644&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;for loop&lt;/code&gt; we created here uses each title in TOC as a pattern inside a &lt;strong&gt;str_which()&lt;/strong&gt; function to find the index number where it detects this pattern.&lt;/p&gt;
&lt;p&gt;For example TOC[1] will use the title of first poem as a pattern and it will return the line number where the poem starts. &lt;strong&gt;At the end, we will have a list of starting lines of each poem.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TOC[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;APPREHENSION&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_which(lawrence_body, pattern = TOC[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# e.g. The poem Apprehension starts at line index number 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Selecting the lines from the beginning of the &lt;strong&gt;first poem&lt;/strong&gt; until the beginning of the &lt;strong&gt;second poem&lt;/strong&gt; will give us the first poem. By iterating everything by +1 we will capture all 42 poems.&lt;/p&gt;
&lt;p&gt;Since the title EMBANKMENT AT NIGHT appears in the titles of two poems we will do a slight correction here. To remove those duplicates I will remove first apperance of index 768 and second appearence of 621.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;index &amp;lt;- index[-c(23,27)]
index&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]    9   37   59   82  110  126  164  192  209  253  276  314  332  347
## [15]  387  428  473  496  536  570  593  621  664  707  745  768  901  933
## [29]  958  990 1057 1100 1193 1253 1286 1313 1376 1502 1527 1571 1606 1644&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(index)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 42&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Not to miss the last poem, I have to add the line index of the
# end of the main text
index[43] &amp;lt;- end_main -1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we have 42 index numbers matching the title of each poem 1 index number to label the end of the main text. We will use those to extract poems separetely.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;second-for-loop&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Second for loop&lt;/h3&gt;
&lt;p&gt;It’s time for the trick. Finally we can capture each 42 poem separately in a list by using a second &lt;code&gt;for loop.&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create an empty list: poems
poems &amp;lt;- list()
for (i in 1:42) {
    
    poems[[i]] &amp;lt;- lawrence_body[(index[i]:index[i+1]-1)]  
}
# Visualize the first poem
writeLines(poems[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## APPREHENSION
## AND all hours long, the town
##        Roars like a beast in a cave
##      That is wounded there
##      And like to drown;
##        While days rush, wave after wave
##      On its lair.
## 
##      An invisible woe unseals
##        The flood, so it passes beyond
##      All bounds: the great old city
##      Recumbent roars as it feels
##        The foamy paw of the pond
##      Reach from immensity.
## 
##      But all that it can do
##        Now, as the tide rises,
##      Is to listen and hear the grim
##      Waves crash like thunder through
##        The splintered streets, hear noises
##      Roll hollow in the interim.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s check if we got what we wanted&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(poems)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 42
##  $ : chr [1:29] &amp;quot;&amp;quot; &amp;quot;APPREHENSION&amp;quot; &amp;quot;AND all hours long, the town&amp;quot; &amp;quot;       Roars like a beast in a cave&amp;quot; ...
##  $ : chr [1:23] &amp;quot;&amp;quot; &amp;quot;COMING AWAKE&amp;quot; &amp;quot;WHEN I woke, the lake-lights were quivering on the&amp;quot; &amp;quot;          wall,&amp;quot; ...
##  $ : chr [1:24] &amp;quot;&amp;quot; &amp;quot;FROM A COLLEGE WINDOW&amp;quot; &amp;quot;THE glimmer of the limes, sun-heavy, sleeping,&amp;quot; &amp;quot;        Goes trembling past me up the College wall.&amp;quot; ...
##  $ : chr [1:29] &amp;quot;&amp;quot; &amp;quot;FLAPPER&amp;quot; &amp;quot;LOVE has crept out of her sealéd heart&amp;quot; &amp;quot;       As a field-bee, black and amber,&amp;quot; ...
##  $ : chr [1:17] &amp;quot;&amp;quot; &amp;quot;BIRDCAGE WALK&amp;quot; &amp;quot;WHEN the wind blows her veil&amp;quot; &amp;quot;       And uncovers her laughter&amp;quot; ...
##  $ : chr [1:39] &amp;quot;&amp;quot; &amp;quot;LETTER FROM TOWN: THE&amp;quot; &amp;quot;ALMOND TREE&amp;quot; &amp;quot;YOU promised to send me some violets. Did you&amp;quot; ...
##  $ : chr [1:29] &amp;quot;&amp;quot; &amp;quot;FLAT SUBURBS, S.W., IN THE&amp;quot; &amp;quot;MORNING&amp;quot; &amp;quot;THE new red houses spring like plants&amp;quot; ...
##  $ : chr [1:18] &amp;quot;&amp;quot; &amp;quot;THIEF IN THE NIGHT&amp;quot; &amp;quot;LAST night a thief came to me&amp;quot; &amp;quot;       And struck at me with something dark.&amp;quot; ...
##  $ : chr [1:45] &amp;quot;&amp;quot; &amp;quot;LETTER FROM TOWN: ON A&amp;quot; &amp;quot;GREY EVENING IN MARCH&amp;quot; &amp;quot;THE clouds are pushing in grey reluctance slowly&amp;quot; ...
##  $ : chr [1:24] &amp;quot;&amp;quot; &amp;quot;SUBURBS ON A HAZY DAY&amp;quot; &amp;quot;     O STIFFLY shapen houses that change not,&amp;quot; &amp;quot;       What conjuror&amp;#39;s cloth was thrown across you,&amp;quot; ...
##  $ : chr [1:39] &amp;quot;&amp;quot; &amp;quot;HYDE PARK AT NIGHT, BEFORE&amp;quot; &amp;quot;THE WAR&amp;quot; &amp;quot;     Clerks.&amp;quot; ...
##  $ : chr [1:19] &amp;quot;&amp;quot; &amp;quot;GIPSY&amp;quot; &amp;quot;     I, THE man with the red scarf,&amp;quot; &amp;quot;        Will give thee what I have, this last week&amp;#39;s earn-&amp;quot; ...
##  $ : chr [1:16] &amp;quot;&amp;quot; &amp;quot;TWO-FOLD&amp;quot; &amp;quot;     How gorgeous that shock of red lilies, and larkspur&amp;quot; &amp;quot;         cleaving&amp;quot; ...
##  $ : chr [1:41] &amp;quot;&amp;quot; &amp;quot;UNDER THE OAK&amp;quot; &amp;quot;     You, if you were sensible,&amp;quot; &amp;quot;     When I tell you the stars flash signals, each one&amp;quot; ...
##  $ : chr [1:42] &amp;quot;&amp;quot; &amp;quot;SIGH NO MORE&amp;quot; &amp;quot;THE cuckoo and the coo-dove&amp;#39;s ceaseless calling,&amp;quot; &amp;quot;                    Calling,&amp;quot; ...
##  $ : chr [1:46] &amp;quot;&amp;quot; &amp;quot;LOVE STORM&amp;quot; &amp;quot;MANY roses in the wind&amp;quot; &amp;quot;     Are tapping at the window-sash.&amp;quot; ...
##  $ : chr [1:24] &amp;quot;&amp;quot; &amp;quot;PARLIAMENT HILL IN THE&amp;quot; &amp;quot;EVENING&amp;quot; &amp;quot;THE houses fade in a melt of mist&amp;quot; ...
##  $ : chr [1:41] &amp;quot;&amp;quot; &amp;quot;PICCADILLY CIRCUS AT NIGHT&amp;quot; &amp;quot;     Street-Walkers.&amp;quot; &amp;quot;WHEN into the night the yellow light is roused like&amp;quot; ...
##  $ : chr [1:35] &amp;quot;&amp;quot; &amp;quot;TARANTELLA&amp;quot; &amp;quot;SAD as he sits on the white sea-stone&amp;quot; &amp;quot;     And the suave sea chuckles, and turns to the moon,&amp;quot; ...
##  $ : chr [1:24] &amp;quot;&amp;quot; &amp;quot;IN CHURCH&amp;quot; &amp;quot;IN the choir the boys are singing the hymn.&amp;quot; &amp;quot;             The morning light on their lips&amp;quot; ...
##  $ : chr [1:29] &amp;quot;&amp;quot; &amp;quot;PIANO&amp;quot; &amp;quot;     Softly, in the dusk, a woman is singing to me;&amp;quot; &amp;quot;     Taking me back down the vista of years, till I see&amp;quot; ...
##  $ : chr [1:44] &amp;quot;&amp;quot; &amp;quot;EMBANKMENT AT NIGHT,&amp;quot; &amp;quot;BEFORE THE WAR&amp;quot; &amp;quot;     Charity.&amp;quot; ...
##  $ : chr [1:44] &amp;quot;&amp;quot; &amp;quot;PHANTASMAGORIA&amp;quot; &amp;quot;RIGID sleeps the house in darkness, I alone&amp;quot; &amp;quot;     Like a thing unwarrantable cross the hall&amp;quot; ...
##  $ : chr [1:39] &amp;quot;&amp;quot; &amp;quot;NEXT MORNING&amp;quot; &amp;quot;     How have I wandered here to this vaulted room&amp;quot; &amp;quot;     In the house of life?—the floor was ruffled with gold&amp;quot; ...
##  $ : chr [1:24] &amp;quot;&amp;quot; &amp;quot;PALIMPSEST OF TWILIGHT&amp;quot; &amp;quot;DARKNESS comes out of the earth&amp;quot; &amp;quot;       And swallows dip into the pallor of the west;&amp;quot; ...
##  $ : chr [1:134] &amp;quot;&amp;quot; &amp;quot;EMBANKMENT AT NIGHT,&amp;quot; &amp;quot;BEFORE THE WAR&amp;quot; &amp;quot;     Outcasts.&amp;quot; ...
##  $ : chr [1:33] &amp;quot;&amp;quot; &amp;quot;WINTER IN THE BOULEVARD&amp;quot; &amp;quot;THE frost has settled down upon the trees&amp;quot; &amp;quot;     And ruthlessly strangled off the fantasies&amp;quot; ...
##  $ : chr [1:26] &amp;quot;&amp;quot; &amp;quot;SCHOOL ON THE OUTSKIRTS&amp;quot; &amp;quot;     How different, in the middle of snows, the great&amp;quot; &amp;quot;          school rises red!&amp;quot; ...
##  $ : chr [1:33] &amp;quot;&amp;quot; &amp;quot;SICKNESS&amp;quot; &amp;quot;WAVING slowly before me, pushed into the dark,&amp;quot; &amp;quot;     Unseen my hands explore the silence, drawing the&amp;quot; ...
##  $ : chr [1:68] &amp;quot;&amp;quot; &amp;quot;EVERLASTING FLOWERS&amp;quot; &amp;quot;WHO do you think stands watching&amp;quot; &amp;quot;       The snow-tops shining rosy&amp;quot; ...
##  $ : chr [1:44] &amp;quot;&amp;quot; &amp;quot;THE NORTH COUNTRY&amp;quot; &amp;quot;IN another country, black poplars shake them-&amp;quot; &amp;quot;         selves over a pond,&amp;quot; ...
##  $ : chr [1:94] &amp;quot;&amp;quot; &amp;quot;BITTERNESS OF DEATH&amp;quot; &amp;quot;     I&amp;quot; &amp;quot;AH, stern, cold man,&amp;quot; ...
##  $ : chr [1:61] &amp;quot;&amp;quot; &amp;quot;SEVEN SEALS&amp;quot; &amp;quot;SINCE this is the last night I keep you home,&amp;quot; &amp;quot;     Come, I will consecrate you for the journey.&amp;quot; ...
##  $ : chr [1:34] &amp;quot;&amp;quot; &amp;quot;READING A LETTER&amp;quot; &amp;quot;SHE sits on the recreation ground&amp;quot; &amp;quot;       Under an oak whose yellow buds dot the pale&amp;quot; ...
##  $ : chr [1:28] &amp;quot;&amp;quot; &amp;quot;TWENTY YEARS AGO&amp;quot; &amp;quot;ROUND the house were lilacs and strawberries&amp;quot; &amp;quot;       And foal-foots spangling the paths,&amp;quot; ...
##  $ : chr [1:64] &amp;quot;&amp;quot; &amp;quot;INTIME&amp;quot; &amp;quot;RETURNING, I find her just the same,&amp;quot; &amp;quot;     At just the same old delicate game.&amp;quot; ...
##  $ : chr [1:127] &amp;quot;&amp;quot; &amp;quot;TWO WIVES&amp;quot; &amp;quot;     I&amp;quot; &amp;quot;INTO the shadow-white chamber silts the white&amp;quot; ...
##  $ : chr [1:26] &amp;quot;&amp;quot; &amp;quot;HEIMWEH&amp;quot; &amp;quot;FAR-OFF the lily-statues stand white-ranked in the&amp;quot; &amp;quot;         garden at home.&amp;quot; ...
##  $ : chr [1:45] &amp;quot;&amp;quot; &amp;quot;DEBACLE&amp;quot; &amp;quot;THE trees in trouble because of autumn,&amp;quot; &amp;quot;       And scarlet berries falling from the bush,&amp;quot; ...
##  $ : chr [1:36] &amp;quot;&amp;quot; &amp;quot;NARCISSUS&amp;quot; &amp;quot;WHERE the minnows trace&amp;quot; &amp;quot;     A glinting web quick hid in the gloom of the brook,&amp;quot; ...
##  $ : chr [1:39] &amp;quot;&amp;quot; &amp;quot;AUTUMN SUNSHINE&amp;quot; &amp;quot;THE sun sets out the autumn crocuses&amp;quot; &amp;quot;       And fills them up a pouring measure&amp;quot; ...
##  $ : chr [1:173] &amp;quot;&amp;quot; &amp;quot;ON THAT DAY&amp;quot; &amp;quot;   ON that day&amp;quot; &amp;quot;     I shall put roses on roses, and cover your grave&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;final-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final Thoughts&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt; is one crucial step in Data Science as data comes rarely ready to use.&lt;/p&gt;
&lt;p&gt;Here, starting from a Poetry Book I isolated each poem separately in a list. Hard part is done. &lt;strong&gt;Now, I can identify how many rhymes each poem contains, word usage across different poems, the similarities between them and many more to gain insights about the author.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I could also analyze the whole book as a single document but by isolating each element I will gain much deeper insight from the data.&lt;/p&gt;
&lt;p&gt;Do you apply similar techniques to isolate chapters or sections from the book or documents to compare and contrast different parts?&lt;/p&gt;
&lt;p&gt;Thank you for reading this post. Please feel free to comment below with your thoughts/feedback.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Genomics at superresolution: Mapping Drug targets on single cell resolution in Fibrosis</title>
      <link>/2019/09/17/genomics-at-superresolution/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/2019/09/17/genomics-at-superresolution/</guid>
      <description>


&lt;p&gt;Advances in &lt;strong&gt;microfluidic technologies&lt;/strong&gt; enabled us to barcode single cells in lipid droplets and to &lt;strong&gt;resolve genomes of individual cells&lt;/strong&gt; from a sequencing mixture (e.g, &lt;a href=&#34;https://www.10xgenomics.com/&#34;&gt;10X Genomics&lt;/a&gt;). By using &lt;strong&gt;Single cell RNA sequencing (scRNA-seq)&lt;/strong&gt; we can discover &lt;strong&gt;rare cell populations&lt;/strong&gt; and genes that are specifically acting in those. Potential is high and the list of publications growing daily.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you are a scientist in a biotech exploring novel targets those might be a great source to &lt;strong&gt;gather specific information&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/Seurat/index.html&#34;&gt;Seurat&lt;/a&gt; package is a great tool for digging into single cell datasets. It will open you access beyond what is in the publications. You can find many tutorials in their &lt;a href=&#34;https://satijalab.org/seurat/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here, I will focus on a recent &lt;a href=&#34;https://www.atsjournals.org/doi/pdf/10.1164/rccm.201712-2410OC&#34;&gt;paper&lt;/a&gt; which explored transcriptome of lung cells from Pulmonary fibrosis patients by scRNAseq.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pulmonary fibrosis&lt;/strong&gt; is a progressive scarring of the lung tissue leading to death within 3-4 years.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Current therapies does not increase the survival&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Many Biotech companies are developing &lt;strong&gt;novel drugs&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    What types of cells those drugs are acting on?
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Our workflow will be in three steps&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Basic Seurat workflow&lt;/li&gt;
&lt;li&gt;Identify cell types on a tSNE plot&lt;/li&gt;
&lt;li&gt;Visualize drug targets on single cell plots&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I picked up scRNA-seq data from a patient with Polymyositis associated intersitial lung disease.&lt;/p&gt;
&lt;p&gt;—&amp;gt; &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3489196&#34;&gt;Download Single Cell RNA seq data&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;seurat-workflow&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Seurat Workflow&lt;/h3&gt;
&lt;p&gt;Load the packages that will be used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;importing-the-h5-file&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Importing the h5 file&lt;/h3&gt;
&lt;p&gt;Here the data comes as an &lt;strong&gt;h5 file.&lt;/strong&gt; But no worries, we can handle that with &lt;strong&gt;Read10X_h5&lt;/strong&gt; function in Seurat. Since the file is directly under my working directory I can apply &lt;code&gt;Read10X_h5(&#34;Filename.h5&#34;)&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MyoILD_01 &amp;lt;- Read10X_h5(&amp;quot;posts_data/GSM3489196_Myositis-ILD_01_filtered_gene_bc_matrices_h5.h5&amp;quot;)
Fib &amp;lt;- CreateSeuratObject(counts = MyoILD_01, min.cells = 3, project= &amp;quot;FightFibrosis&amp;quot;, min.features = 200)
Fib&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class Seurat 
## 20246 features across 7163 samples within 1 assay 
## Active assay: RNA (20246 features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our Data matrix now contains &lt;strong&gt;20246&lt;/strong&gt; genes and &lt;strong&gt;7163&lt;/strong&gt; cells&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-quick-look-at-the-raw-count-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A Quick look at the raw count data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Lets examine a few genes in the first thirty cells
MyoILD_01[c(&amp;quot;SPP1&amp;quot;,&amp;quot;TGFB1&amp;quot;,&amp;quot;CCL2&amp;quot;), 1:30]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3 x 30 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
##                                                                    
## SPP1  1 . . 2 . . . 33 . . 1 . . . . . . . . . . . . . . . 9 . . 20
## TGFB1 . . . . 1 . .  . . . . . . . 1 . 3 . . . . . . . 1 2 . . .  .
## CCL2  5 . . 2 . . .  . . . . . . . . . . . . . . . . . . . . . .  .&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-pre-processing-workflow-for-scrna-seq-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Standard pre-processing workflow for scRNA-seq data&lt;/h3&gt;
&lt;p&gt;Pre-processing involves filtration of cells based on Quality control metrics (e.g .mitochondrial contamination, Coverage). We will proceed by normalization and identification of the highly variable features then at the end we will scale the data.&lt;/p&gt;
&lt;div id=&#34;qc-and-selecting-cells-for-further-analysis&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;QC and selecting cells for further analysis&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s add Mitochondrial stats to Fib data. [[ operator can add 
# columns to object metadata. 

Fib[[&amp;quot;percent.mt&amp;quot;]] &amp;lt;- PercentageFeatureSet(object = Fib, pattern = &amp;quot;^MT-&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quick look at the Quality control metrics for the first 5 cells
head(x = Fib@meta.data, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       orig.ident nCount_RNA nFeature_RNA percent.mt
## AAACCTGAGATCCCGC-1 FightFibrosis       2257         1010   4.386354
## AAACCTGAGCAGCCTC-1 FightFibrosis       3367          713  66.914167
## AAACCTGAGCCAGAAC-1 FightFibrosis       7354         1943   3.929834
## AAACCTGAGGGATGGG-1 FightFibrosis       9323         2786   8.430763
## AAACCTGAGTCGTACT-1 FightFibrosis       2937         1125   6.775621&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;violin-plots-to-visualize-qc-metrics&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Violin plots to visualize QC metrics&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Visualize QC metrics as a violin plot
VlnPlot(object = Fib, features = c(&amp;quot;nFeature_RNA&amp;quot;, &amp;quot;nCount_RNA&amp;quot;, &amp;quot;percent.mt&amp;quot;),
        ncol = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/qc2-1.png&#34; width=&#34;1248&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We will use FeatureScatter to visualize feature-feature relationships like 
# RNA counts or percentage of mitochondiral contamination

plot1 &amp;lt;- FeatureScatter(object = Fib, feature1 = &amp;quot;nCount_RNA&amp;quot;, feature2 = &amp;quot;percent.mt&amp;quot;) 
plot2 &amp;lt;- FeatureScatter(object = Fib, feature1 = &amp;quot;nCount_RNA&amp;quot;, feature2 = &amp;quot;nFeature_RNA&amp;quot;) 
CombinePlots(plots = list(plot1,plot2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/qc2-2.png&#34; width=&#34;1248&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# As you see on the left plot cells with high percentage of mitochondrial genes
# have very low numbers of RNA indicating that they are low quality/dead cells.
# Let&amp;#39;s remove them.
Fib &amp;lt;- subset(x = Fib, subset = nFeature_RNA &amp;gt; 200 &amp;amp; nFeature_RNA &amp;lt; 4000 &amp;amp; 
              percent.mt &amp;lt; 12.5)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;normalize-the-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Normalize the data&lt;/h4&gt;
&lt;p&gt;Log normalization helps to reduce the influences of the outliers.
Normalized values will be stored in &lt;code&gt;Fib[[&#34;RNA&#34;]]@data&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Fib &amp;lt;- NormalizeData(object = Fib, normalization.method = &amp;quot;LogNormalize&amp;quot;, 
                     scale.factor = 1e4)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;identify-highly-variable-features&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Identify highly variable features&lt;/h4&gt;
&lt;p&gt;Let’s calculate the features that exhibit high cell-to-cell variation in the dataset. Focusing on those genes will help to highlight biological signal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Fib &amp;lt;- FindVariableFeatures(object = Fib, selection.method = &amp;#39;vst&amp;#39;,  nfeatures = 2000)

# Identify the 10 most highly variable genes
top10 &amp;lt;- head(x = VariableFeatures(object = Fib), 10)
top10&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;SCGB1A1&amp;quot; &amp;quot;SCGB3A1&amp;quot; &amp;quot;SFTPC&amp;quot;   &amp;quot;SCGB3A2&amp;quot; &amp;quot;HBB&amp;quot;     &amp;quot;PLA2G2A&amp;quot; &amp;quot;MT1G&amp;quot;   
##  [8] &amp;quot;TPSB2&amp;quot;   &amp;quot;FABP4&amp;quot;   &amp;quot;MT1H&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Plot variable features with and without labels
plot1 &amp;lt;- VariableFeaturePlot(object = Fib)
plot2 &amp;lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE)
CombinePlots(plots = list(plot1, plot2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/var_features-1.png&#34; width=&#34;1056&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-the-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Scale the data&lt;/h4&gt;
&lt;p&gt;Next, apply a linear transformation that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The &lt;code&gt;ScaleData&lt;/code&gt; function:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Highly-expressed genes might dominate downstream analyses since their expression range is much higher than most other genes.&lt;/strong&gt; In order to prevent this we need to;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;shift the expression of each gene, so that the mean expression across cells is 0&lt;/li&gt;
&lt;li&gt;scale the expression of each gene, so that the variance across cells is;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apply the &lt;code&gt;ScaleData&lt;/code&gt; function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.genes &amp;lt;- rownames(x = Fib)
Fib &amp;lt;- ScaleData(object = Fib, features = all.genes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Another factor that can influence downstream analyses is cell cycle status, 
# cells that arenormally cycling but in different phases of cell cycle # might appear as separate populations.
# Seurat is preloaded with list of cell cycle markers, from Tirosh et al. 2015, 
# segregate this list into markers of G2/M phase and markers of S phase

s.genes &amp;lt;- cc.genes$s.genes
g2m.genes &amp;lt;- cc.genes$g2m.genes
Fib &amp;lt;- CellCycleScoring(Fib, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE)

# We can view cell cycle scores and phase assignments with
head(Fib[[]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       orig.ident nCount_RNA nFeature_RNA percent.mt
## AAACCTGAGATCCCGC-1 FightFibrosis       2257         1010   4.386354
## AAACCTGAGCCAGAAC-1 FightFibrosis       7354         1943   3.929834
## AAACCTGAGGGATGGG-1 FightFibrosis       9323         2786   8.430763
## AAACCTGAGTCGTACT-1 FightFibrosis       2937         1125   6.775621
## AAACCTGAGTCGTTTG-1 FightFibrosis       5447         1719   4.149073
## AAACCTGCAAGTCTAC-1 FightFibrosis       6453         1836   2.773904
##                         S.Score    G2M.Score Phase     old.ident
## AAACCTGAGATCCCGC-1  0.006739441 -0.016659228     S FightFibrosis
## AAACCTGAGCCAGAAC-1 -0.040762255 -0.010151464    G1 FightFibrosis
## AAACCTGAGGGATGGG-1 -0.048223904 -0.025580453    G1 FightFibrosis
## AAACCTGAGTCGTACT-1  0.076114887  0.009717348     S FightFibrosis
## AAACCTGAGTCGTTTG-1 -0.045171005 -0.053868788    G1 FightFibrosis
## AAACCTGCAAGTCTAC-1  0.003354484 -0.009033119     S FightFibrosis&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Regress out cell cycle scores during data scaling
Fib &amp;lt;- ScaleData(Fib, vars.to.regress = 
                   c(&amp;quot;S.Score&amp;quot;, &amp;quot;G2M.Score&amp;quot;),  features =rownames(Fib))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;perform-linear-dimensional-reduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Perform linear dimensional reduction&lt;/h3&gt;
&lt;p&gt;Each gene creates another dimension in our dataset, but most of those does not play a role in differenting subgroups of cells. Principal components analyses (PCA) helps us by reducing the dimensions of our data into compoments which explains most of the variation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Fib &amp;lt;- RunPCA(object = Fib, features = VariableFeatures(object = Fib), 
              ndims.print = 10, nfeatures.print = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## PC_ 10 
## Positive:  VCAN, MCEMP1, S100A8, FCN1, CD2, IL32, S100A6, TIMP1, CCL5, CD3D 
## Negative:  CHIT1, A2M, CHCHD6, AC079767.4, SEPP1, ALOX15B, GPNMB, DNASE2B, LIPA, SLC40A1&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;visualize-the-pca-results&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize the PCA results&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Examine and visualize PCA results a few different ways
print(x = Fib[[&amp;#39;pca&amp;#39;]], dims = 1:5, nfeatures = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## PC_ 1 
## Positive:  TMSB4X, TYROBP, FTL, FCER1G, VIM 
## Negative:  RSPH1, C9orf24, TMEM190, C20orf85, FAM183A 
## PC_ 2 
## Positive:  FTH1, CTSS, TYROBP, B2M, FCER1G 
## Negative:  GPRC5A, SFTPB, CEACAM6, HOPX, MUC1 
## PC_ 3 
## Positive:  PLA2G2A, GFPT2, MEDAG, COL3A1, COL1A2 
## Negative:  SFTPB, SFTPA2, SFTA2, SFTPA1, SLC34A2 
## PC_ 4 
## Positive:  SFTPC, NAPSA, SFTPD, LRRK2, LAMP3 
## Negative:  S100A2, KRT19, KRT5, AKR1C1, BPIFB1 
## PC_ 5 
## Positive:  CPA3, TPSAB1, TPSB2, MS4A2, GATA2 
## Negative:  S100A6, CSTB, S100A10, GCHFR, TXN&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VizDimLoadings(object = Fib, dims = 1:2, reduction = &amp;#39;pca&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/pca_viz-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(object = Fib, reduction = &amp;#39;pca&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/pca_viz-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimHeatmap(object = Fib, dims = 1:9, cells = 500, balanced = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/multi-heatmap-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-dimensionality-of-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What is the ‘dimensionality’ of the data?&lt;/h3&gt;
&lt;p&gt;For clustering analyses we will choose the principal components which explain most of the variation in our data. &lt;code&gt;Elbow plot&lt;/code&gt; uses a ranking of principle components based on the percentage explained by each one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ElbowPlot(object = Fib)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/elbow_plot-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We did not get a clear elbow shape here, but after 10th principal component additional dimensions does not explain big amount of the variance. So we will use first 10 dimensions for the subsequent analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cluster-the-cells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cluster the cells&lt;/h3&gt;
&lt;p&gt;A graph-based clustering approach will be performed, built upon initial strategies in (&lt;a href=&#34;http://www.cell.com/abstract/S0092-8674(15)00549-8&#34;&gt;Macosko &lt;em&gt;et al&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Fib &amp;lt;- FindNeighbors(object = Fib, dims = 1:10)
Fib &amp;lt;- FindClusters(object = Fib, resolution = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
## 
## Number of nodes: 6320
## Number of edges: 196713
## 
## Running Louvain algorithm...
## Maximum modularity in 10 random starts: 0.8872
## Number of communities: 15
## Elapsed time: 0 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Look at cluster IDs of the first 5 cells
head(Idents(Fib), 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## AAACCTGAGATCCCGC-1 AAACCTGAGCCAGAAC-1 AAACCTGAGGGATGGG-1 
##                  2                  2                  8 
## AAACCTGAGTCGTACT-1 AAACCTGAGTCGTTTG-1 
##                  0                 10 
## Levels: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tsne-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TSNE plot&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Fib &amp;lt;- RunTSNE(object = Fib, dims = 1:6)
DimPlot(object = Fib, reduction = &amp;#39;tsne&amp;#39;, label = TRUE, label.size = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/TSNE%20plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-find-genes-that-differentiate-each-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to find genes that differentiate each cluster?&lt;/h3&gt;
&lt;p&gt;We can use &lt;code&gt;FindMarkers()&lt;/code&gt; function to search for cluster biomarkers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Find all markers of cluster 0
cluster0.markers &amp;lt;- FindMarkers(object = Fib, ident.1 = 0, min.pct = 0.25)
head(x = cluster0.markers, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          p_val avg_logFC pct.1 pct.2 p_val_adj
## GPNMB        0 1.0814399 0.947 0.450         0
## CSTB         0 1.0377160 0.994 0.892         0
## FTL          0 1.0160962 1.000 0.998         0
## APOC1        0 0.9919471 0.991 0.819         0
## SH3BGRL3     0 0.9252345 0.990 0.798         0
## CTSD         0 0.9105122 0.995 0.836         0
## FTH1         0 0.8873914 1.000 0.997         0
## PSAP         0 0.8835586 1.000 0.876         0
## CTSB         0 0.8773872 0.986 0.752         0
## LGALS1       0 0.8622147 0.992 0.637         0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Find markers for every cluster compared to all remaining cells, report only 
# the positive ones
Fib.markers &amp;lt;- FindAllMarkers(object = Fib, only.pos = TRUE, min.pct = 0.25, 
                              logfc.threshold = 0.25)

# Make a table containing markers for each cluster set. 
# We will use this table to assign cell types to clusters.
Fib.markers %&amp;gt;% group_by(cluster) %&amp;gt;% top_n(n = 5, wt = avg_logFC) %&amp;gt;% 
  print(n = 85)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 75 x 7
## # Groups:   cluster [15]
##        p_val avg_logFC pct.1 pct.2 p_val_adj cluster gene    
##        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;   
##  1 0.            1.08  0.947 0.45  0.        0       GPNMB   
##  2 2.60e-293     1.13  0.935 0.582 5.27e-289 0       FABP5   
##  3 8.54e-289     1.12  0.814 0.365 1.73e-284 0       CTSL    
##  4 3.43e-188     1.43  0.46  0.133 6.95e-184 0       SPP1    
##  5 2.78e-110     1.37  0.288 0.078 5.64e-106 0       CCL2    
##  6 2.69e-231     1.33  0.996 0.658 5.45e-227 1       APOE    
##  7 1.91e-204     1.02  0.926 0.403 3.86e-200 1       MS4A6A  
##  8 1.35e-174     0.918 0.932 0.423 2.74e-170 1       C1QC    
##  9 1.59e-119     1.07  0.86  0.457 3.22e-115 1       CCL18   
## 10 1.56e- 56     0.916 0.576 0.311 3.15e- 52 1       SEPP1   
## 11 0.            2.26  0.663 0.108 0.        2       FABP4   
## 12 0.            1.43  0.846 0.165 0.        2       MCEMP1  
## 13 5.19e-222     1.24  0.969 0.496 1.05e-217 2       GCHFR   
## 14 4.41e-218     1.36  0.98  0.505 8.93e-214 2       C1QA    
## 15 4.43e-210     1.35  0.967 0.483 8.97e-206 2       C1QB    
## 16 0.            3.18  0.964 0.339 0.        3       SCGB3A2 
## 17 0.            2.01  0.995 0.376 0.        3       SFTPB   
## 18 0.            1.73  0.943 0.188 0.        3       CEACAM6 
## 19 2.27e-273     2.23  0.929 0.364 4.59e-269 3       SFTPA2  
## 20 8.38e-271     1.72  0.813 0.203 1.70e-266 3       SFTPA1  
## 21 0.            2.70  0.896 0.035 0.        4       C9orf24 
## 22 0.            2.46  0.87  0.026 0.        4       TMEM190 
## 23 0.            2.44  0.892 0.026 0.        4       RSPH1   
## 24 0.            2.42  0.868 0.025 0.        4       C20orf85
## 25 0.            2.39  0.907 0.104 0.        4       TPPP3   
## 26 0.            2.76  0.975 0.227 0.        5       S100A2  
## 27 0.            2.19  0.797 0.083 0.        5       KRT15   
## 28 0.            1.72  0.684 0.048 0.        5       KRT5    
## 29 6.72e-278     1.93  0.471 0.035 1.36e-273 5       MMP1    
## 30 9.96e-220     1.75  0.925 0.319 2.02e-215 5       AQP3    
## 31 0.            2.45  0.737 0.077 0.        6       BPIFB1  
## 32 6.07e-262     2.14  0.984 0.305 1.23e-257 6       WFDC2   
## 33 2.03e-221     2.21  0.982 0.385 4.11e-217 6       SLPI    
## 34 1.17e-163     3.21  0.948 0.624 2.36e-159 6       SCGB3A1 
## 35 8.07e-152     2.91  0.797 0.293 1.63e-147 6       SCGB1A1 
## 36 0.            2.57  0.797 0.072 0.        7       S100B   
## 37 9.62e-289     1.76  0.829 0.156 1.95e-284 7       FAM26F  
## 38 2.50e-224     2.18  1     0.728 5.06e-220 7       HLA-DPB1
## 39 2.51e-213     1.99  0.992 0.658 5.07e-209 7       HLA-DPA1
## 40 1.75e-191     1.71  0.955 0.449 3.55e-187 7       HLA-DQA1
## 41 4.11e- 50     1.01  0.546 0.231 8.31e- 46 8       STMN1   
## 42 1.29e- 41     0.917 0.819 0.529 2.60e- 37 8       TUBA1B  
## 43 1.29e- 40     0.915 0.807 0.517 2.61e- 36 8       TUBB    
## 44 1.32e- 29     0.973 0.825 0.615 2.67e- 25 8       H2AFZ   
## 45 5.14e- 29     1.16  0.77  0.503 1.04e- 24 8       HIST1H4C
## 46 0.            2.28  0.984 0.113 0.        9       NAPSA   
## 47 3.65e-299     2.20  0.984 0.159 7.39e-295 9       SFTA2   
## 48 8.60e-252     2.99  1     0.226 1.74e-247 9       SFTPA1  
## 49 3.66e-220     4.21  0.961 0.265 7.42e-216 9       SFTPC   
## 50 4.19e-168     2.33  0.992 0.39  8.47e-164 9       SFTPA2  
## 51 0.            2.61  0.570 0.01  0.        10      COL3A1  
## 52 0.            2.56  0.604 0.005 0.        10      SPARCL1 
## 53 0.            2.42  0.456 0.005 0.        10      PLA2G2A 
## 54 0.            2.40  0.544 0.005 0.        10      COL1A2  
## 55 1.09e-278     2.57  0.537 0.02  2.20e-274 10      COL1A1  
## 56 0.            4.23  0.993 0.035 0.        11      TPSB2   
## 57 0.            3.74  0.993 0.02  0.        11      TPSAB1  
## 58 0.            3.32  1     0.02  0.        11      CPA3    
## 59 0.            2.78  0.911 0.017 0.        11      MS4A2   
## 60 0.            2.33  0.856 0.016 0.        11      KIT     
## 61 1.98e-262     2.08  0.624 0.023 4.01e-258 12      FCN1    
## 62 5.17e- 70     1.95  0.475 0.059 1.05e- 65 12      IL1R2   
## 63 2.47e- 66     1.98  0.634 0.119 5.01e- 62 12      VCAN    
## 64 4.37e- 58     3.03  0.812 0.258 8.85e- 54 12      S100A8  
## 65 2.45e- 46     2.67  0.901 0.466 4.96e- 42 12      S100A9  
## 66 2.37e- 68     2.24  0.593 0.055 4.80e- 64 13      IL32    
## 67 1.03e- 66     2.00  0.296 0.013 2.08e- 62 13      KLRB1   
## 68 4.82e- 52     3.79  0.259 0.013 9.77e- 48 13      IGHG1   
## 69 3.98e- 44     3.37  0.259 0.015 8.06e- 40 13      IGHG4   
## 70 3.42e- 42     2.22  0.352 0.03  6.92e- 38 13      CCL5    
## 71 6.32e-208     1.85  0.978 0.036 1.28e-203 14      CPA3    
## 72 1.19e-176     1.28  0.822 0.03  2.41e-172 14      KIT     
## 73 3.11e-176     1.40  0.844 0.032 6.30e-172 14      MS4A2   
## 74 7.63e-172     1.75  0.889 0.036 1.54e-167 14      TPSAB1  
## 75 2.72e-158     2.05  0.978 0.051 5.50e-154 14      TPSB2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details consult to &lt;a href=&#34;http://satijalab01.nygenome.org/seurat/v3.0/de_vignette.html&#34;&gt;DE vignette&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;According to the table above I generated a cluster id vector to assign cell type to each cluster. I have a group NA which I could not assign a cell type, which is probably a technical artifact from cell cycle regression since the top genes expressed in this population are cell cycle related. I also found 3 subpopulations of macrophages and 2 types of mast cells in thiS patient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Assigning Cell ids

new.cluster.ids &amp;lt;- c(&amp;quot;Macrophages(1)&amp;quot;, &amp;quot;Macrophages(2)&amp;quot;, &amp;quot;Macrophages(3)&amp;quot;,
                     &amp;quot;AT2(1) Cells&amp;quot;, &amp;quot;Cliated Cells&amp;quot;, &amp;quot;Basal Cells&amp;quot;, &amp;quot;Club Cells&amp;quot;, 
                     &amp;quot;Dendritic Cells&amp;quot;, &amp;quot;NA&amp;quot;, &amp;quot;AT2(2) Cells&amp;quot;, &amp;quot;Fibroblasts&amp;quot;, 
                     &amp;quot;Mast(1) Cells&amp;quot;, &amp;quot;Monocytes&amp;quot;, &amp;quot;T/NKT Cells&amp;quot;, &amp;quot;Mast(2) Cells&amp;quot;)
names(new.cluster.ids) &amp;lt;- levels(Fib)
Fib &amp;lt;- RenameIdents(Fib, new.cluster.ids)
DimPlot(Fib, reduction = &amp;quot;tsne&amp;quot;, label = TRUE, label.size = 8, pt.size = 1.0) + NoLegend()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/tsnewithcellids-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s look at the expression of a few genes of interest accross different subtypes
VlnPlot(Fib, features = c(&amp;quot;SPP1&amp;quot;, &amp;quot;CHIT1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/differentfeautures-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features = c(&amp;quot;SPP1&amp;quot;, &amp;quot;APOE&amp;quot;, &amp;quot;SCGB3A2&amp;quot;, &amp;quot;C9orf24&amp;quot;, &amp;quot;S100A2&amp;quot;, &amp;quot;BPIFB1&amp;quot;, &amp;quot;S100B&amp;quot;, &amp;quot;COL3A1&amp;quot;, &amp;quot;FCN1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/differentfeautures-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-cells-biotech-companies-are-targeting-in-lung-fibrosis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What cells &lt;code&gt;Biotech&lt;/code&gt; Companies are targeting in lung fibrosis?&lt;/h3&gt;
&lt;p&gt;Novel therapies in pulmonary fibrosis are urgently needed. Let’s look at few promising drugs currently in clinical trials.&lt;/p&gt;
&lt;div id=&#34;fibrinogen&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Fibrinogen&lt;/h4&gt;
&lt;p&gt;Fibrinoge’s lead compound pamrevlumab blocks CTGF. Let’s have a look which cells produce it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VlnPlot(Fib, features =c(&amp;quot;CTGF&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/Fibrinogen-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features = c(&amp;quot;CTGF&amp;quot;), pt.size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/Fibrinogen-2.png&#34; width=&#34;672&#34; /&gt;
Main source for the &lt;code&gt;CTGF&lt;/code&gt; production here seems the &lt;code&gt;Ciliated cells.&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;galapagos&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Galapagos&lt;/h4&gt;
&lt;p&gt;Galapagos GLPG1690 has entered Phase 3 clinical trials and it targets Autotaxin (ENPP2).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VlnPlot(Fib, features =  c(&amp;quot;ENPP2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/GLPG1690-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features =  c(&amp;quot;ENPP2&amp;quot;),  pt.size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/GLPG1690-2.png&#34; width=&#34;672&#34; /&gt;
We see a low expression of &lt;code&gt;ENPP&lt;/code&gt; mainly in Macrophages, Dendritic cells and Fibroblasts.&lt;/p&gt;
&lt;p&gt;The other clinical candidate of Galapagos is GLPG1205 which targets GPR84. It has entered Phase 2 clinical trials.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VlnPlot(Fib, features =  c(&amp;quot;GPR84&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/GLPG1205-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features =  c(&amp;quot;GPR84&amp;quot;), pt.size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/GLPG1205-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GPR84&lt;/code&gt; has very low expression throughout the lung cells of this patient. The gene is mainly expressed in Type 1 Macrophages.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bristol-myers-squibb-bms-986020&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bristol-Myers-Squibb: &lt;code&gt;BMS-986020&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;BMS-986020 is an anti-fibrotic drug being developed by Bristol-Myers Squibb, and is a lysophosphatidic acid (LPA) receptor antagonist.&lt;/p&gt;
&lt;p&gt;Let’s look at the expression of a LPAR1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VlnPlot(Fib, features = c(&amp;quot;LPAR1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/LPAR1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features =c(&amp;quot;LPAR1&amp;quot;),  pt.size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/LPAR1-2.png&#34; width=&#34;672&#34; /&gt;
It is expressed at low levels but consistently on many types of lung cells.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;roche-nintedanib&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Roche &lt;code&gt;nintedanib&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Nintedanib is one of the two new medicines approved for IPF patients. It targets multiple receptor tyrosine kinase receptors such as VEGF, FGF and PDGF.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VlnPlot(Fib, features = c(&amp;quot;VEGFA&amp;quot;, &amp;quot;PDGFA&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/nintedanib-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FeaturePlot(Fib, features =  c(&amp;quot;VEGFA&amp;quot;, &amp;quot;PDGFA&amp;quot;), pt.size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-17-genomics-at-superresolution-advances-in-sequencing-technologies_files/figure-html/nintedanib-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;VEGFA, PDGFA is highly expressed in multiple types of cells in the lung microenvironment.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;final-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final thoughts&lt;/h3&gt;
&lt;p&gt;Seurat package allowed us to cluster different types of lung cells so that we can visualize their specific gene expression. We used those plots to see which cells express the drug targets in clinical trials or in use.&lt;br /&gt;
Although changes associated with fibrosis are well defined the causal factors are not known. Reflecting this we saw that those &lt;strong&gt;drugs target many different components of the lung microenvironment.&lt;/strong&gt; The conquest is on and we hope promising therapies arrive soon.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Start blogging in 5 minutes on Netlify with Hugo and blogdown (September 2019 Update)</title>
      <link>/2019/09/15/deploy-your-blog-in-5-minutes/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/2019/09/15/deploy-your-blog-in-5-minutes/</guid>
      <description>


&lt;p&gt;This guide will help you to get your website online in a few minutes. Then, customize and add your own material in RStudio environment, push it to your Github repository and benefit from the continous deployment feature of Netlify.
It took me many days of work, reading tens of blog posts, YouTube videos and a lot of testing to figure out all of this.&lt;/p&gt;
&lt;p&gt;Here is an up to date workflow of &lt;strong&gt;how I created my Blog on Github and deployed at Netlify.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;tools-we-need&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tools we need;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RStudio&lt;/li&gt;
&lt;li&gt;Hugo&lt;/li&gt;
&lt;li&gt;Blogdown&lt;/li&gt;
&lt;li&gt;Git&lt;/li&gt;
&lt;li&gt;Github&lt;/li&gt;
&lt;li&gt;Netlify&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hugo is the actual website builder and &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; is an R package that allows us to use Hugo in R environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;on-rstudio-build-your-website-locally.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On RStudio: Build your website locally.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Select &lt;strong&gt;File&lt;/strong&gt; menu&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Select &lt;strong&gt;New Project -&amp;gt; New Directory -&amp;gt; Website using blogdown&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, to create a new site with the academic theme replace default lithium &lt;code&gt;Hugo theme&lt;/code&gt; with &lt;strong&gt;gcushen/hugo-academic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For other themes go to &lt;a href=&#34;http://themes.gohugo.io&#34; class=&#34;uri&#34;&gt;http://themes.gohugo.io&lt;/a&gt;, choose a theme you like, click homepage and you will be redirected to its github repository.&lt;br /&gt;
Replace its &lt;strong&gt;repository name&lt;/strong&gt; with “&lt;strong&gt;gcushen/hugo-academic&lt;/strong&gt;” above)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;command will create the website and it should be visible on the viewer pane.&lt;/p&gt;
&lt;p&gt;Use &lt;strong&gt;list.files()&lt;/strong&gt; to see the files/folders generated.&lt;/p&gt;
&lt;div id=&#34;prepare-for-github-compatibility&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prepare for GitHub compatibility&lt;/h4&gt;
&lt;p&gt;To be able to publish the website on github we need to specify a &lt;strong&gt;docs&lt;/strong&gt; folder instead of the default public folder where the website is created.&lt;/p&gt;
&lt;p&gt;Open your &lt;strong&gt;config.toml&lt;/strong&gt; file under the Website folder, and add the lines; &lt;a id=&#34;editconfig&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;baseurl: &#34;https://yourusername.github.io/page/&#34;&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;publishDir = &#34;docs&#34;&lt;/code&gt;
&lt;img src=&#34;/img/configtoml.jpg&#34; alt=&#34;configtoml&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Save the config file. This will rebuild the site and create the docs folder.
Now you can go back to your folder and delete the public directory.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;on-github-account&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On Github account&lt;/h3&gt;
&lt;div id=&#34;create-a-new-repository&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create a new repository&lt;/h4&gt;
&lt;p&gt;Log in to your Github account and create a new repository.
Here I called it &lt;code&gt;page.&lt;/code&gt;
Then your remote repository will be at&lt;br /&gt;
&lt;a href=&#34;https://github.com/yourusername/page.git&#34; class=&#34;uri&#34;&gt;https://github.com/yourusername/page.git&lt;/a&gt;
Copy that link.
&lt;img src=&#34;/img/git.png&#34; alt=&#34;git&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;on-git&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;On Git&lt;/h3&gt;
&lt;div id=&#34;create-your-local-.git-repository&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create your local .git repository&lt;/h4&gt;
&lt;p&gt;By using pwd and cd commands navigate your directory to the Website folder&lt;/p&gt;
&lt;p&gt;Initialize your local repository&lt;br /&gt;
&lt;code&gt;git init&lt;/code&gt;&lt;br /&gt;
Use the copied link from above&lt;br /&gt;
&lt;code&gt;git remote add origin https://github.com/yourusername/page.git&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git add .&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git commit -m createmywebsite&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Following command will synchronize all your files to your Github repository&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;publishing-your-website-on-github-pages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Publishing your website on Github pages&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In your Github repository. Go to settings&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Scroll down to Github pages, choose source &amp;gt; &lt;strong&gt;master branch/docs&lt;/strong&gt; folder&lt;/li&gt;
&lt;li&gt;This will update the page. Scroll down to Github pages again click the link:&lt;br /&gt;
e.g. &lt;a href=&#34;https://yourusername.github.io/page/&#34; class=&#34;uri&#34;&gt;https://yourusername.github.io/page/&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Hoorray! In this step your website should be up and running on Github!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deploying-your-website-to-netlify&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Deploying your Website to Netlify&lt;/h3&gt;
&lt;p&gt;If you want to benefit from the advantages like continous deployment you can
use &lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Go to your &lt;strong&gt;Netlify&lt;/strong&gt;, Click &lt;code&gt;Get started for free&lt;/code&gt; and sign up with Github.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose &lt;strong&gt;New site from Git&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Choose &lt;strong&gt;GitHub&lt;/strong&gt; at the bottom&lt;/li&gt;
&lt;li&gt;Click on &lt;strong&gt;Configure the Netlify app on GitHub.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;On github select your target repository. Save.&lt;/li&gt;
&lt;li&gt;On Netlify pick up that repository.&lt;/li&gt;
&lt;li&gt;Modify Basic build settings: &lt;strong&gt;Publish directory&lt;/strong&gt; should be &lt;strong&gt;docs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Click on &lt;strong&gt;Show advanced&lt;/strong&gt; &amp;gt; New Variable&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Add a New Variable&lt;br /&gt;
Modify as Key = HUGO_VERSION and Value = 0.58.1&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;This step is important otherwise your site will not be built.&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you dont know your hugo version; on Rstudio &amp;gt; type&lt;/p&gt;
&lt;p&gt;&lt;code&gt;blogdown::hugo_version()&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;strong&gt;Deploy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It will allocate you a random link. You have to go back to your config.toml and modify baseurl as we did for Github &lt;a href=&#34;#editconfig&#34;&gt;above&lt;/a&gt; but with this netlify link.&lt;/p&gt;
&lt;p&gt;After this step you have to push changes to github from your local git. Similarly to the steps above without &lt;code&gt;git init&lt;/code&gt; this time.&lt;/p&gt;
&lt;p&gt;Netlify will detect those changes you pushed to your github repository and your site will be published in a few seconds.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hoorray! In this step your website should be up and running on Netlify!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-use-your-own-domain-name&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to use your own domain name&lt;/h3&gt;
&lt;div id=&#34;go-to-your-domain-provider-e.g-i-did-on-go-daddy&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Go to your domain provider e.g I did on Go Daddy&lt;/h4&gt;
&lt;p&gt;My Products &amp;gt; Scroll down to your domain &amp;gt; Click DNS&lt;/p&gt;
&lt;p&gt;Create new or modify if existing an A record pointing your root domain to Netlify load balancer’s IP address 104.198.14.52 as in below;
&lt;img src=&#34;/img/A_record.jpg&#34; alt=&#34;A_record&#34; /&gt;Add a CNAME file as here;
&lt;img src=&#34;/img/netlify_CNAME.jpg&#34; alt=&#34;netlify_CNAME&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;go-to-domain-settings-on-your-deploy-at-netlify&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Go to domain settings on your deploy at Netlify&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Add custom domain&lt;/li&gt;
&lt;li&gt;Fill in your domain name&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Click Verify &amp;gt; Yes, add domain &amp;gt; Verify DNS configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Voila, in this step your website should be online at www.yourdomain.com!!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
