---
title: 'Data Wrangling for Text mining: Extract individual elements from a Book'
author: ''
date: '2019-09-25'
slug: data-wrangling-text-mining
categories: []
tags:
  - RStudio
  - R Markdown
  - Text mining
  - Stringr
  - Data preparation
  - For loop
subtitle: ''
summary: ''
authors: []
lastmod: '2019-09-25T10:02:47+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

My ambitious goal is to write a machine learning algorithm that predicts authors. But let's start with something simpler. An important part in a Data Science workflow is data preparation. **Clean it, reformat it and make it usable for further analysis.**

```{r, fig.cap="Photo by Patrick Tomasso on Unsplash", echo=FALSE}
library(knitr)
library(ggplot2)
# All defaults
include_graphics("/img/patrick-tomasso-Oaqk7qqNh_c-unsplash.jpg")
```

I will work on a Poetry book called "New Poems" from D. H. Lawrence. You can download it from [Project Gutenberg website](https://www.gutenberg.org/) which is a library of over 60,000 free eBooks. 

**The goal is to isolate each poem individually for text mining analysis.**  
  
Let's figure out a solution. 

{{% alert note %}}
I will use the table of contents section to **fish out each poem separately** by using two **for loops.**
{{% /alert %}}


### Install required packages

```{r Import packages, warning=FALSE, message=FALSE}
library(dplyr)
library(stringr)
library(stringi)
```

### Copy the book from DH Lawrence "New Poems"

At gutenberg website there are couple of slightly different formats of the book. Since there were some mistakes in the .txt file I used 
the html version [here](http://www.gutenberg.org/files/22726/22726-h/22726-h.htm). I copied the text and pasted it in a text editor and saved to my working directory. 
```{r data}

lawrence <- readLines("posts_data/lawrence_new_poems.txt")

```
Our file contains ```r length(lawrence)``` lines. With square brackets [ ] we can view the lines we want. Let's look at the first few lines;

```{r Lines, warning = FALSE, message = FALSE}
lawrence[1:5]

```
```{r, fig.cap="Photo by Thiebaud Faix on Unsplash", echo=FALSE}
library(knitr)
library(ggplot2)
# All defaults
include_graphics("/img/thiebaud-faix-eBkEJ9cH5b4-unsplash.jpg")
```
The [book](http://www.gutenberg.org/files/22726/22726-h/22726-h.htm) has 42 poems in total. Table of contents (TOC) starts with the line "CONTENTS" and ends with the line "ON THAT DAY".

I will use those lines to extract the TOC. Stringr package comes in handy here. **str_which()** function returns line index numbers for a given term.
```{r extract toc, warning = FALSE, message = FALSE}
start <- str_which(lawrence, pattern = fixed("CONTENTS"))
start
lawrence[start]
# We are choosing first appearance of "ON THAT DAY" with [1] because it appears 
# also in the Poem title later.
end <-  str_which(lawrence, pattern = fixed("ON THAT DAY"))[1]
end
lawrence[end]
```

Slicing the lines from ```r start+1``` to  ```r end``` will give us the TOC.

```{r toc, warning = FALSE, message = FALSE}
TOC <- lawrence[(start+1):(end)]
```

To remove empty spaces I will use here **stri_remove_empty()** function from **stringi** package.

```{r remove spaces}
TOC <- stri_remove_empty(TOC)
```
Let's look at how the clean TOC looks. 
```{r toc clean, warning = FALSE, message = FALSE}
TOC 

```


Next, we will extract main text containing only the poems without TOC and other metadata. We need to slice the document starting from the end of the contents ```(end)``` till end of the last poem.

```{r capture main body}
# After the last poem some metadata starts with "End of the Project..."
# We will slice until this line
end_main <- str_which(lawrence, "End of the Project Gutenberg EBook of New Poems, by D. H. Lawrence")
# Capture main text
lawrence_body <- lawrence[(end+1):(end_main -1)]
```

Now, we have TOC and main body of the book as two separate objects. 

### First for loop  

We will use TOC and a ```for loop``` to get the index numbers of the title's of each poem.
```{r capture individual poems}

# First initiate an empty list
index <- list()
# For loop
for (i in 1:42) {
index[[i]] <- str_which(lawrence_body, pattern = TOC[i])
}

index<- unlist(index)
index

```
The ```for loop``` we created here uses each title in TOC as a pattern inside a **str_which()** function to find the index number where it detects this pattern.   

For example TOC[1] will use the title of first poem as a pattern and it will return the line number where the poem starts. **At the end, we will have a list of starting lines of each poem.**  
```{r TOC[1]}
TOC[1]
str_which(lawrence_body, pattern = TOC[1])
# e.g. The poem Apprehension starts at line index number 9
```

Selecting the lines from the beginning of the **first poem** until the beginning of the **second poem** will give us the first poem. By iterating everything by +1 we will capture all 42 poems.


Since the title EMBANKMENT AT NIGHT appears in the titles of two poems we will do a slight correction here. To correct this, I will remove first appearance of index 768 and second appearance of 621.

```{r index}
index <- index[-c(23,27)]
index
length(index)
# Not to miss the last poem, I have to add the line index of the
# end of the main text. We can use the end of the main body as above.
index[43] <- end_main -1
```
Now, we have 42 index numbers matching the title of each poem 1 index number to label the end of the main text. We will use those to extract poems separately.   

### Second for loop

It's time for the trick. Finally we can capture each 42 poem separately in a list by using a second ```for loop.```
```{r capture}
# Create an empty list: poems
poems <- list()
for (i in 1:42) {
    
    poems[[i]] <- lawrence_body[(index[i]:index[i+1]-1)]  
}
# Visualize the first poem
writeLines(poems[[1]])
```

Let's check if we got what we wanted.
```{r final view}
str(poems)
```

### Final Thoughts

**Data Preparation** is a crucial step in Data Science as data comes rarely ready to use.

Here, starting from a Poetry Book I isolated each poem separately in a list. Hard part is done. **Now, I can identify how many rhymes each poem contains, word usage across different poems, the similarities between them and many more to gain insights about the author.** 

I could also analyze the whole book as a single document but by isolating each element I will gain much deeper insight from the data. 

Do you apply similar techniques to isolate chapters or sections from the book or documents to compare and contrast different parts?  

Thank you for reading this post. Please feel free to comment below with your thoughts/feedback.  