---
title: 'Text mining: How to extract individual elements from a Book'
author: ''
date: '2019-09-25'
slug: text-mining-extracting-elements
categories: []
tags:
  - RStudio
  - R Markdown
  - Text mining
  - Stringr
  - Data preparation
  - For loop
subtitle: ''
summary: ''
authors: []
lastmod: '2019-09-25T10:02:47+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

My ambitious goal is to write a machine learning algorithm that predicts the authors. But let's start with something simpler.

[Project Gutenberg](https://www.gutenberg.org/) is a library of over 60,000 free eBooks. I will work on a Poetry book called "New Poems" from D. H. Lawrence. 

**The goal is to isolate each poem individually for text mining analysis later.** Hints on internet was not plenty so I decided to figure out a solution myself. 

{{% alert note %}}
I will use the table of contents section to **fish out each poem separately** by using two **for loops.**
{{% /alert %}}


### Install the required packages

```{r Import packages, warning=FALSE, message=FALSE}
library(dplyr)
library(stringr)
library(stringi)
```

### Copy the book from DH Lawrence "New Poems"

Since there were some mistakes in the .txt version of the book I copied the text from the html version at [gutenbergr website](http://www.gutenberg.org/files/22726/22726-h/22726-h.htm) and pasted it in a txt file and saved to my working directory. 
```{r data}

lawrence <- readLines("posts_data/lawrence_new_poems.txt")

```
Our file contains ```r length(lawrence)``` lines. With square brackets [ ] we can view the lines we are interested. Let's look at the first few lines;

```{r Lines, warning = FALSE, message = FALSE}
lawrence[1:5]

```

The [book](http://www.gutenberg.org/files/22726/22726-h/22726-h.htm) has 42 poems in total. Table of contents (TOC) starts with the line "CONTENTS" and ends with the line "ON THAT DAY"

I will use those lines to extract the TOC. Stringr package comes in handy here. **str_which()** function returns line index numbers for a given term.
```{r extract toc, warning = FALSE, message = FALSE}
start <- str_which(lawrence, pattern = fixed("CONTENTS"))
start
lawrence[start]
# We are choosing first appearance of "ON THAT DAY" with [1] because it appears 
# also in the Poem title later.
end <-  str_which(lawrence, pattern = fixed("ON THAT DAY"))[1]
end
lawrence[end]
```

Slicing the lines from ```r start+1``` to  ```r end``` will give us the TOC.

```{r toc, warning = FALSE, message = FALSE}
TOC <- lawrence[(start+1):(end)]
```

To remove empty spaces I will use here **stri_remove_empty()** function from **stringi** package.

```{r remove spaces}
TOC <- stri_remove_empty(TOC)
```
Let's look at how the clean TOC looks. 
```{r toc clean, warning = FALSE, message = FALSE}
TOC 

```


Now, we will extract main text containing only the poems without metadata. We need to slice the document starting from the end of the contents ```(end)``` till end of the last poem.

```{r capture main body}
# After the last poem some metadata starts with "End of the Project..."
# We will slice until this line
end_main <- str_which(lawrence, "End of the Project Gutenberg EBook of New Poems, by D. H. Lawrence")
# Capture main text
lawrence_body <- lawrence[(end+1):(end_main -1)]
```

### First for loop  

We will use a ```for loop``` to get the index numbers of the title's of each poem.
```{r capture individual poems}

# First initiate an empty list
index <- list()
# For loop
for (i in 1:42) {
index[[i]] <- str_which(lawrence_body, pattern = TOC[i])
}

index<- unlist(index)
index

```
The ```for loop``` we created here uses each title in TOC as a pattern inside a **str_which()** function to find the index number where it detects this pattern.   

For example TOC[1] will use the title of first poem as a pattern and it will return the line number where the poem starts. **At the end, we will have a list of starting lines of each poem.**  
```{r TOC[1]}
TOC[1]
str_which(lawrence_body, pattern = TOC[1])
# e.g. The poem Apprehension starts at line index number 9
```

Selecting the lines from the beginning of the **first poem** until the beginning of the **second poem** will give us the first poem. By iterating everything by +1 we will capture all 42 poems.


Since the title EMBANKMENT AT NIGHT appears in the titles of two poems we will do a slight correction here. To remove those duplicates I will remove first apperance of index 768 and second appearence of 621.

```{r index}
index <- index[-c(23,27)]
index
length(index)
# Not to miss the last poem, I have to add the line index of the
# end of the main text
index[43] <- end_main -1
```
Now, we have 42 index numbers matching the title of each poem 1 index number to label the end of the main text. We will use those to extract poems separetely.   

### Second for loop

It's time for the trick. Finally we can capture each 42 poem separately in a list by using a second ```for loop.```
```{r capture}
# Create an empty list: poems
poems <- list()
for (i in 1:42) {
    
    poems[[i]] <- lawrence_body[(index[i]:index[i+1]-1)]  
}
# Visualize the first poem
writeLines(poems[[1]])
```

Let's check if we got what we wanted
```{r final view}
str(poems)
```

### Final Thoughts

**Data Preparation** is one crucial step in Data Science as data comes rarely ready to use.

Here, starting from a Poetry Book I isolated each poem separately in a list. Hard part is done. **Now, I can identify how many rhymes each poem contains, word usage across different poems, the similarities between them and many more to gain insights about the author.** 

I could also analyze the whole book as a single document but by isolating each element I will gain much deeper insight from the data. 

Do you apply similar techniques to isolate chapters or sections from the book or documents to compare and contrast different parts?  

Thank you for reading this post. Please feel free to comment below with your thoughts/feedback.  