---
title: An intuitive real life example of a binomial distribution and how to simulate it in R
author: ''
date: '2019-10-28'
slug: probability-distributions
categories: []
tags:
  - ggplot2
  - binomial distribution
  - statistics
  - probability
  - pvalue
subtitle: ''
summary: ''
authors: []
lastmod: '2019-10-28T20:48:21+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>Last week, I came across a data that I thought it is a great opportunity to write about Binomial probability distributions.</p>
<div id="what-is-a-binomial-distribution-and-why-we-need-to-know-it" class="section level1">
<h1>What is a binomial distribution and why we need to know it?</h1>
<p><strong>Binomial distributions</strong> refer to a repeated set of events and each single event in a set has two possible outcomes. Bi- in binomial distributions refers to those outcomes. Two possibilities are decribed as <strong>Success</strong> or <strong>no Success</strong>. A “yes” or “no”.</p>
<p>For example, in flipping coins, the two possibilities are getting a head (success) or tails (no success) or vice versa.</p>
<div id="why-is-this-interesting" class="section level2">
<h2>Why is this interesting?</h2>
<p>What is the probability of getting 25 heads out of 50 coin flips? You are right, 25 is an expected outcome. <strong>But how about getting 49 heads out of 50 flips?</strong> What is the probability of that given the coin is fair?</p>
<p>Let’s repeat this set of 50 times coin flipping, 100.000 times and look at the probability distribution.</p>
<p>Luckily, we can simulate this in R.</p>
<p><code>rbinom</code> function can make a given number of repeated (here 100.000) sets (50 times of coin flipping) of experiments. It takes 3 arguments.</p>
<p><code>rbinom(n, size, p)</code><br />
<strong>n</strong> = number of repetitions/trials = 100.000.<br />
<strong>size</strong> = sample size = 50.<br />
<strong>p</strong> is the probability of success (Here chance of throwing a heads is 0.5).</p>
<p>By wrapping <code>rbinom</code> inside <code>mean()</code> function we can actually calculate the probability of that event.</p>
<p>Let’s compare the probabilities of getting 25, 30 or 35 or more heads.</p>
<pre class="r"><code>library(tidyverse)

# Probability of getting 25 or more heads
mean(rbinom(100000, 50, .5) &gt; 24)</code></pre>
<pre><code>## [1] 0.55545</code></pre>
<pre class="r"><code># Probability of getting 30 or more heads
mean(rbinom(100000, 50, .5) &gt; 29)</code></pre>
<pre><code>## [1] 0.10084</code></pre>
<pre class="r"><code># Probability of getting 35 or more heads
mean(rbinom(100000, 50, .5) &gt; 34)</code></pre>
<pre><code>## [1] 0.00354</code></pre>
<p>As we see to get more than 35 heads is very unlikely in a set. Let’s visualize this. The bars in red represents the sets which had 35 or more heads.</p>
<pre class="r"><code>flips &lt;- rbinom(100000, 50, 0.5)
flips &lt;- data.frame(flips)
flips &lt;- flips %&gt;% mutate(more_than_35 = ifelse(flips &gt; 35, &quot;Yes&quot;, &quot;No&quot;))
flips %&gt;%  ggplot(aes(x=flips, fill = more_than_35)) + 
  geom_histogram(binwidth = 0.5) + 
  scale_fill_manual(values = c(&quot;black&quot;, &quot;red&quot;)) +
  theme_classic() +
  theme(legend.position = c(0.85, 0.85))</code></pre>
<p><img src="/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>You can also see here a key difference of a binomial distribution is that they can take only discrete values. It is not possible to have 35.5 heads. Although, there are differences, <strong>when the sample size is large enough their shape will be similar and normal distributions can be used to estimate binomial probabilities</strong>.</p>
<p><strong>So what are all those will be useful for?</strong></p>
<p>Coin flipping expertise may not have useful real life applications but let’s give some other examples.</p>
<ul>
<li><strong>Number of patients responding to a treatment.</strong></li>
</ul>
<p>Let’s say you know that a cancer medicine has 10% probability to cure a patient. You have multiple groups of 500 patients each with a different genetic mutation. You want to identify patient subgroups which better respond to your therapy. The expected number of patients responded to the therapy ( like above E = size * p) which is 500 * 0.1. So each group will have around 50 recovered patients, if there were no effects of those genetic mutations. But you found in one group that 65 patients responded. Is that due to chance or a significant effect?</p>
<ul>
<li><strong>Think about a hospital emergency station.</strong></li>
</ul>
<p>If you know 3.000 patients came in one year because of alcohol abuse. You can compare whether it was Friday or Saturday or another evening of a week. Each day has 1/7 chance of getting a patient visit. You can find out the whether events happening in the weekends more likely than expected and organize the staff numbers accordingly.</p>
<ul>
<li><strong>If you are running a webserver.</strong></li>
</ul>
<p>You can allocate your resources better by identifying times when traffic will be higher.</p>
<ul>
<li><strong>Number of people who answered ‘yes’ to a survey question</strong></li>
<li><strong>How many games a team will win in one season?</strong></li>
<li><strong>Vote counts for a candidate in an election.</strong></li>
<li><strong>Number of defective products in a production run.</strong></li>
</ul>
<p>Binomial distributions are common and they are very useful. Let’s come back to our case.
The data comes from TidyTuesday which I introduced you in my last <a href="https://dataatomic.com/r/tidytuesday-which-are-the-best-family-cars/">post</a>.</p>
<p>Having the <strong>correct mindset</strong> for anything gives us a better feeling of the moment.</p>
<p><strong>If you go to the cinema at the 13th to watch a horror movie, are you more likely to view it positively than any other date?</strong> I was curious if movie makers had the same idea and I analyzed Horror movies data to calculate numbers releases in different days of the month. This is a good example of a binomial probability distribution. Let’s look at the data.</p>
<pre class="r"><code>library(tidyverse) # ggplot2, dplyr, tidyr, readr, 
                   # purrr, tibble, stringr, forcats
library(animation)
library(viridis)</code></pre>
<pre class="r"><code>horror_movies &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv&quot;)

dim(horror_movies)</code></pre>
<pre><code>## [1] 3328   12</code></pre>
<pre class="r"><code>head(horror_movies)</code></pre>
<pre><code>## # A tibble: 6 x 12
##   title genres release_date release_country movie_rating review_rating
##   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;                &lt;dbl&gt;
## 1 Gut ~ Drama~ 26-Oct-12    USA             &lt;NA&gt;                   3.9
## 2 The ~ Horror 13-Jan-17    USA             &lt;NA&gt;                  NA  
## 3 Slee~ Horror 21-Oct-17    Canada          &lt;NA&gt;                  NA  
## 4 Trea~ Comed~ 23-Apr-13    USA             NOT RATED              3.7
## 5 Infi~ Crime~ 10-Apr-15    USA             &lt;NA&gt;                   5.8
## 6 In E~ Horro~ 2017         UK              &lt;NA&gt;                  NA  
## # ... with 6 more variables: movie_run_time &lt;chr&gt;, plot &lt;chr&gt;, cast &lt;chr&gt;,
## #   language &lt;chr&gt;, filming_locations &lt;chr&gt;, budget &lt;chr&gt;</code></pre>
<p>I need some <strong>data pre-processing</strong> before I can make my visualizations. Dates are given in <code>day:month:year</code> format. I need to split them to individual columns. Also couple of movies does not have the day of the month. I will remove them.</p>
<pre class="r"><code>horror_date &lt;-  horror_movies %&gt;% 
                separate(
                  release_date, 
                  c(&quot;day&quot;, &quot;month&quot;, &quot;year&quot;),
                  sep = &quot;-&quot;)

horror_date$day &lt;- as.numeric(horror_date$day)

# Remove rows without Date of the month

horror_date &lt;- horror_date %&gt;% filter(day &lt; 32) 

# I am excluding Day 1 from the analysis (Most aggreements starts at 1st)

horror_date_table &lt;- horror_date %&gt;% filter(day &gt; 1)

# Let&#39;s check what is the most common day in the month for a horror movie release
horror_date_table &lt;-  horror_date_table %&gt;%
  group_by(day) %&gt;% 
  count() %&gt;% 
  arrange(desc(n))
horror_date_table</code></pre>
<pre><code>## # A tibble: 30 x 2
## # Groups:   day [30]
##      day     n
##    &lt;dbl&gt; &lt;int&gt;
##  1    13   124
##  2    18   119
##  3    25   119
##  4    21   110
##  5    31   107
##  6    28   102
##  7    10   100
##  8    20   100
##  9     5    99
## 10     7    98
## # ... with 20 more rows</code></pre>
<p>Let’s visualize the data.</p>
<pre class="r"><code># Final
horror_date_table$day &lt;- as.character(horror_date_table$day)

my_title &lt;- &quot;Horror movies are more likely to be released at the 13th&quot;

p &lt;- horror_date_table %&gt;% 
    ungroup() %&gt;% 
    mutate(day=fct_reorder(day, n, .desc=TRUE)) %&gt;% 
    ggplot(aes(x=day, y=n)) +
    geom_col(aes(fill=n)) +
    scale_fill_viridis( direction =-1) + 
    theme(
      plot.title = element_text(size=24, color= &quot;black&quot;, hjust=0.5, vjust = -1),
      plot.subtitle = element_text(size=36, color= &quot;red&quot;, hjust=0.5, vjust = -1),
      panel.background = element_rect(fill = &quot;white&quot;), 
      plot.background = element_rect(fill = &quot;white&quot;),
      panel.grid = element_blank(),
      legend.position = &quot;none&quot;, 
      text = element_text(size=18), 
      axis.text.x =element_text(vjust=12, size=17, colour= &quot;white&quot;, face= &quot;bold&quot;),
      axis.title.x = element_text(vjust=9.5), 
      axis.text.y=element_blank(),
      axis.ticks= element_blank(), 
      plot.caption = element_text(hjust = 1, vjust = 10)) +
    labs(
          caption= &quot;Source: IMDb, Plot: @dataatomic&quot;,
          x = &quot;Day of the Month&quot;, 
          y = &quot;Number of movies released&quot;,
          title = my_title) +
    geom_label(aes(label = n), size=5, fill=&quot;yellow&quot;, alpha=0.9) 
p</code></pre>
<p><img src="/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/unnamed-chunk-3-1.png" width="1152" /></p>
</div>
</div>
<div id="is-this-significant" class="section level1">
<h1>Is this significant?</h1>
<p>In our data, there are <strong>2782</strong> movies associated with a release date. Since these are random events each day have an equal chance of 1/30 for a movie release. <strong>We expect a similar distribution of movies at each day, e.g. around the 92 (mean=2782/30).</strong></p>
<p>What we want to know is, are there any specific days in the month Movie industry prefers intentionally to release or not to release a movie?</p>
<pre class="r"><code># Size of our distribution is the total number of movies released 
n_value &lt;- horror_date_table %&gt;% ungroup() %&gt;% summarize(n2 = sum(n))
size &lt;- n_value$n2
size</code></pre>
<pre><code>## [1] 2782</code></pre>
<pre class="r"><code># The probability (= success rate = a given outcome to occur = movie released)
p &lt;-  1/30  # Since it can occur any of the 30 days in a months</code></pre>
<p>I want to know which days are in the <strong>range of random chance</strong> and which days there is a <strong>significant preference or an aversion</strong> to release a movie. To do this I can define a lower and upper boundary for significance (p value &lt; 0.05).</p>
<p>You can simulate this 2782 movie release dates events 100.000 times with rbinom function and calculate the mean and variance.</p>
<pre class="r"><code># Simulated statistics
 
estimates &lt;-  rbinom(100000, size, p)

# Simulated mean
mean(estimates)</code></pre>
<pre><code>## [1] 92.71845</code></pre>
<pre class="r"><code># Simulated variance
var(estimates)</code></pre>
<pre><code>## [1] 89.20341</code></pre>
<p>The average value is around 92 movies released in one day.</p>
<p>We can also calculate theoretical values by the derived mathematical formulas that define the binomial function:</p>
<p>Mean = size * p<br />
Variance = size * p * (1 - p)</p>
<p>Let’s calculate.</p>
<pre class="r"><code># Theoretical statistics

# Expected mean = size * p
mean_theoretical &lt;- 2782 * 1/30
mean_theoretical</code></pre>
<pre><code>## [1] 92.73333</code></pre>
<pre class="r"><code># Expected Variance = size * p * (1-p)
var_theoretical &lt;- size * 1/30 * (1-1/30)
var_theoretical</code></pre>
<pre><code>## [1] 89.64222</code></pre>
<p>Great, simulated and theoretical values are almost the same. So, I can use my simulations to find out 95% confidence interval which will contain the values that can happen due to random chance.</p>
<p>We can do this by the qbinom() function in r. We can calculate the quantile 97.5 and 2.5 as our upper and lower boundaries respectively.</p>
<pre class="r"><code># Boundaries for p values smaller than 0.05

lower &lt;- qbinom(0.975, 2782, 1/30)
lower</code></pre>
<pre><code>## [1] 112</code></pre>
<pre class="r"><code>upper &lt;- qbinom(0.025, 2782, 1/30)
upper</code></pre>
<pre><code>## [1] 75</code></pre>
<p>Values higher than <code>112</code> and values lower than <code>75</code> can not happen due to random chance in our binomial distribution.</p>
<p>Our value at the 13th is 124. Above the 97.5th quantile. So it is significant. But what is the exact p value?</p>
<pre class="r"><code># Probability of getting 124 movie releases in a day like here it happened on the 13th. # Probability of getting at least 124 success

p_val_binom &lt;- 2 * (1 - pbinom(124, 2782, 1/30))
p_val_binom</code></pre>
<pre><code>## [1] 0.001335455</code></pre>
<p>Let’s visualize the significant days which movie makers more or less likely to release a movie. I will highlighted the significant days with darker color.</p>
<pre class="r"><code># I will add a new column so I can separetly define values outside the 95% confidence interval.

horror_date_table_ci &lt;- horror_date_table %&gt;% mutate(significant = ifelse((n &lt; 112 &amp; n &gt; 75), 0,1))

# Visualize the significant days 
p_ci &lt;- horror_date_table_ci %&gt;% 
    ungroup() %&gt;% 
    mutate(day=fct_reorder(day, n, .desc=TRUE)) %&gt;% 
    ggplot(aes(x=day, y=n)) +
    geom_col(aes(fill=significant)) +
    scale_fill_viridis( direction =-1) + 
    theme(
        plot.title = element_text(size=24, color= &quot;black&quot;, hjust=0.5, vjust = -1),
        plot.subtitle = element_text(size=36, color= &quot;red&quot;, hjust=0.5, vjust = -1),
        panel.background = element_rect(fill = &quot;white&quot;), 
        plot.background = element_rect(fill = &quot;white&quot;),
        panel.grid = element_blank(),
        text = element_text(size=18), 
        axis.text.x =element_text(vjust=12, size=17, colour= &quot;white&quot;, face= &quot;bold&quot;),
        axis.title.x = element_text(vjust=9.5), 
        axis.text.y=element_blank(),
        axis.ticks= element_blank(), 
        plot.caption = element_text(hjust = 1, vjust = 10)) +
    labs(
        caption= &quot;Source: IMDb, Plot: @dataatomic&quot;,
        x = &quot;Day of the Month&quot;, 
        y = &quot;Number of movies released&quot;,
        title = my_title) +
        geom_label(aes(label = n), size=5, fill=&quot;yellow&quot;, alpha=0.9)
p_ci                                                     </code></pre>
<p><img src="/post/2019-10-28-an-intuitive-example-for-a-binomial-distribution_files/figure-html/6-1.png" width="1152" /></p>
<p>We performed a hypothesis testing by calculating the p value by using the pbinom() function.</p>
<p><strong>However, another widely used way to do so is to calculate the mean (the expected probability) of our distribution and its standard deviation and to verify how many standard deviations the observed value is away from the mean (the z score).</strong></p>
<p>Because we usually test our hypothesis using a sample, we work with the sampling distribution instead of the population distribution. This means that we use the standard error.</p>
<pre class="r"><code>sample_mean &lt;- horror_date_table %&gt;% ungroup() %&gt;% summarise(n=mean(n))
sample_mean</code></pre>
<pre><code>## # A tibble: 1 x 1
##       n
##   &lt;dbl&gt;
## 1  92.7</code></pre>
<pre class="r"><code>p &lt;- 1/30

sample_variance &lt;-  2782 * p * (1-p)
sample_variance</code></pre>
<pre><code>## [1] 89.64222</code></pre>
<pre class="r"><code>sample_sd &lt;- sqrt(sample_variance)

# Calculate z-score for observation 13th of the month = 124 movies are 
# released
observation &lt;- 124
z_score &lt;- (observation - sample_mean) / sample_sd
z_score</code></pre>
<pre><code>##          n
## 1 3.302367</code></pre>
<pre class="r"><code># Calculate the p-value of observing 124 or more movie releases in a day

p_val_nor &lt;- 2 * pnorm(3.302, lower.tail = FALSE)
p_val_nor</code></pre>
<pre><code>## [1] 0.0009599807</code></pre>
<p>P values found by using an approximation of a normal distribution and with a simulation of a binomial distribution are very close, Normal: <code>0.00095</code>, Binomial <code>0.00133</code>.</p>
</div>
<div id="future-thoughts-conclusions" class="section level1">
<h1>Future thoughts / Conclusions</h1>
<p>As we saw, many events in real life can be explained by binomial probability distributions, and they allow us to calculate whether or not the events happened due to random chance and test different hypotheses.</p>
<p>Until next time!</p>
<p>Serdar</p>
</div>
